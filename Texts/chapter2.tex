% !TEX root = ../thesis.tex

First up in this chapter is a brief summary of quantum field theories, both at zero and finite temperature, followed by a rather detailed derivation of the Fröhlich Hamiltonian. After this follows an illustration of how one can treat an interacting theory perturbatively in terms of pictorial Feynman diagrams. Finally there will be a short introduction to Monte Carlo methods.


\section{Quantum field theories}

\subsection{Single- and many-particle quantum mechanics}

In quantum mechanics the state of a particle $ | \psi \rangle $ can be projected onto the position basis $ | \vec x \rangle $ to form a wave function $ \langle \vec x | \psi \rangle = \psi (\vec x) $. In the Schrödinger picture, the dynamics is contained within the states $ | \psi \rangle = | \psi (t) \rangle $ so that $ \psi(\vec x) = \psi(\vec x, t) $ the time evolution of which is governed by the Schrödinger equation (in the non-relativistic limit). The quantity $ \psi^*(\vec x, t) \psi(\vec x, t) $ is real, and according to the Copenhagen interpretation of quantum mechanics \cite{HermannWimmel} it is to be interpreted as the probability density function. From this, the expectation value of some quantity, e.g.\ the position of the particle, is acquired through
\begin{equation}
	\begin{split}
		\langle \vec x(t) \rangle
		&= \int \vec x \, \psi^*(\vec x, t) \psi(\vec x, t) \diff^3x \\
		&= \int \vec x \, \langle \psi(t) | \vec x \rangle \langle \vec x | \psi(t) \rangle \diff^3x \\
		&= \langle \psi(t) | \left[ \int \vec x \, | \vec x \rangle \langle \vec x | \diff^3x \right] | \psi(t) \rangle \\
		&= \langle \psi(t) | \, \hat{\vec x} \left[ \int | \vec x \rangle \langle \vec x | \diff^3x \right] | \psi(t) \rangle \\
		&= \langle \psi(t) | \, \hat{\vec x} \, | \psi(t) \rangle \,.
	\end{split}
\end{equation}
To reach the final equality utilization has been made of the fact that the position basis is an eigenbasis of the position operator $ \hat{\vec x} | \vec x \rangle = \vec x | \vec x \rangle $ and also that this basis is orthonormal and complete so that the unity operator may be expressed as $ \hat \eye = \sum_{\vec x} | \vec x \rangle \langle \vec x | $.

What has been described so far is a quantum mechanical system of a single particle. In order to describe a system of more than one particle, this formalism need to be generalized to a many-particle description. When doing this, attention needs to be paid to the statistics of indistinguishable particles. That is, the state of the entire system must be symmetric with respect to the interchange of two indistinguishable bosons and antisymmetric to the interchange of two indistinguishable fermions. In the many-particle quantum mechanics formalism, this can be rather cumbersome even when dealing with a noninteracting system. Another shortcoming with this description of quantum mechanics is that the number of particles of each species must be fixed. Hence it is not possible to have particle creation or particle annihilation, which is necessary for certain processes.

\subsection{Second-quantization}

The second quantization \cite{quantumTheoryOfManyParticleSystems, AbrikosovGorkov} is a Hamiltonian based method for constructing a quantum field theory. Such a theory does not have the shortcomings of having a fixed set of particles as in the case of the many-particle description of quantum mechanics.

Again the state of the total system will be described by individual single-particle states. However, instead of having explicit all the permutations of the indistinguishable single-particle states in order to incorporate the statistics, the total system state will now be expressed using occupation numbers. That is, in this representation the only information given is for each species of particle, what number of particles occupies which states. For example, given the following set of single-particle states $ \{ | \nu_i \rangle \} $ where $ i = 0, \, 1, \, 2, \, \dots $, the expression describing a state in which $ | \nu_0 \rangle $ and $ | \nu_2 \rangle $ are occupied by three and two particles respectively would then be $ |3, \, 0, \, 0, \, 2, \, 0, \, 0, \, \dots \rangle $.

In order to allow for the number of particles to be variable the Fock space is used. This space is a combination of Hilbert state spaces for any number of particles; from the empty vacuum state to a state with infinite particles. In order to create and annihilate a particle of a certain quantum number, creation $ \hat c^\dagger_\nu $ and annihilation $ \hat c_\nu $ operators are used. It can be shown that they are the Hermitian conjugates of one another which motivates the notation. These operators incorporate the underlaying statistics of the particle at hand by a set of commutation relations. For bosons they are
\begin{equation}
	\label{eq:boseOperators}
	[\hat a_i, \, \hat a^\dagger_j] = \delta_{ij}
	\;, \quad
	[\hat a_i, \, \hat a_j] = [\hat a^\dagger_i, \, \hat a^\dagger_j] = 0 \,.
\end{equation}
These commutation relations are, for each single-particle state, identical to those of the ladder operators of a harmonic oscillator. For fermions the commutation relations are identical, but the commutator is exchanged in favor of the anticommutator in order to make the state antisymmetric, i.e.\
\begin{equation}
	\{ \hat b_i, \, \hat b^\dagger_j \} = \delta_{ij}
	\;, \quad
	\{ \hat b_i, \, \hat b_j \} = \{ \hat b^\dagger_i, \, \hat b^\dagger_j \} = 0 \,.
\end{equation}

The second-quantized Hamiltonian may be constructed by translating single- and many-particle quantum mechanical operators into the second-quantized description. In the case of a one-body operator this is translation is rather intuitive. Here the second-quantization operator $ \hat O $ is given by \cite{quantumTheoryOfManyParticleSystems}
\begin{equation}
	\label{eq:O1toO2}
	\hat O = \sum_{\mu, \nu} \langle \mu | O | \nu \rangle \hat c^\dagger_{\mu} \hat c_{\nu} \,,
\end{equation}
where $ O $ is the first-quantized operator, $ \mu $ and $ \nu $ are quantum numbers labeling the set of orthonormal single-particle states $ \{ | \mu \rangle \} $ and $ \hat c^\dagger_\mu, \, \hat c_\mu $ being the corresponding second-quantized creation and annihilation operators.


% One interesting property arises from the relation $ \{ \hat b^\dagger_i , \, \hat b^\dagger_i \} = \hat b^\dagger_i \hat b^\dagger_i + \hat b^\dagger_i \hat b^\dagger_i = 0 $, the implication of which become apparent when trying to create two or more particles sharing the same single-particle state; a zero will be multiplied by the resulting state. Hence all observables computed using such a state will be exactly zero. This would affect the physics equally to there being no state of this sort which of course is nothing but the Pauli exclusion principle.


\subsection{Field operators}

When having utilized the second-quantization formalism, the quantum mechanical system is described by a quantum field. That is, rather than being an operator as in single- and many-particle quantum mechanics, the position is now a parameter, just like time.

Field operators are creation and annihilation operators just like any other. They have gained their special name simply because they change the occupation number of single-particle eigenstates of the position operator. That is, they create or annihilate a particle at a particular position in space. Using the set of complete orthonormal single-particle wave functions $ \{ \psi_{\nu}(\vec x) \} $ along with the corresponding creation and annihilation operators $ \hat c^\dagger_\nu $, $ \hat c_\nu $, these field operators may be constructed by the following superpositions \cite{quantumTheoryOfManyParticleSystems},
\begin{equation}
	\label{eq:fieldOperator}
	\hat \psi (\vec x) \equiv \sum_{\nu} \hat c_{\nu} \psi_{\nu}(\vec x)
	\; , \quad
	\hat \psi^\dagger (\vec x) \equiv \sum_{\nu} \hat c^\dagger_{\nu} \psi^*_{\nu}(\vec x) \,.
\end{equation}
The $ \hat \psi (\vec x) $ will annihilate a particle at position $ \vec x $ whilst the Hermitian conjugate $ \hat \psi^\dagger (\vec x) $ will do the opposite and create a particle at position $ \vec x $.



\section{A few words on finite temperature formalism}

In a zero temperature quantum field theory, the Heisenberg picture is normally used when calculating observables, i.e.\ $ O = \langle \Psi_0 |  \hat O_\text{H}  | \Psi_0 \rangle $. In this picture the operators are responsible for the time evolution of the observables whilst the state vectors are made time independent. This is achieved by letting the time evolution of the Schrödinger state vector $ | \Psi_0 (t) \rangle = e^{-i \hat H t}  | \Psi_0 \rangle $ be absorbed into the Heisenberg operator $ \hat O_\text{H}(t) \equiv e^{i \hat H t} \, \hat O_\text{S} \, e^{-i \hat H t} $. Since the temperature $ T = 0 $ in such a theory, one does not need to be concerned about thermodynamics when calculating an observable, even if the ground state is not the vacuum one.

For a finite temperature quantum field theory and a general system, this no longer holds true. In order to incorporate the thermodynamics, the observables are no longer calculated by the expectation value of merely one ground state but instead as an ensemble average. In the case of a system with a variable number of particles, the grand canonical ensemble should be used. The partition function is then given by $ Z_\text{G} = \text{Tr} \, e^{-\beta (\hat H - \mu \hat N)} = \text{Tr} \, e^{-\beta \hat K} $ where $ \beta $ is the inverse temperature, $ \hat H $ is the Hamiltonian, $ \hat N $ is the number operator, $ \mu $ is the chemical potential and the trace is taken over a complete set of states. Introduced was also the grand canonical Hamiltonian $ \hat K \equiv \hat H - \mu \hat N $. In accordance with the partition function, the statistical operator is then defined as $ \hat \rho_\text{G} = e^{-\beta \hat K} / Z_\text{G} $ so that 
\begin{equation}
	\label{eq:finiteTempObservable}
	O
	= \sum_\nu \langle \Psi_\nu |  \hat \rho_\text{G} \, \hat O_\text{H}  | \Psi_\nu \rangle
	\equiv
	\text{Tr} \{ \hat \rho_\text{G} \, \hat O_\text{H}(t) \} \,.
\end{equation}
The operator product sandwiched between the state vectors in the equation above contains both real and imaginary exponents originating from the thermodynamics and quantum mechanics respectively. Following the Matsubara formalism \cite{Matsubara, quantumTheoryOfManyParticleSystems, AbrikosovGorkov}, one proceeds by introducing a new picture in order to treat the two types of exponents on an equal footing. This is a modified Heisenberg picture where a Wick rotation in time $ \tau = i t $ is preformed, and the Hamiltonian is exchanged in favor of the grand canonical Hamiltonian. An operator in this picture is then related to the corresponding one in the Schrödinger picture as
\begin{equation}
	\label{eq:modHeisPic}
	\hat O_\text{K}(\tau) \equiv e^{\hat K \tau} \, \hat O_\text{S} \, e^{-\hat K \tau} \,.
\end{equation}


\subsection{Green's function}

The single-particle Green's function, also known as the propagator, plays a crucial role in quantum field theory. At zero temperature, in position and time representation, the single-particle Green's function is defined as
\begin{equation}
	i G_{\alpha \beta} (x, x')
	\equiv \frac{\langle \Psi_0 | T[\hat \psi_{\text{H} \alpha} (x) \hat \psi^\dagger_{\text{H} \beta} (x')] |\Psi_0 \rangle}{\langle \Psi_0 |\Psi_0 \rangle}
\end{equation}
and gives the probability amplitude of a particle traveling from one point in space and time to another one. Here $ | \Psi_0 \rangle $ is the ground state vector in the Heisenberg picture, $ \hat \psi_{\text{H} \alpha}(x) $ is the $ \alpha $-th component of a field operator also in the Heisenberg picture, $ T[ \cdots ] $ orders the operators according to their time while $ x $ and $ x' $ are position-time four-vectors. This Green's function contains observable properties such as the ground state energy and the excitation spectrum of the system. Using the Lehman representation, the expectation value of any single-particle operator in the ground state of the system might also be extracted.

Above zero temperature, now working with an imaginary time $ \tau $, the Green's function of interest is the temperature Green's function. In the imaginary time and position representation, the corresponding single-particle temperature Green's function is defined through
\begin{equation}
	\Gt_{\alpha \beta} (x, x')
	\equiv \text{Tr} \big\{ \hat \rho_\text{G} \, T_\tau [\hat \psi_{\text{K} \alpha}(x) \hat \psi^\dagger_{\text{K} \alpha}(x') ] \big\} \,.
\end{equation}
Here $ \psi_{\text{K} \alpha}(x) $ is the $ \alpha $-th component of a field operator in the modified Heisenberg picture, $ T_\tau [\cdots] $ orders the operators according to their value of $ \tau $,  $ \text{Tr} \{ \rho_\text{G} \cdots \} $ is the same weighted sum of inner products as mentioned before while $ x $ and $ x' $ are position-imaginary time four-vectors. Since the temperature single-particle Green's function is not a function of time, it is only possible to directly extract from it observables which do not depend on time, that is, thermodynamic observables. In order to obtain time dependent properties, one must first relate the temperature Green's function to a real-time Green's function. This is something which will not be of importance to this thesis and thus will not be discussed any further. From here on only the finite temperature formalism will be considered and whenever a Green's function is mentioned it will be understood that the single-particle temperature Green's function is the one that is referred to.

Assuming the Hamiltonian is time independent and translationally invariant, the Green's function will depend only on the difference $ \vec x - \vec x' $ and $ \tau - \tau' $ as soon shall be shown. By further imposing spin independency onto the Hamiltonian, the spin dependency of the Green's function may be factored out as $ \Gt_{\alpha \beta}(\vec x - \vec x', \tau - \tau ') = \delta_{\alpha \beta} \, \Gt(\vec x - \vec x', \tau - \tau') $. Thus, from this point and forward, when referring to a Green's function the spin dependency will be omitted.

In the case of a cubic system with a finite volume $ V = l^3 $, accompanied by periodic boundary conditions, the single-particle wave functions 
\begin{equation}
	\psi_{\vec k} (\vec x) = \frac{e^{i \vec k \cdot \vec x}}{\sqrt V}
\end{equation}
correspond to eigenstates of the momentum operator with eigenvalues given by
\begin{equation}
	\label{eq:momentumQuantumNumbers}
	k_i = \frac{2\pi}{l} n_i
	\; ; \quad 
	n_i = 0, \, \pm 1, \, \pm 2, \dots \,.
\end{equation}
Constructing the field operators (\ref{eq:fieldOperator}) in terms of these, the expression for the Green's function may be transformed as
\begin{equation}
	\begin{split}
		\Gt (\vec x - \vec x', \tau - \tau ')
		&= \sum_{\vec k, \vec p} \psi_{\vec k}(\vec x) \psi^*{\vec p}(\vec x') \text{Tr} \big\{ \hat \rho_\text{G} \, T_\tau [\hat c_{\vec k}(\tau) \hat c^\dagger_{\vec p}(\tau ')] \big\} \\
		&= \sum_{\vec k, \vec p} \psi_{\vec k}(\vec x) \psi^*{\vec p}(\vec x') \delta_{\vec k, \vec p} \text{Tr} \big\{ \hat \rho_\text{G} \, T_\tau [\hat c_{\vec k}(\tau - \tau') \hat c^\dagger_{\vec k}(0)] \big\} \\
		&= \frac{1}{V} \sum_{\vec k} e^{i \vec k \cdot ( \vec x - \vec x' )} \text{Tr} \big\{ \hat \rho_\text{G} \, T_\tau [\hat c_{\vec k}(\tau - \tau') \hat c^\dagger_{\vec k}(0)] \big\} \\
		&= \int \frac{\diff^3k}{(2\pi)^3} e^{i \vec k \cdot ( \vec x - \vec x' )}  \text{Tr} \big\{ \hat \rho_\text{G} \, T_\tau [\hat c(\vec k, \tau - \tau') \hat c^\dagger(\vec k, 0)] \big\} \,,
	\end{split}
\end{equation}
where in the last equality the limit $ l \rightarrow \infty $ has been taken. In order to shift the time, the hermiticity of $ \hat K $ allowed for the trace to be expressed in terms of it's complete set of eigenstates $ \{ | \nu_{\vec k} \rangle \} $. Then, since the Hamiltonian is time independent it will commutate with itself at any two given times, implying that $ \exp \{ \hat K \tau - \hat K \tau' \} = \exp \{ \hat K \tau\} \exp \{- \hat K \tau' \} $. On the other hand, in the limit of an infinite system, the Green's function in momentum space is obtained through the Fourier transform
\begin{equation}
	\label{eq:defGpt}
	\Gt (\vec x, \tau) = \int \frac{\diff^3 k}{(2 \pi)^3} \,  e^{i \vec k \cdot \vec x} \, \Gt (\vec k, \tau) \,.
\end{equation}
Hence it must be the case that
\begin{equation}
	\label{eq:GptExpression}
	\Gt(\vec k, \tau) = \text{Tr} \big\{ \hat \rho_\text{G} \, T_\tau [\hat c(\vec k, \tau) \hat c^\dagger(\vec k, 0)] \big\} \,.
\end{equation}
Assuming the ground state ensemble to be the vacuum state, i.e\ $ \text{Tr}\{ \hat \rho_\text{G} \cdots \} \rightarrow \langle \text{vac} | \cdots | \text{vac} \rangle $, this expression further simplifies into
\begin{equation}
	\label{eq:GptExpressionVac}
	\Gt(\vec k, \tau) = \langle \text{vac} | \hat c(\vec k, \tau) \hat c^\dagger(\vec k, 0) | \text{vac} \rangle
	\; , \quad \tau \geq 0
\end{equation}
and is for all other imaginary times identically zero. 

In order to demonstrate some important properties of $ \Gt(\vec k, \tau) $ the unity operator $ \hat \eye = \sum_\nu | \nu \rangle \langle \nu | $, constructed in terms of the complete set of eigenstates $ \{ | \nu (\vec k) \rangle \} $ of the grand canonical Hamiltonian $ \hat K \, | \nu (\vec p) \rangle = \xi_\nu(\vec p) \, | \nu (\vec p) \rangle $, is inserted into expression (\ref{eq:GptExpressionVac}). By recalling that the annihilation operator in the modified Heisenberg picture (\ref{eq:modHeisPic}) is given by $ \hat c_{\vec k} (\tau) = e^{\hat K \tau} \, \hat c_{\vec k} (0) \, e^{- \hat K \tau} $ the expression then boils down to \cite{MishchenkoA.2000DqMC}
\begin{equation}
	\label{eq:startingPointFreePropagator}
	\Gt(\vec k, \tau) =
	\sum_\nu | \langle \nu | \hat c^\dagger_{\vec k} | \text{vac} \rangle |^2 e^{-(\xi_\nu - \xi_\text{vac})\tau}
	\; , \quad \tau \geq 0 \,.
\end{equation}
Here it is has been used that $ \xi_\text{vac} $ is the vacuum energy, i.e.\ $ \hat K \, | \text{vac} \rangle = \xi_\text{vac} \, | \text{vac} \rangle $. For the Fröhlich Hamiltonian to be considered later, $ \xi_\text{vac} = 0 $ and will therefore be ignored in the remaining calculation. Rather than working with some unknown set $ \{ \nu \} $, it is more convenient to parametrize using the frequency. This is done by introducing the spectral density function
 \begin{equation}
	g_{\vec{k}} (\omega)
	\equiv \sum_\nu \delta (\omega - \xi_\nu) \, | \langle \nu | \hat c^\dagger_{\vec k} | \text{vac} \rangle |^2 \,,
\end{equation}
through which the single-particle Green's function is expressed as
\begin{equation}
	\label{eq:GInTermsOfSpec}
	\Gt(\vec k, \tau) = \int g_{\vec k} (\omega) \, e^{- \omega \tau} \diff \omega
	\; , \quad \tau \geq 0 \,.
\end{equation}
Assuming the Green's function to be that of an electron ($ \hat c_{\vec k} \rightarrow \hat a_{\vec k} $), the factor $ | \langle \nu | \hat a^\dagger_{\vec k} | \text{vac} \rangle |^2 = | \langle \nu | \vec k \rangle |^2 $ is nothing more than the overlap of the eigenstate $ | \nu \rangle $ with the free electron state of momentum $ \vec k $. If there exist a stable eigenstate $  | \nu_{0, \vec k} \rangle $ with energy $ \xi_0(\vec k) $, the spectral function should contain the term $ | \langle \nu_{0, \vec k} | \vec k \rangle |^2 \, \delta(\omega - \xi_0(\vec k)) $. Being a stable state, the energy $ \xi_0(\vec k) $ is lower than the corresponding energy of any other possible eigenstate. According to (\ref{eq:GInTermsOfSpec}), at imaginary times $ \tau \rightarrow \infty $, the sole contribution to the single-particle Green's function should come from this stable state. That is,
\begin{equation}
	\label{eq:longTimeLimit}
	\Gt(\vec k, \tau \rightarrow \infty) = Z_0(\vec k) e^{- \xi_0(\vec k) \tau} \,,
\end{equation}
where $ Z_0(\vec k) = | \langle \nu_{0, \vec k} | \vec k \rangle |^2 $ is the bare-electron factor. The corresponding energy eigenvalue $ E_0 $ of the Hamiltonian $ \hat H $ is according to the definition of the grand canonical Hamiltonian given by
\begin{equation}
	E_0(\vec k) = \xi_0 (\vec k) + \mu \,.
\end{equation}
This because there is only one electron present in the system in the case of a single particle Green's function. Finally, since $ \hat H $ is independent of $ \mu $, this must also be true for $ E_0 $, which is the reason for this energy later being investigated rather than $ \xi_0 $.

\subsection{Bare single-particle Green's function}

An eigenstate to a bare Hamiltonian, e.g.\ $ \hat K_0 = \sum_{\vec k} \xi^0_{\vec k} \hat c^\dagger_{\vec k} \hat c_{\vec k} $, is referred to as either a bare or a free state. The energies $ \xi^0_{\vec k} $ are known from solving the corresponding problem in first-quantization. Reusing the previous assumptions and calculations, but $ \hat K $ every where replaced with $ \hat K_0 $, the bare Green's function in momentum space is found to be,
\begin{equation}
	\Gt^{(0)}(\vec k, \tau)
	= \sum_{\vec p} | \langle \vec p | \hat c^\dagger_{\vec k} | \text{vac} \rangle |^2 e^{-\xi^0_{\vec p} \tau}
	\quad \tau \geq 0 \,.
\end{equation}
However, this time the eigenstates are known, and using their orthonormality, the expression of the bare single-particle Green's function simplifies to
\begin{equation}
	\label{eq:freeProp}
	\Gt^{(0)}(\vec k, \tau)
	= e^{-\xi^0(\vec k)  \, \tau}
	\quad \tau \geq 0
\end{equation}
in the limit of an infinite system.

\section{Derivation of the Fröhlich Hamiltonian}

What will happen to a dielectric medium if one introduces a charged particle, and how will this particle react to changes in the dielectric medium? These are questions which Herbert Fröhlich answered in his 1954 paper \textit{Electrons in lattice fields} \cite{electronsInLatticeFields}. In this section the original derivation will be outlined with attention directed towards details important for the thesis.

\subsection{Classical picture}

Consider a diatomic crystal, e.g.\ rock salt. Such a crystal is made up out of ions which pairwise have a zero net charge as illustrated in figure \ref{fig:illustrationOfDiatomicCrystal}. By introducing a free electron into such a crystal, the crystal will become polarized due to the electric field exerted by the electron. The polarization is then described by a set of displacement vectors, one for each lattice point. In order to simplify what follows this set of displacement vectors are treated as a continuous vector field.

\begin{figure}[H]
	\centering
	\begin{subfigure}[c]{0.45\textwidth}
		\includegraphics[width=\textwidth]{{"Images/Crystal_illustration/description"}.pdf}
		\caption{The filled circles illustrate four types of charges. The color represent the charge sign; the ones to the left are positively charged and the ones to the right are negatively charged. The magnitude of charge is represented by the size; the charges have the same charge quantity within each row, but the ones in the top row have a weaker charge than the ones in the bottom row.}
	\end{subfigure}\hfill
	\begin{subfigure}[c]{0.45\textwidth}
		\includegraphics[width=\textwidth]{{"Images/Crystal_illustration/crystal"}.pdf}
		\caption{A layer of a diatomic crystal. This particular crystal has a face-centered cubic structure.}
	\end{subfigure}
	\caption{}
	\label{fig:illustrationOfDiatomicCrystal}
\end{figure}

If this system is first looked at in a steady state situation, the polarization is determined solely by the dielectric permittivity $ \epsilon_\text{r} $. A handy quantity is the electric displacement field (CGS units)
\begin{equation}
	\label{eq:DefDfield}
	\vec D = \vec E + 4 \pi \vec P = \epsilon \vec E
\end{equation}
where $ \vec E $ is the total electric field, $ \vec P $ is the polarization and $ \epsilon = \epsilon_\text{r} \epsilon_0 $ is the permittivity. Since the source of this field is given solely by the free electron, it may be thought of as an external electrical field. If the electron is at position $ \vec x_\text{e} $, the $ \vec D $-field at a position $ \vec x $ is given by the familiar expression
\begin{equation}
	\vec D( \vec x, \vec x_\text{e}) = - \nabla \frac{Q}{\left| \vec x - \vec x_\text{e} \right|} \,,
\end{equation}
so that
\begin{equation}
	\nabla \cdot \vec D( \vec x, \vec x_\text{e}) = 4 \pi q \, \delta(\vec x - \vec x_\text{e}) \,.
\end{equation}
Here $ Q $ is the charge of the electron and the second equality is to be thought of as valid only as a distribution. In agreement with the definition of the $ \vec D $-field the electric field due to the bound charges is defined as $ \vec E_\text{bound} = - 4 \pi \vec P $ since $ \vec D = \vec E + 4 \pi \vec P = \vec E - \vec E_\text{bound} \equiv \vec E_\text{free} $.

The interaction energy, which is minimized when the $ \vec D $-field is parallel to the polarization, is given by 
\begin{equation}
	\label{eq:interaction_energy}
	E_\text{int} = - \int_V \vec D(\vec x, \vec x_\text{e}) \cdot \vec P(\vec x) \diff^3 x \,.
\end{equation}
Introducing a scalar potential to the bound electric field, $ \vec E_\text{bound}= - \nabla \Phi $, this interaction energy may be re-expressed as 
\begin{equation}
	\label{eq:interaction_energy_calculation}
	%\resizebox{\hsize}{!}{$
	    	\begin{split}
    			E_\text{int} 
    			&= - \frac{1}{4 \pi} \int_\Omega \vec D(\vec x, \vec x_\text{e}) \cdot \nabla \Phi(\vec x) \diff^3 x \\
    			&= - \frac{1}{4 \pi} \int_{\Omega \setminus V_\varepsilon} \vec D(\vec x, \vec x_\text{e}) \cdot \nabla \Phi(\vec x) \diff^3 x
    				 - \frac{1}{4 \pi} \int_{V_\varepsilon} \vec D(\vec x, \vec x_\text{e}) \cdot \nabla \Phi(\vec x) \diff^3 x \\
    			&= - \frac{1}{4 \pi} \int_{\Omega \setminus V_\varepsilon} \nabla \cdot \left[ \Phi(\vec x) \vec D(\vec x, \vec x_\text{e}) \right] \diff^3 x
    				+ \underbrace{
    					\frac{1}{4 \pi} \int_{\Omega \setminus V_\varepsilon} \Phi(\vec x) \nabla \cdot \vec D(\vec x, \vec x_\text{e}) \diff^3 x
    				}_{0}
				\\[-1.1em]
    				&\qquad + \overbrace{
    					\frac{q}{4 \pi} \int_{V_{\varepsilon}'} \frac{1}{x^2} \frac{\partial \Phi(\vec x + \vec x_\text{e})}{\partial x}  \diff^3 x
    				}^{\rightarrow \, 0 \; \text{as} \; \varepsilon \, \rightarrow \, 0} \\
    			&= \frac{Q}{4 \pi} \int_{-\partial V_{\varepsilon}'} \Phi(\vec x + \vec x_\text{e}) \nabla \frac{1}{x} \cdot \diff^2 \vec{x} \\
    			&= Q \, \Phi(\vec x_\text{e})
    		\end{split}
    	%$}
\end{equation}
Here it has both been assumed that $ \Phi (\vec x) $ have a continuous first derivative as well as $ \allowbreak \Phi(\vec x) \vec D(\vec x, \vec x_\text{e}) \simeq 0 $ on the boundary $ \vec x \in \partial \Omega $. In order to use the divergence theorem, the singularity at $ \vec x_\text{e} $ was isolated in a spherical volume $ V_\varepsilon $ with radius  $ \varepsilon \rightarrow 0 $ centered at $ \vec x_\text{e} $.

From this point and onwards, a system in a steady state is no longer considered and hence the time dependence is brought back. However, the solution to the time dependent version of the model clearly must agree with the time independent quantities in the limit of steady state.

Since each lattice point in the crystal is occupied by a ion, the dynamics of the system is characterized by two time scales. That is, the time it takes to displace the bound electrons relative their nuclei (deformation of ion) and the time it takes to displace the nucleus relative the lattice (deformation of lattice structure). These two types of deformation are illustrated in figure \ref{fig:twoTypesOfPolrisation}. Since the bound electrons are significantly lighter than their nuclei, the ion deformation time is expected to be much smaller than the time it takes to deformation the lattice. Denoting these timescales as $ t_\text{uv} $ and $ t_\text{ir} $ respectively, this translates to $ t_\text{uv} \ll t_\text{ir} $ or  $ \omega_\text{uv} \gg \omega_\text{ir} $, where $ \omega \propto 1/t $ is the corresponding characteristic frequency. The subscripts of course indicate that frequencies lie in the ultraviolet and infrared region respectively. The total deformation, due to these two types of deformations, may then be expressed as $ \vec P = \vec P_\text{ir} + \vec P_\text{uv} $.
\begin{figure}[H]
        \centering
        \begin{subfigure}[b]{0.45\textwidth}
                \includegraphics[width=\textwidth]{{"Images/Crystal_illustration/uv_polarization"}.pdf}
                \caption{Deformation of the ions at a time $ t \approx t_\text{uv} $.}
        \end{subfigure}\hfill
        \begin{subfigure}[b]{0.45\textwidth}
                \includegraphics[width=\textwidth]{{"Images/Crystal_illustration/ir_polarization"}.pdf}
                \caption{Deformation of the lattice at a time $ t' \approx t_\text{ir} \gg t $.}
        \end{subfigure}
        \caption{}
        \label{fig:twoTypesOfPolrisation}
\end{figure}

It is reasonable to further assume that each type of polarization behave as a driven harmonic oscillator, that is
\begin{equation}
	\label{eq:driven_harmonic_oscillator}
	\ddot{ \vec P}_\text{ir} (\vec x) + \omega^2_\text{ir} \, \vec P_\text{ir} (\vec x) = \frac{ \vec D(\vec x, \vec x_\text{e})}{ \gamma }
	\; , \quad
	\ddot{ \vec P}_\text{uv} (\vec x) + \omega^2_\text{uv} \, \vec P_\text{uv} (\vec x) = \frac{ \vec D(\vec x, \vec x_\text{e})}{ \delta } \,.
\end{equation}
Here $ \gamma $ and $ \delta $ are constants to be determined using the steady state solution
\begin{equation}
	\label{eq:static_P_D_relation}
	4 \pi \vec P(\vec x) = (1 - 1/\epsilon) \vec D(\vec x, \vec x_\text{e}) \,,
\end{equation}
which follow from equation (\ref{eq:DefDfield}). However, since there are two unknowns to be solved for an additional relation is needed.

% At a frequency $ \omega_\infty $ of the external field $ \vec D $, satisfying $ \omega_\text{uv} \gg \omega_\infty \gg \omega_\text{ir} $, one has a time dependent relation $ \vec D = \epsilon_\infty \vec E $. Such a frequency corresponds in this model to a slowly moving electron


This second relation is the time-dependent high frequency response $ \vec D = \epsilon_\infty \vec E $, where the rate of change $ \omega_\infty $ of the external $ \vec D $-field satisfies $ \omega_\text{uv} \gg \omega_\infty \gg \omega_\text{ir} $. In the case of a free electron this criteria implies that the electron must be moving extremely slow compared to the UV timescale, but extremely quick compared to the IR timescale. Hence the UV-part of the polarization will manage to follow the changes in the $ \vec D $-field nearly adiabatically whilst the IR-part wont have time adapt to the changes. It is therefore reasonable to assume the latter contribution to be approximately constant as well as negligible in comparison to the former contribution, i.e.\ $ \vec P \simeq \vec P_\text{uv} $. Using this last approximation together with the relation of $ \vec D $ and $ \vec E $ through $ \epsilon_\infty $, one obtains in similarity to (\ref{eq:static_P_D_relation})
\begin{equation}
	\label{eq:static_Puv_D_relation}
	4 \pi \vec P_\text{uv} (\vec x) =  (1 - 1/\epsilon_\infty) \vec D(\vec x, \vec x_\text{e}) \,.
\end{equation}
By subtracting (\ref{eq:static_Puv_D_relation}) from (\ref{eq:static_P_D_relation}) a similar expression for $ \vec P_\text{ir} $ is found to be
\begin{equation}
	\label{eq:static_Pir_D_relation}
	4 \pi \vec P_\text{ir} (\vec x) =  (1/\epsilon_\infty - 1/\epsilon) \vec D(\vec x, \vec x_\text{e}) \,.
\end{equation}

Further implications of the current rate of change $ \omega_\infty $ are obtained by substituting $ \ddot{\vec P}_\text{uv} \approx \omega_\infty^2 \, \vec P_\text{uv} \ll \omega_\text{uv}^2 \, \vec P_\text{uv} $ and $ \dot{\vec P}_\text{ir} \approx 0 $ into (\ref{eq:driven_harmonic_oscillator}), which then simplifies to
\begin{equation}
	\omega^2_\text{ir} \, \vec P_\text{ir} (\vec x) = \frac{ \vec D(\vec x, \vec x_\text{e})}{ \gamma }
	\; , \quad
	\omega^2_\text{uv} \, \vec P_\text{uv} (\vec x) = \frac{ \vec D(\vec x, \vec x_\text{e})}{ \delta } \,.
\end{equation}
By finally comparing this equation to (\ref{eq:static_Puv_D_relation}) and (\ref{eq:static_Pir_D_relation}) the value of $ \gamma $ and $ \delta $, in terms of know material properties, are found to be
\begin{equation}
	\frac{1}{\gamma} = \frac{\omega_\text{ir}^2}{4 \pi} \left( \frac{1}{\epsilon_\infty} - \frac{1}{\epsilon} \right)
	\; , \quad
	\frac{1}{\delta} = \frac{\omega_\text{uv}^2}{4 \pi} \left( 1 - \frac{1}{\epsilon_\infty} \right) \,.
\end{equation}

Having formulated the equation of motion for the two types of polarization, the next task is to construct one for the free electron. Since the electron was assumed to be moving slowly, one may without hesitation treat it in the non-relativistic limit. Then the only force acting on the electron is due to the bound electric field, i.e.\ $ \vec F(\vec x_\text{e}) = q \vec E_\text{bound} (\vec x_\text{e}) = - q \nabla \Phi (\vec x_\text{e}) $. Thus $ m \ddot{\vec x}_\text{e} = \dot{\vec p}_\text{e} = - q \nabla \Phi (\vec x_\text{e}) $ where $ m $ is an effective mass which in general is different from the electronic mass $ m_\text{e} $. By treating $ \vec p_\text{e} $,  $ \vec P_\text{uv} (\vec x) $ and $ \vec P_\text{ir} (\vec x) $ as independent quantities, one may out of the equations of motion together with the interaction (\ref{eq:interaction_energy_calculation}) construct the Lagrangian
\begin{equation}
	\begin{split}
		L &= \frac{\gamma}{2} \int \left[ \dot{\vec P}_\text{ir}^2 (\vec x) - \omega_\text{ir}^2 \, \vec P_\text{ir}^2 (\vec x) \right] \diff^3 x
		+ \frac{\delta}{2} \int \left[ \dot{\vec P}_\text{uv}^2 (\vec x) - \omega_\text{uv}^2 \, \vec P_\text{uv}^2 (\vec x) \right] \diff^3 x \\
		&+ \int \vec D(\vec x, \vec x_\text{e}) \cdot \left[ \vec P_\text{ir}(\vec x) +  \vec P_\text{uv}(\vec x) \right] \diff^3 x
		+ \frac{\vec p_\text{e}^2}{2m} \,.
	\end{split}
\end{equation}
Performing a Legendre transformation, the Hamiltonian is found to be
\begin{equation}
	\label{eq:Hamiltonian_raw}
	\begin{split}
		H &= \frac{\gamma}{2} \int \left[ \dot{\vec P}_\text{ir}^2 (\vec x) + \omega_\text{ir}^2 \, \vec P_\text{ir}^2 (\vec x) \right] \diff^3 x
		+ \frac{\delta}{2} \int \left[ \dot{\vec P}_\text{uv}^2 (\vec x) + \omega_\text{uv}^2 \, \vec P_\text{uv}^2 (\vec x) \right] \diff^3 x \\
		&- \int \vec D(\vec x, \vec x_\text{e}) \cdot \left[ \vec P_\text{ir}(\vec x) +  \vec P_\text{uv}(\vec x) \right] \diff^3 x
		+ \frac{\vec p_\text{e}^2}{2m} \,.
	\end{split}
\end{equation}

Since the UV-part of the polarization follows the external field nearly adiabatically, the dynamic solution $ \vec P_\text{uv} $ is approximatively the statical one with respect to the $ \vec D $-field. Hence the contribution of $ \vec P_\text{uv} $ to the the Hamiltonian becomes constant so that it can be removed without affecting the dynamics, giving rise merely to an energy shift. Having removed $ \vec P_\text{uv} $ from the theory it is no longer necessary to keep the subscript of $ \vec P_\text{ir} $ and $ \omega_\text{ir} $ for differentiation purposes, therefore it is from here on omitted.

Before proceeding with the derivation, it is important to point out that the integrals in $ L $ and $ H $ are divergent. The reason for this is the polarization, which according to (\ref{eq:static_Puv_D_relation}) and (\ref{eq:static_Pir_D_relation}) is proportional to the $ \vec D $-field which in turn is singular at $ \vec x = \vec x_\text{e} $. This divergence is a consequence from disregarding the lattice structure when interpreting the displacements as a continuous vector field. If one where to calculate this integral, it would be necessary to express the polarization as a Fourier series and omit terms with a wave length smaller than that of the lattice constant.

At this point it is convenient to introduce here a complex vector field $ \vec B $,
\begin{equation}
	\label{eq:B_field_def}
	\vec B(\vec x) = \sqrt{\frac{\gamma \omega}{2}} \left[ \vec P(\vec x) + \frac{i}{\omega} \dot{\vec P}(\vec x) \right]
	\; , \quad
	\vec B^*(\vec x) = \sqrt{\frac{\gamma \omega}{2}} \left[ \vec P(\vec x) - \frac{i}{\omega} \dot{\vec P}(\vec x) \right] \,,
\end{equation}
so that
\begin{equation}
	\label{eq:inv_B_field_def}
	\vec P(\vec x) = \sqrt{\frac{1}{2 \omega \gamma}} \left[ \vec B^* (\vec x) + \vec B (\vec x) \right]
	\; , \quad
	 \dot{\vec P}(\vec x) = i \sqrt{\frac{\omega}{2 \gamma}} \left[ \vec B^* (\vec x) - \vec B (\vec x) \right] \,.
\end{equation}
The Hamiltonian, re-expressed in terms of this $ \vec B $-field, transform into
\begin{equation}
	H = \frac{\vec p_\text{e}^2}{2m}
	+ \omega \int \vec B^* (\vec x) \cdot \vec B (\vec x) \diff^3 x
	- \sqrt{\frac{1}{2 \gamma \omega}} \int \vec D(\vec x, \vec x_\text{e}) \cdot \left[ \vec B(\vec x) +  \vec B^*(\vec x) \right] \diff^3 x \,.
\end{equation}
By assuming the system to be cubic of size $ V = l^3 $, the $ \vec B $-field and its complex conjugate may each be expressed in terms of a Fourier series
\begin{equation}
	\label{eq:B_field_fourier}
	\vec B (\vec x) = \sum_{\vec q} \frac{\vec q}{q} \, b_{\vec q} \, \frac{e^{i \vec q \cdot \vec x}}{\sqrt V}
	\; , \quad
	\vec B^* (\vec x) = \sum_{\vec q} \frac{\vec q}{q} \, b^*_{\vec q} \, \frac{e^{-i \vec q \cdot \vec x}}{\sqrt V}
\end{equation}
where the wave vectors are given according to (\ref{eq:momentumQuantumNumbers}).
Next, by defining a scalar potential $ \Xi $ for the IR-part of the polarization as $ 4 \pi \vec P = \nabla \Xi $ it is according to (\ref{eq:interaction_energy_calculation}) possible to express the interaction energy between $ \vec D $ and $ \vec P $ as $ Q \, \Xi (\vec x_\text{e}) $. Using (\ref{eq:B_field_def}) and (\ref{eq:B_field_fourier}) together with $ \Xi $ the expression for the Hamiltonian then becomes
\begin{equation}
	H = \frac{\vec p_\text{e}^2}{2m}
	+ \omega \sum_{\vec q} b^*_{\vec q} b_{\vec q}
	+ \frac{1}{\sqrt V} \sum_{\vec q} V(q) \left[ b^*_{\vec q} \, e^{-i \vec q \cdot \vec x_\text{e}} - b_{\vec q} \, e^{i \vec q \cdot \vec x_\text{e}} \right] \,,
\end{equation}
where both
\begin{equation}
	\label{eq:VofQ}
	V(q) = i \left( 2 \sqrt 2 \pi \alpha \right)^{1/2} \left( \frac{\omega^3}{m} \right)^{1/4} \frac{1}{q}
\end{equation}
and the interaction parameter
\begin{equation}
	\alpha = \frac{1}{2} \left( \frac{1}{\epsilon_\infty} - \frac{1}{\epsilon} \right) \sqrt{ \frac{2m}{\omega} } Q^2
\end{equation}
has been introduced.

Here it seems as if the interaction part of the Hamiltonian is ill behaved since the $ \vec q = \vec 0 $ term clearly is singular. This is a consequence from the periodic boundary condition which was imposed when expressing $ \vec B $  as a Fourier series. Originally the system contained only a single free electron. With a periodic boundary condition however, the system now consists of an infinite number of copies of the cube with volume $ V $, each containing a free electron. These electrons interact with one another due to the long range Coulomb repulsion. To avoid this behavior when periodically continuing the system, one should introduce in each cube the uniform charge density $ - Q/V $. Doing so would give rise to an attractive Coulomb force which for each electron would cancel the Coulomb repulsion. Such an interaction would exactly cancel the ill behaved $ \vec q = \vec 0 $ term in the interaction part of the Hamiltonian, since the only difference would be the sign of the charge, i.e $ Q \rightarrow -Q $.

\subsection{Quantization}

In order to quantize the theory, it is of utter importance to construct a set of canonical coordinates $ p_i $ and $ q_i $ for which the commutation relations then are known. Using (\ref{eq:driven_harmonic_oscillator}) and (\ref{eq:Hamiltonian_raw}), it is easy to verify that $ \phi_i(\vec x, t)_i = [\vec P(\vec x, t)]_i $ and $ \pi_i(\vec x, t) = \gamma [ \dot{\vec P}(\vec x, t) ]_i $ obey Hamilton's field equations
\begin{equation}
	\dot \phi_i = \frac{\delta H}{\delta \pi_i}
	\; , \quad
	\dot \pi_i = - \frac{\delta H}{\delta \phi_i}
\end{equation}
and thus constitutes a set of canonical field coordinates. By then employing a restricted canonical transformation $ q_i = q_i(\vec \phi, \vec \pi), \, p_i = p_i (\vec \phi, \vec \pi) $, one obtains the following set of canonical coordinates
\begin{equation}
	\label{eq:pAndQ}
	q_{\vec k} = \sqrt{\frac{1}{2 \omega \gamma}} \left[ b^*_{\vec k} + b_{\vec k} \right]
	\; , \quad
	p_{\vec k} = i \sqrt{\frac{\gamma \omega}{2}} \left[ b^*_{\vec k} - b_{\vec k} \right] \,.
\end{equation}
It is pretty straight forward to verify that this is in fact true. Using (\ref{eq:inv_B_field_def}) and (\ref{eq:B_field_fourier}) together with the expressions for the sets of canonical coordinates one may express $ \vec \phi, \vec \pi $ in terms of $ q_{\vec k}, p_{\vec k} $ and vice versa,
\begin{equation}
	\begin{split}
		q_{\vec k} &= \frac{1}{\sqrt V} \int \frac{\vec k}{k} \cdot \left[ \frac{1}{\omega \gamma} \vec \pi (\vec x) \sin \vec k \cdot \vec x  + \vec \phi (\vec x) \cos \vec k \cdot \vec x\right] \diff^3 x \\
		p_{\vec k} &= \frac{1}{\sqrt V} \int \frac{\vec k}{k} \cdot \left[ \vec \pi (\vec x) \cos \vec k \cdot \vec x - \omega \gamma \, \vec \phi (\vec x) \sin \vec k \cdot \vec x \right] \diff^3 x \\
		\vec \phi (\vec x) &= \frac{1}{\sqrt{V}} \sum_{\vec k} \frac{\vec k}{k} \left[ q_{\vec k} \cos \vec k \cdot \vec x - \frac{1}{ \omega \gamma} p_{\vec k} \sin \vec k \cdot \vec x \right] \\
		\vec \pi (\vec x) &= \frac{1}{\sqrt V} \sum_{\vec k} \frac{\vec k}{k} \left[ \omega \gamma \, q_{\vec k} \sin \vec k \cdot \vec x +  p_{\vec k} \cos \vec k \cdot \vec x \right] \,.
	\end{split}
\end{equation}
Then, by showing that these coordinates satisfy the relations \cite{ClassicalMechanics}
\begin{equation}
	\begin{split}
		\left( \frac{\delta q_{\vec k}}{\delta \phi_i} \right)_{\vec \phi, \vec \pi} &= \left( \frac{\partial \pi_i}{\partial p_{\vec k}} \right)_{q, p} \\
		\left( \frac{\delta p_{\vec k}}{\delta \pi_i} \right)_{\vec \phi, \vec \pi} &=  \left( \frac{\partial \phi_i}{\partial q_{\vec k}} \right)_{q, p}
	\end{split}
	\qquad \qquad
	\begin{split}
		\left( \frac{\delta q_{\vec k}}{\delta \pi_i} \right)_{\vec \phi, \vec \pi} &= - \left( \frac{\partial \phi_i}{\partial p_{\vec k}} \right)_{q, p} \\
		\left( \frac{\delta p_{\vec k}}{\delta \phi_i} \right)_{\vec \phi, \vec \pi} &= - \left( \frac{\partial \pi_i}{\partial q_{\vec k}} \right)_{q, p}
	\end{split}
\end{equation}
proves that the transformation used, and the set of coordinates $ q_{\vec k}, p_{\vec k} $ obtained, both are canonical.


Before promoting these new coordinates to operators, once must symmetrize the product $ b_{\vec q}^* b_{\vec q} $. Up to this point, $ b_{\vec q}^* $ and $ b_{\vec q} $ have been complex valued variables so that the order in which they appeared in such a product does not matter. However, due to a nonzero commutation relation when promoted to operators, this will no longer be the case. In order to not favor any of the two possible orderings, they are chosen to contribute equally, i.e.\ $ b^*_{\vec q} b_{\vec q} = (b^*_{\vec q} b_{\vec q} + b_{\vec q} b^*_{\vec q})/2 $.

By promoting the canonical coordinates to operators and imposing Bose statistics onto $ \hat q_{\vec k}, \, \hat p_{\vec k} $, the commutation relations follow from the corresponding poisson bracket relations of classical mechanics, i.e.\
\begin{equation}
	\begin{split}
		\big\{ q_{\vec k}, \, p_{\vec p} \big\}_\text{PB} = \delta_{\vec k, \vec p}
		\; &\rightarrow \;
		\big[ \hat q_{\vec k}, \, \hat p_{\vec p} \big] = i \delta_{\vec k, \vec p} \\[1ex]
		\big\{ [\vec x_\text{e}]_i, \, [ \vec p_\text{e} ]_j \big\}_\text{PB} = \delta_{i, j}
		\; &\rightarrow \;
		\big[ [\hat{ \vec x}_\text{e}]_i, \, [ \hat{ \vec p}_\text{e} ]_j \big] = i \delta_{i, j} \,.
	\end{split}
\end{equation}
Substituting with (\ref{eq:pAndQ}) into the first of these equations, and using that $ [ \hat q_{\vec k}, \, \hat q_{\vec p} ] = [ \hat p_{\vec k}, \, \hat p_{\vec p} ] = 0 $, one is left with the relations $ [\hat b_{\vec k}, \, \hat b^\dagger_{\vec p}] = \delta_{\vec k, \vec p} $ and $ [\hat b_{\vec k}, \, \hat b_{\vec p}] = 0 $. Using these commutation relations the previously symmetrized terms of the Hamiltonian are rewritten as $ (\hat b^\dagger_{\vec q} \hat b_{\vec q} + \hat b_{\vec q} \hat b^\dagger_{\vec q})/2  = \hat b^\dagger_{\vec q} \hat b_{\vec q} + \tfrac{1}{2} $. The full Hamiltonian in quantized form then  becomes
\begin{equation}
	\hat H = \frac{\hat{\vec p}_\text{e}^2}{2m}
	+ \omega \sum_{\vec q} \hat b^\dagger_{\vec q} \hat b_{\vec q}
	+ \frac{1}{\sqrt V} \sum_{\vec q} V(q) \left( \hat b^\dagger_{\vec q} \, e^{-i \vec q \cdot \hat{\vec x}_\text{e}} - \hat b_{\vec q} \, e^{i \vec q \cdot \hat{\vec x}_\text{e}} \right) \,.
\end{equation}
where the zero point energy $ \omega \sum_{\vec q} \tfrac{1}{2} $ of the oscillating ions have been omitted.

The commutation relations satisfied by $ \hat b^\dagger_{\vec q} $ and $ \hat b_{\vec q} $ are the same as (\ref{eq:boseOperators}), implying that these operators are nothing but the creation and annihilation operators of a bosonic field. The polarization field $ \vec P $ can then be tough of as being represented by a set of harmonic oscillators each corresponding to a quantized mode of vibration in the lattice, i.e.\ a phonon. Since the frequency of the phonons is momentum independent they are said to be dispersionless. For optical phonons which couple to infrared radiation, this is at low momenta a good approximation as shown in figure \ref{fig:phononDispersionRelation}.
\begin{figure}[H]
	\centering
 	\includegraphics[width=0.4\textwidth, ]{{"Images/Dispersion_relation/dispersion_relation"}.pdf}
	\caption{The upper and lower curves illustrate the characteristics of an optical and acoustic dispersion relation respectively. The outlined orange region suggests were the optical dispersion relation may be well approximated as momentum independent.}
	\label{fig:phononDispersionRelation}
\end{figure}
Having sorted out the quantization of the $ \vec B $-field, the attention is turned towards the electron which not yet has undergone second-quantization. In order to achieve this, the recipe (\ref{eq:O1toO2}) is used which translates an one-body operator from first to second-quantization. By using the allowed momenta (\ref{eq:momentumQuantumNumbers}) as occupation numbers for the electron state, one obtains
\begin{equation}
	\begin{split}
		\frac{\hat{\vec p}_\text{e}^2}{2m} &\rightarrow \sum_{\vec p} \frac{p^2}{2m} \hat a^\dagger_{\vec p} \hat a_{\vec p} \,, \\[1em]
		e^{-i \vec q \cdot \hat{ \vec x}_\text{e}} 
		& \rightarrow
		\sum_{\vec k, \vec p} \langle \vec k | e^{-i \vec q \cdot \hat{ \vec x}_\text{e}} | \vec p \rangle \hat a^\dagger_{\vec k} \hat a_{\vec p} \\
		& = \sum_{\vec k, \vec p} \langle \vec k |
			\left[ \int | \vec x \rangle \langle \vec x | \diff^3 x \right]
			e^{-i \vec q \cdot \hat{ \vec x}_\text{e}}
			\left[ \int | \vec y \rangle \langle \vec y | \diff^3 y \right]
			| \vec p \rangle \hat a^\dagger_{\vec k} \hat a_{\vec p} \\
		& = \sum_{\vec k, \vec p} \hat a^\dagger_{\vec k} \hat a_{\vec p}
			\int \diff^3 x \;
			\frac{e^{- i \vec k \cdot \vec x}}{\sqrt{V}} \,
			e^{-i \vec q \cdot \vec x} \,
			 \frac{e^{i \vec p \cdot \vec x}}{\sqrt{V}} \\
		& = \sum_{\vec k, \vec p} \hat a^\dagger_{\vec k} \hat a_{\vec p}
			\; \delta( \vec k + \vec q - \vec p) \\
		& = \sum_{\vec p} \hat a^\dagger_{\vec p - \vec q} \hat a_{\vec p}
	\end{split}
\end{equation}
and similarly
\begin{equation}
	e^{i \vec q \cdot \hat{ \vec x}_\text{e}} \rightarrow \sum_{\vec p} \hat a^\dagger_{\vec p + \vec q} \hat a_{\vec p} \,.
\end{equation}
Substituting with this into the Hamiltonian and using that interaction term is symmetric with respect to $ \vec q $, the fully second-quantized Hamiltonian becomes
\begin{equation}
	\label{eq:finalHamiltonian}
	\hat H
	= \sum_{\vec p} \frac{p^2}{2m} \hat a^\dagger_{\vec p} \hat a_{\vec p}
	+ \omega \sum_{\vec q} \hat b^\dagger_{\vec q} \hat b_{\vec q}
	+ \frac{1}{\sqrt V} \sum_{\vec q, \vec p} V (q) \left( \hat b^\dagger_{\vec q} - \hat b_{- \vec q} \right) \hat a^\dagger_{\vec p - \vec q} \hat a_{\vec p} \,.
\end{equation}
The grand canonical Hamiltonian $ \hat K $, which is used extensively in finite temperature field theory, is obtained by adding chemical potentials to $ \hat H $. But since there is no conservation law regarding the number of phonons it must be the case that $ \mu_\text{phonon} = 0 $. Thus
\begin{equation}
	\label{eq:finalGrandCanoniclaHamiltonian}
	\hat K
	= \sum_{\vec p} \left( \frac{p^2}{2} - \mu \right) \hat a^\dagger_{\vec p} \hat a_{\vec p}
	+ \sum_{\vec q} \hat b^\dagger_{\vec q} \hat b_{\vec q}
	+ \frac{1}{\sqrt V} \sum_{\vec q, \vec p} V (q) \left( \hat b^\dagger_{\vec q} - \hat b_{- \vec q} \right) \hat a^\dagger_{\vec p - \vec q} \hat a_{\vec p}
\end{equation}
where for convenience $ m = \omega = 1 $ has been used.

\section{Perturbation theory}

Assume the Hamiltonian to be time-independent in the Schrödinger picture and expressible as the sum $ \hat K = \hat K_0 + \hat K_1 $, where $ \hat K_1 $ contains the interactions of the theory without which the problem would be exactly solvable. If this interaction is weak enough, it is reasonable to treat it perturbatively by expanding with respect to some small interaction parameter $ \alpha $. In order to do so it is necessary to introduce yet a new picture, the interaction picture. In the finite temperature formalism, operators in the interaction picture are related to the ones in the Schrödinger picture through $ \hat O_\text{I} (\tau) = e^{\hat K_0 \tau} \, \hat O_\text{S} \, e^{-\hat K_0 \tau} $. Within this picture, it is possible to express the ensemble average of a $ \tau $-ordered product of operators by the perturbation series
\begin{equation}
	\label{eq:perturbationSeries}
	\begin{gathered}
		\text{Tr} \{ \hat \rho_\text{G} \, T_\tau [\hat A_\text{K}(\tau_a) \, \hat B_\text{K}(\tau_b) \, \cdots \, \hat F_\text{K}(\tau_f) ] \} \\
		= \\
\resizebox{\textwidth}{!}{$
		\frac{
			\sum_{n=0}^\infty \frac{(-1)^n}{n!} \int_0^\beta \diff \tau_1 \cdots \int_0^\beta \diff \tau_n \, 
			\text{Tr} \left\{ e^{- \beta \hat K_0} T_\tau [\hat K_1 (\tau_1) \cdots \hat K_1 (\tau_n) \, \hat A(\tau_a) \, \hat B(\tau_b) \, \cdots \, \hat F(\tau_f)] \right\}
		}{
			\sum_{n=0}^\infty \frac{(-1)^n}{n!} \int_0^\beta \diff \tau_1 \cdots \int_0^\beta \diff \tau_n \,
			\text{Tr} \left\{ e^{- \beta \hat K_0} T_\tau [\hat K_1 (\tau_1) \cdots \hat K_1 (\tau_n)] \right\}
		} \,.
$}
	\end{gathered}
\end{equation}
In both the nominator and denominator of the expression above, there is the frequently appearing factor
\begin{equation}
	\label{eq:bareStatcalEnsembleAverage}
	\text{Tr} \{ e^{-\beta \hat K_0 } T_\tau [ \hat A \, \hat B \cdots\,  \hat F] \} \,.
\end{equation}
It was first proved by Matsubara \cite{Matsubara} that this factor could be rewritten as the sum of all possible permutations of contractions $ \hat A^\cdot \hat B^\cdot \equiv \text{Tr} \{ \hat \rho_{\text{G}0} \, T_\tau [ \hat A \,\hat B ] \} $ amongst the product of operators $ \hat A \hat B \cdots \hat F $. Here $ \hat \rho_{\text{G}0} $ is the bare statistical operator, defined in accordance with $ \hat \rho_\text{G} $ but having the full Hamiltonian replaced by the noninteracting part only. In the case of a creation and an annihilation operator, the contraction
\begin{equation}
	\hat c_{\vec k} (\tau) ^\cdot \, \hat c^\dagger_{\vec k} (\tau') ^\cdot
	= \text{Tr} \{ \hat \rho_{\text{G}0} \, T_\tau [ \hat c_{\vec k} (\tau) \, \hat c^\dagger_{\vec k} (\tau') ] \}
	= \Gt^{(0)}(\vec k, \tau)
\end{equation}
is nothing but the definition of the bare propagator in momentum space (\ref{eq:GptExpression}). All other types of contractions amongst such operators turn out to be zero, i.e.\
\begin{equation}
	\hat c_{\vec k}(\tau)^\cdot \, \hat c_{\vec k}(\tau')^\cdot
	= \hat c^\dagger_{\vec k}(\tau)^\cdot\, \hat c^\dagger_{\vec k}(\tau')^\cdot
	= \hat c_{\vec k}(\tau)^\cdot \, \hat c^\dagger_{\vec p}(\tau')^\cdot
	= 0
	\quad \forall \quad
	\vec k \neq \vec p \,.
\end{equation}
Hence only a small part of all terms in (\ref{eq:bareStatcalEnsembleAverage}) survive, and these are the ones which may be represented pictorially in terms of Feynman diagrams. Further more the denominator of (\ref{eq:perturbationSeries}) will serve to precisely cancel out any unconnected diagram part from the nominator. What is left of the perturbations series is then an infinite number of connected Feynman diagrams which are easily constructed from a set of Feynman rules.

\subsection{Diagrammatic analysis}

The constituents of the resulting Feynman diagrams are easily obtained just by analyzing the Hamiltonian (\ref{eq:finalGrandCanoniclaHamiltonian}). In case of the vacuum ground state, the bare electronic and phononic propagators, referred to as $ \Gt^{(0)} $ and $ \Dt^{(0)} $ respectively, are given according to (\ref{eq:freeProp}) and represented as
\begin{fmffile}{FMFFILEelectronPropagator}
	\begin{empheq}[box={\FDbox[0pt][0pt]}]{equation}
		\label{eq:G0ofKt}
		\begin{tikzpicture}[baseline={([yshift=-.5ex]current bounding box.center)}]
			\node {
				\FDframe[4][5][4][5]{
					\begin{fmfgraph*}(25, 1.5)
				\fmfleft{i}
				\fmfright{o}
				\fmf{fermion, label=$\vec p$}{i,o}
				\fmfv{label=$ 0 $, label.angle=-180}{i}
				\fmfv{label=$ \tau $, label.angle=0}{o}
					\end{fmfgraph*}%
				}%
			};
		\end{tikzpicture}
		=  \, 
		\Gt^{(0)}(\vec p, \tau)
		= \exp \left \{ -\left( \frac{p^2}{2} - \mu \right) \tau \right \}
		\quad \tau \geq 0 \,,
	\end{empheq}
\end{fmffile}%
\begin{fmffile}{FMFFILEelectronPropagatorphononPropagator}
	\begin{empheq}[box={\FDbox[0pt][0pt]}]{equation}
		\label{eq:D0ofKt}
		\begin{tikzpicture}[baseline={([yshift=-.5ex]current bounding box.center)}]
			\node {
				\FDframe[4][5][4][5]{
					\begin{fmfgraph*}(25, 1.5)
				\fmfleft{i}
				\fmfright{o}
				\fmf{dashes, label=$\vec q$}{i,o}
				\fmfv{label=$ 0 $, label.angle=-180}{i}
				\fmfv{label=$ \tau $, label.angle=0}{o}
					\end{fmfgraph*}%
				}%
			};
		\end{tikzpicture}
		=  \, 
		\Dt^{(0)}(\vec q, \tau)
		= \exp \left \{ - \tau \right \}
		\quad \tau \geq 0 \,.
	\end{empheq}
\end{fmffile}%
Since any propagator going backwards in time is identically zero, it is possible to use the convention that the momentum is carried in the direction of increased time, which throughout this paper will be towards the right. Then, by examining the interaction part of the Hamiltonian, the possible vertices and their contribution are found out to be
\begin{fmffile}{FMFFILEelectronPropagatorvertices}
	\begin{empheq}[box={\FDbox[0pt][0pt]}]{equation}
		\begin{tikzpicture}[baseline={([yshift=-.5ex]current bounding box.center)}]
			\node {
				\FDframe[0][0][0][5]{
					\begin{fmfgraph*}(47, 19)
				\fmfstraight
				\fmfleft{i1,i2}
				\fmfright{o1,o2}
				\fmf{fermion, label=$\vec p$}{i1,v1}
				\fmf{fermion, label=$\vec p - \vec q$}{v1,o1}
				\fmf{dashes, tension=0, left=0.36, label=$\vec q$}{v1,o2}
				\fmfdot{v1}
					\end{fmfgraph*}%
				}%
			};
		\end{tikzpicture}
		=
		\begin{tikzpicture}[baseline={([yshift=-.5ex]current bounding box.center)}]
			\node {
				\FDframe[0][0][0][5]{
					\begin{fmfgraph*}(47, 19)
				\fmfstraight
				\fmfleft{i1,i2}
				\fmfright{o1,o2}
				\fmf{fermion, label=$\vec p - \vec q$}{i1,v1}
				\fmf{fermion, label=$\vec p$}{v1,o1}
				\fmf{dashes, tension=0, right=0.36, label=$\vec q$}{v1,i2}
				\fmfdot{v1}
					\end{fmfgraph*}%
				}%
			};%
		\end{tikzpicture}
		= \frac{V(\vec q)}{\sqrt V}
	\end{empheq}
\end{fmffile}%
with $ V(\vec q) $ as defined in (\ref{eq:VofQ}).

In this thesis only the electronic single-particle Green's function will be studied in terms of Feynman diagrams. Hence the operators $ \hat A \, \hat B \, \cdots \, \hat F $ in the perturbation series (\ref{eq:perturbationSeries}) are replaced by $ \hat a_{\vec p} \hat a^\dagger_{\vec p} $ as to coincide with the definition (\ref{eq:GptExpression}) of $ \Gt(\vec p, \tau) $. In order to construct the relevant diagrams, the Feynman rules \cite{quantumTheoryOfManyParticleSystems} dictate:
\begin{enumerate}
	\item Draw all topologically distinct diagrams with $ 2n + 1 $ electron lines and $ n $ phonon lines.
	\item With each particle line associate a factor $ \Gt^{(0)} $ in case of an electron, and $ \Dt^{(0)} $ in case of a phonon.
	\item Each vertex contributes with the factor $ V(\vec q) / \sqrt V $, where $ \vec q $ is the momentum of the phonon connected to this vertex.
	\item Conserve the total momentum at every vertex.
	\item The external legs should both be assigned the external momentum $ \vec p $ of the interacting Green's function $ \Gt(\vec p, \tau) $. The ingoing external leg should start at the imaginary time $ 0 $ and the outgoing external leg should terminate at $ \tau $.
	\item For each of the $ n $ internal momenta, sum over all allowed momentum values.
	\item For each of the $ n $ internal imaginary times, integrate from $ 0 $ to $ \beta $.
	\item Multiply each diagram with the factor $ (-1)^n $.
\end{enumerate}
In this thesis the single-particle Green's function will be studied in the limit $ V \rightarrow \infty $ and $ T \rightarrow 0 $. Hence the sums over internal momenta should be replaced according to
\begin{equation}
	\frac{1}{V} \sum_{\vec k} \cdots \rightarrow \int \frac{\diff^3k}{(2\pi)^3} \cdots \,,
\end{equation}
and the upper bound of the imaginary time integrals $ \beta \rightarrow \infty $.

Because the propagators being identically zero for negative imaginary times, there is no contribution from diagrams containing tadpoles, electron loops or similar structures. This is illustrated in figure \ref{fig:vanishingContributions}.
\begin{figure}[H]
	\begin{fmffile}{FMFFILEtadpoleAndLoop}
		\begin{empheq}[box={\FDbox[0pt][0pt]}]{equation*}
			\begin{tikzpicture}[baseline={([yshift=-.5ex]current bounding box.center)}]
				\node {
					\FDframe[1][5][33][0]{
						\begin{fmfgraph*}(25, 22)
							\fmfleft{i}
							\fmfright{o}
							\fmf{dashes}{i,v1}
							\fmf{fermion, tension=0.2, right}{v1,o,v1}
							\fmfdot{v1}
							\fmfv{label=$ \propto \langle \text{vac} | \hat a^\dagger \hat a | \text{vac} \rangle = 0 $, label.angle=0}{o}
						\end{fmfgraph*}%
					}%
				};
			\end{tikzpicture}
			\quad \qquad
			\begin{tikzpicture}[baseline={([yshift=-.5ex]current bounding box.center)}]
				\node {
					\FDframe[1][5][1][0]{
						\begin{fmfgraph*}(46, 22)
				\fmfleft{i}
				\fmfright{o}
				\fmf{dashes, tension=2}{i,v1}
				\fmf{dashes, tension=2}{v2,o}
				\fmf{fermion, right, tension=0.8}{v1,v2}
				\fmf{fermion, right, tension=0.8, label=$ \Gt^{(0)}(\tau - \tau' < 0) = 0 $}{v2,v1}
				\fmfdot{v1,v2}
				\fmfv{label=$ \tau $, label.angle=-120}{v1}
				\fmfv{label=$ \tau' $, label.angle=-60}{v2}
						\end{fmfgraph*}%
					}%
				};%
    			\end{tikzpicture}
		\end{empheq}
	\end{fmffile}%
	\caption{A tadpole and an electron loop both of which are equal to zero due to the ground state ensemble of vacuum.}
	\label{fig:vanishingContributions}
\end{figure}
The only contributing diagrams are then those where all electron propagators follow after one another in a line, and phonon propagators spawn and die on the vertices on that line. That is,
\begin{fmffile}{FMFFILEGUpToSecondOrder}
	\begin{empheq}[box={\FDbox[0pt][0pt]}]{equation}
	\label{eq:GinTermsOfDiagrams}
		\begin{split}
			\Gt(\vec p, \tau)
			&=
			\begin{tikzpicture}[baseline={([yshift=15]current bounding box.south)}]
				\node {
					\FDframe[4][0][4][5]{
						\begin{fmfgraph*}(20, 5)
					\fmfstraight
					\fmfbottom{i,o}
					\fmf{fermion, label=$\vec p$, label.side=left}{i,o}
					\fmfv{label=$ 0 $, label.angle=-180}{i}
					\fmfv{label=$ \tau $, label.angle=0}{o}
						\end{fmfgraph*}%
					}%
				};%
			\end{tikzpicture}
			+
			\begin{tikzpicture}[baseline={([yshift=15]current bounding box.south)}]
				\node {
					\FDframe[4][5][4][5]{
						\begin{fmfgraph*}(60, 10)
					\fmfstraight
					\fmfbottom{i,o}
        					\fmf{fermion, label=$\vec p$, label.side=left}{i,v1}
        					\fmf{fermion, label=$\vec p - \vec q$, label.side=left}{v1,v2}
        					\fmf{fermion, label=$\vec p$, label.side=left}{v2,o}
        					\fmf{dashes,  label=$\vec q$, left, tension=0}{v1,v2}
        					\fmfv{label=$ \tau_1 $, label.angle=-90}{v1}
        					\fmfv{label=$ \tau_2 $, label.angle=-90}{v2}
        					\fmfv{label=$ 0 $, label.angle=-180}{i}
        					\fmfv{label=$ \tau $, label.angle=0}{o}
        					\fmfdot{v1,v2}
						\end{fmfgraph*}%
					}%
				};%
			\end{tikzpicture} \\
			&+
			\begin{tikzpicture}[baseline={([yshift=15]current bounding box.south)}]
				\node {
					\FDframe[4][5][4][5]{
						\begin{fmfgraph*}(100, 10)
					\fmfstraight
					\fmfbottom{i,o}
        					\fmf{fermion, label=$\vec p$, label.side=left}{i,v1}
        					\fmf{fermion, label=$\vec p - \vec q$, label.side=left}{v1,v2}
        					\fmf{fermion, label=$\vec p$, label.side=left}{v2,v3}
        					\fmf{fermion, label=$\vec p - \vec k$, label.side=left}{v3,v4}
        					\fmf{fermion, label=$\vec p$, label.side=left}{v4,o}
        					\fmf{dashes,  label=$\vec q$, left, tension=0}{v1,v2}
        					\fmf{dashes,  label=$\vec k$, left, tension=0}{v3,v4}
        					\fmfv{label=$ \tau_1 $, label.angle=-90}{v1}
        					\fmfv{label=$ \tau_2 $, label.angle=-90}{v2}
        					\fmfv{label=$ \tau_3 $, label.angle=-90}{v3}
        					\fmfv{label=$ \tau_4 $, label.angle=-90}{v4}
        					\fmfv{label=$ 0 $, label.angle=-180}{i}
        					\fmfv{label=$ \tau $, label.angle=0}{o}
        					\fmfdot{v1,v2,v3,v4}
						\end{fmfgraph*}%
					}%
				};%
			\end{tikzpicture} \\
			&+
			\begin{tikzpicture}[baseline={([yshift=15]current bounding box.south)}]
				\node {
					\FDframe[4][5][4][5]{
						\begin{fmfgraph*}(100, 20)
					\fmfstraight
					\fmfbottom{i,o}
        					\fmf{fermion, label=$\vec p$, label.side=left}{i,v1}
        					\fmf{fermion, label=$\vec p - \vec q$, label.side=left}{v1,v2}
        					\fmf{fermion, label=$\vec p - \vec q - \vec k$, label.side=left}{v2,v3}
        					\fmf{fermion, label=$\vec p - \vec k$, label.side=left}{v3,v4}
        					\fmf{fermion, label=$\vec p$, label.side=left}{v4,o}
        					\fmf{dashes,  label=$\vec q$, left, tension=0}{v1,v3}
        					\fmf{dashes,  label=$\vec k$, left, tension=0}{v2,v4}
        					\fmfv{label=$ \tau_1 $, label.angle=-90}{v1}
        					\fmfv{label=$ \tau_2 $, label.angle=-90}{v2}
        					\fmfv{label=$ \tau_3 $, label.angle=-90}{v3}
        					\fmfv{label=$ \tau_4 $, label.angle=-90}{v4}
        					\fmfv{label=$ 0 $, label.angle=-180}{i}
        					\fmfv{label=$ \tau $, label.angle=0}{o}
        					\fmfdot{v1,v2,v3,v4}
						\end{fmfgraph*}%
					}%
				};%
			\end{tikzpicture} \\
			&+
			\begin{tikzpicture}[baseline={([yshift=15]current bounding box.south)}]
				\node {
					\FDframe[4][5][4][5]{
						\begin{fmfgraph*}(100, 30)
					\fmfstraight
					\fmfbottom{i,o}
        					\fmf{fermion, label=$\vec p$, label.side=left}{i,v1}
        					\fmf{fermion, label=$\vec p - \vec q$, label.side=left}{v1,v2}
        					\fmf{fermion, label=$\vec p - \vec q - \vec k$, label.side=left}{v2,v3}
        					\fmf{fermion, label=$\vec p - \vec q$, label.side=left}{v3,v4}
        					\fmf{fermion, label=$\vec p$, label.side=left}{v4,o}
        					\fmf{dashes,  label=$\vec q$, left, tension=0}{v1,v4}
        					\fmf{dashes,  label=$\vec k$, left, tension=0}{v2,v3}
        					\fmfv{label=$ \tau_1 $, label.angle=-90}{v1}
        					\fmfv{label=$ \tau_2 $, label.angle=-90}{v2}
        					\fmfv{label=$ \tau_3 $, label.angle=-90}{v3}
        					\fmfv{label=$ \tau_4 $, label.angle=-90}{v4}
        					\fmfv{label=$ 0 $, label.angle=-180}{i}
        					\fmfv{label=$ \tau $, label.angle=0}{o}
        					\fmfdot{v1,v2,v3,v4}
						\end{fmfgraph*}%
					}%
				};%
			\end{tikzpicture} \\
			&+ \cdots \,.
		\end{split}
	\end{empheq}
\end{fmffile}%
It is obvious that the contribution from each diagram is nonzero only when the times are ordered chronologically, i.e. $ 0 = \tau_0 \le \tau_1 \le \tau_2 \le \dots \le \tau_{2n - 1} = \tau $. Because if this was not the case at least one propagator would propagate backwards in time. Thus it is only meaningful to carry out the integrals such that this chronologization constraint is fulfilled.

Another important property of these diagrams is that they all carry a positive definite contribution to $ \Gt $. This since the value of a propagator always is larger than or equal to zero, and the sign from the factor $ (-1)^n $ cancel the $ i^{2n} $ contained within $ V(\vec q)^{2n} $.

Since the Hamiltonian is isotropic, there will be no preferred direction of momenta. Hence the single particle Green's function will only be dependent on the magnitude of the external momentum $ p = |\vec p | $, i.e.\ $ \Gt = \Gt(\alpha, \mu, p, \tau) $.

\subsection{Dyson equation}

Working at zero temperature allows for a full Fourier representation of the single-particle Green's function, i.e.
\begin{equation}
	G(\vec x, \tau) = \frac{1}{(2\pi)^4} \int \diff^3 k \int \diff \omega \, e^{i (\vec k \cdot \vec x - \omega \tau)} G(\vec k, \omega)
	\; ; \quad G = \Gt, \, \Dt, \, \Gt^{(0)}, \, \Dt^{(0)} \,.
\end{equation}
It so happens to be more pleasant working in $ \vec k $-$ \omega $ space for a lot of reasons, but what will be of importance here is the conservation of total four momentum $ k = (\omega, \vec k) $ at all vertices in a Feynman diagram. In that way the external legs of a diagram no longer depend upon any internal variables and may therefore be factored out from the nasty integral expression. Hence it is convenient to express the interacting single-particle Green's function, here depicted as a double line, in terms of the self-energy $ \Sigma(k) $ as
\begin{fmffile}{FMFFILEGinTermsOfSelfEnergy}
	\begin{empheq}[box={\FDbox[0pt][0pt]}]{equation}
	\label{eq:boldLine}
		\begin{tikzpicture}[baseline={([yshift=-.5ex]current bounding box.center)}]
			\node {
				\FDframe{
					\begin{fmfgraph*}(19, 12)
			\fmfleft{i}
			\fmfright{o}
			\fmf{heavy, label=$ k $, label.side=left}{i,o}
					\end{fmfgraph*}%
				}%
			};
		\end{tikzpicture}
		=
		\begin{tikzpicture}[baseline={([yshift=-.5ex]current bounding box.center)}]
			\node {
				\FDframe{
					\begin{fmfgraph*}(19, 12)
			\fmfleft{i}
			\fmfright{o}
			\fmf{fermion, label=$ k $, label.side=left}{i,o}
					\end{fmfgraph*}%
				}%
			};%
		\end{tikzpicture}
		+
		\begin{tikzpicture}[baseline={([yshift=-.5ex]current bounding box.center)}]
			\node {
				\FDframe{
					\begin{fmfgraph*}(53, 12)
			\fmfleft{i}
			\fmfright{o}
			\fmf{fermion, label=$ k $, label.side=left}{i,v1}
			\fmf{fermion, label=$ k $, label.side=left}{v1,o}
			\fmfv{d.sh=circle,d.f=empty,d.si=.2w,l=$\Sigma(k)$,l.dist=0,decoration.size=.2w}{v1}
					\end{fmfgraph*}%
				}%
			};%
		\end{tikzpicture} \,,
	\end{empheq}
\end{fmffile}%
where then
\begin{fmffile}{FMFFILEselfEnergy}
	\begin{empheq}[box={\FDbox[0pt][0pt]}]{equation}
		\begin{split}
		\label{eq:selfEnergy}
			\begin{tikzpicture}[baseline={([yshift=0]current bounding box.south)}]
				\node {
					\FDframe[0][0][0][-6]{
						\begin{fmfgraph*}(12, 12)
					\fmfiv{d.sh=circle,d.f=empty,d.si=1w,l=$\Sigma(k)$,l.dist=0,right=0.5h}{c}
						\end{fmfgraph*}%
					}%
				};
			\end{tikzpicture}
			&=
			\begin{tikzpicture}[baseline={([yshift=1pt]current bounding box.south)}]
				\node {
					\FDframe[0][5][0][0]{
						\begin{fmfgraph*}(22, 11)
					\fmfstraight
					\fmfbottom{i,o}
					\fmf{fermion, label=$ k - q $, label.side=left}{i,o}
					\fmf{dashes, label=$q$, label.side=left, left}{i,o}
					\fmfdot{i,o}
						\end{fmfgraph*}%
					}%
				};%
			\end{tikzpicture}
			+
			\begin{tikzpicture}[baseline={([yshift=1pt]current bounding box.south)}]
				\node {
					\FDframe[0][5][0][0]{
						\begin{fmfgraph*}(66, 11)
					\fmfstraight
        					\fmfbottom{i,o}
					\fmf{fermion, label=$ k - q $, label.side=left}{i,v1}
					\fmf{dashes, label=$q$, label.side=left, left, tension=0}{i,v1}
					\fmf{fermion, label=$ k $, label.side=left}{v1,v2}
					\fmf{fermion, label=$ k - s $, label.side=left}{v2,o}
					\fmf{dashes, label=$s$, label.side=left, left, tension=0}{v2,o}
					\fmfdot{i,o,v1,v2}
						\end{fmfgraph*}%
					}%
				};%
			\end{tikzpicture} \\
			&+
			\begin{tikzpicture}[baseline={([yshift=1pt]current bounding box.south)}]
				\node {
					\FDframe[0][5][0][0]{
						\begin{fmfgraph*}(66, 22)
					\fmfstraight
        					\fmfbottom{i,o}
					\fmf{fermion, label=$ k - q $, label.side=left}{i,v1}
					\fmf{dashes, label=$q$, label.side=left, left, tension=0}{i,v2}
					\fmf{fermion, label=$ k - q - s$, label.side=left}{v1,v2}
					\fmf{fermion, label=$ k - s $, label.side=left}{v2,o}
					\fmf{dashes, label=$s$, label.side=left, left, tension=0}{v1,o}
					\fmfdot{i,o,v1,v2}
						\end{fmfgraph*}%
					}%
				};%
			\end{tikzpicture} \\
			&+
			\begin{tikzpicture}[baseline={([yshift=1pt]current bounding box.south)}]
				\node {
					\FDframe[0][5][0][0]{
						\begin{fmfgraph*}(66, 33)
					\fmfstraight
        					\fmfbottom{i,o}
					\fmf{fermion, label=$ k - q $, label.side=left}{i,v1}
					\fmf{dashes, label=$q$, label.side=left, left, tension=0}{i,o}
					\fmf{fermion, label=$ k -q - s $, label.side=left}{v1,v2}
					\fmf{fermion, label=$ k - q $, label.side=left}{v2,o}
					\fmf{dashes, label=$s$, label.side=left, left, tension=0}{v1,v2}
					\fmfdot{i,o,v1,v2}
						\end{fmfgraph*}%
					}%
				};%
			\end{tikzpicture}
			+ \cdots \,.
		\end{split}
	\end{empheq}
\end{fmffile}%
A related quantity is the proper self-energy $ \Sigma^*(k) $, which is made up by a subset of the self-energy diagrams. These diagrams are said to be irreducible, meaning that they cannot be split in two by cutting only one propagator. Examples of such diagrams are the first, third and fourth diagram in (\ref{eq:selfEnergy}). The second diagram in the same expression can be split in half by cutting the electronic propagator with four-momenta $ k $ and is then said to be a reducible diagram. With this definition of the proper self-energy, the self-energy is nothing but
\begin{fmffile}{FMFFILEselfEnergyInTermsOfProperSelfEnergy}
	\begin{empheq}[box={\FDbox[0pt][0pt]}]{equation}
		\label{eq:selfEnergyInTermsOfProperSelfEnergy}
		\begin{tikzpicture}[baseline={([yshift=-.5ex]current bounding box.center)}]
			\node {
				\FDframe{
					\begin{fmfgraph*}(12, 12)
				\fmfiv{d.sh=circle,d.f=empty,d.si=1w,l=$\Sigma(k)$,l.dist=0,right=0.5h}{c}
					\end{fmfgraph*}%
				}%
			};
		\end{tikzpicture}
		=
		\begin{tikzpicture}[baseline={([yshift=-.5ex]current bounding box.center)}]
			\node {
				\FDframe{
					\begin{fmfgraph*}(12, 12)
				\fmfiv{d.sh=circle,d.f=empty,d.si=1w,l=$\Sigma^*(k)$,l.dist=0}{c}
					\end{fmfgraph*}%
				}%
			};%
		\end{tikzpicture}
		+
		\begin{tikzpicture}[baseline={([yshift=-.5ex]current bounding box.center)}]
			\node {
				\FDframe[0][6][0][6]{
					\begin{fmfgraph*}(12, 24)
				\fmftop{o}
				\fmfbottom{i}
				\fmf{fermion, label=$ k $, label.side=left}{i,o}
				\fmfv{d.sh=circle,d.f=empty,d.si=1w,l=$\Sigma^*(k)$,l.dist=0}{i}
				\fmfv{d.sh=circle,d.f=empty,d.si=1w,l=$\Sigma^*(k)$,l.dist=0}{o}
					\end{fmfgraph*}%
				}%
			};%
		\end{tikzpicture}
		+
		\begin{tikzpicture}[baseline={([yshift=-.5ex]current bounding box.center)}]
			\node {
				\FDframe[0][6][0][6]{
					\begin{fmfgraph*}(12, 49)
				\fmftop{o}
				\fmfbottom{i}
				\fmf{fermion, label=$ k $, label.side=left}{i,v1}
				\fmf{fermion, label=$ k $, label.side=left}{v1,o}
				\fmfv{d.sh=circle,d.f=empty,d.si=1w,l=$\Sigma^*(k)$,l.dist=0}{i}
				\fmfv{d.sh=circle,d.f=empty,d.si=1w,l=$\Sigma^*(k)$,l.dist=0}{v1}
				\fmfv{d.sh=circle,d.f=empty,d.si=1w,l=$\Sigma^*(k)$,l.dist=0}{o}
					\end{fmfgraph*}%
				}%
			};%
		\end{tikzpicture}
		+
		\begin{tikzpicture}[baseline={([yshift=-.5ex]current bounding box.center)}]
			\node {
				\FDframe[0][6][0][6]{
					\begin{fmfgraph*}(12, 73)
				\fmftop{o}
				\fmfbottom{i}
				\fmf{fermion, label=$ k $, label.side=left}{i,v1}
				\fmf{fermion, label=$ k $, label.side=left}{v1,v2}
				\fmf{fermion, label=$ k $, label.side=left}{v2,o}
				\fmfv{d.sh=circle,d.f=empty,d.si=1w,l=$\Sigma^*(k)$,l.dist=0}{i}
				\fmfv{d.sh=circle,d.f=empty,d.si=1w,l=$\Sigma^*(k)$,l.dist=0}{v1}
				\fmfv{d.sh=circle,d.f=empty,d.si=1w,l=$\Sigma^*(k)$,l.dist=0}{v2}
				\fmfv{d.sh=circle,d.f=empty,d.si=1w,l=$\Sigma^*(k)$,l.dist=0}{o}
					\end{fmfgraph*}%
				}%
			};%
		\end{tikzpicture}
		+ \cdots \,.
	\end{empheq}
\end{fmffile}%
By inserting (\ref{eq:selfEnergyInTermsOfProperSelfEnergy}) into (\ref{eq:boldLine}), factoring out $ \Gt^{(0)}(k) \, \Sigma^*(k) $ from every diagram but the bare propagator and identifying what is left with $ \Gt(k) $, one obtains a self consistent expression for $ \Gt(k) $ known as Dyson's equation,
\begin{fmffile}{FMFFILEDysonEquation}
	\begin{empheq}[box={\FDbox[0pt][0pt]}]{equation}
		\begin{tikzpicture}[baseline={([yshift=-.5ex]current bounding box.center)}]
			\node {
				\FDframe{
					\begin{fmfgraph*}(19, 12)
			\fmfleft{i}
			\fmfright{o}
			\fmf{heavy, label=$ k $, label.side=left}{i,o}
					\end{fmfgraph*}%
				}%
			};
		\end{tikzpicture}
		=
		\begin{tikzpicture}[baseline={([yshift=-.5ex]current bounding box.center)}]
			\node {
				\FDframe{
					\begin{fmfgraph*}(19, 12)
			\fmfleft{i}
			\fmfright{o}
			\fmf{fermion, label=$ k $, label.side=left}{i,o}
					\end{fmfgraph*}%
				}%
			};%
		\end{tikzpicture}
		+
		\begin{tikzpicture}[baseline={([yshift=-.5ex]current bounding box.center)}]
			\node {
				\FDframe{
					\begin{fmfgraph*}(53, 12)
			\fmfleft{i}
			\fmfright{o}
			\fmf{heavy, label=$ k $, label.side=left}{i,v1}
			\fmf{fermion, label=$ k $, label.side=left}{v1,o}
			\fmfv{d.sh=circle,d.f=empty,d.si=.2w,l=$\Sigma^*(k)$,l.dist=0,decoration.size=.2w}{v1}
					\end{fmfgraph*}%
				}%
			};%
		\end{tikzpicture} \,.
	\end{empheq}
\end{fmffile}%
Hence the equation for $ \Gt(k) $ in terms of $ \Gt^{(0)}(k) $ and $ \Sigma^*(k) $ becomes
\begin{equation}
	\label{eq:dysonEquation}
	\Gt(k) = \frac{1}{1/\Gt^{(0)}(k) - \Sigma^*(k)} \,.
\end{equation}


\section{Monte Carlo Methods}

The Monte Carlo method \cite{Binder, NewmanBarkema} studies models of systems by stochastic computer simulations. Such a simulation rely on repeated sampling of (pseudo-)random numbers in order to obtain results for models which in principle might be either deterministic or stochastic. In physics-related problems this method is often used in order to sample a sequence of states of a physical system whose probability is given in accordance to a model Hamiltonian. Expectation values of interest may then be approximated by appropriately constructed sample means.

Usually the state space of the system at hand is too large to fully cover during a Monte Carlo simulation which will lead to statistical noise in calculated system properties. A lot of this noise may be suppressed by sampling states which represent the system well. This is known as importance sampling.



\subsection{Markov processes, detailed balance and ergodicity}

In order to sample states of a system a Markov process is used. Given an initial state $ x $ such a process will generate a new state $ x' $ on random, that is, if the Markov process repeatedly was given the state $ x $ the new state $ x' $ would not be the same every time. The probability $ P(x | x') $ of generating a state $ x' $ given $ x $ is referred to as a transition probability. In order to be a Markov process there are two criteria which the transition probabilities must fulfill; they are not allowed to change with time and they may only depend on the properties of the current states $ x $ and $ x' $. During the course of a Monte Carlo simulation the Markov process is repeatedly fed the system state in order to generate a sequence of states. When the simulation have run for a long enough time, the frequency for which a particular state is generated will converge to a distribution corresponding to the design of the transition probabilities. When this has happened one say that the process has reached an equilibrium and the distribution has become stationary. However, in order for the succession of generated states to match the pursued probability distribution when equilibrium has been reached, it is necessary that the conditions of ergodicity and detailed balance are satisfied.

Starting with the condition of ergodicity, this is the requirement that the Markov process should be able to reach any state of the system in a finite simulation time when starting from any other state. This is equal to saying that there must be at least one path of non-zero transition probabilities between any two states. This is illustrated in figure \ref{fig:stateSpaceIllustration}. If the process would not be ergodic, some states would never be sampled, no matter how long the simulation was running. The equilibrium distribution of the Markov process would then be such that some states would have a zero probability mass, which in general would not agree with the true distribution of the simulated physical system.
\begin{figure}[H]
        \centering
        \begin{subfigure}[b]{0.5\textwidth}
                \includegraphics[width=\textwidth]{{"Images/State_space_illustration/state-space-connected"}.pdf}
        \end{subfigure}\hfill
        \begin{subfigure}[b]{0.45\textwidth}
                \includegraphics[width=\textwidth]{{"Images/State_space_illustration/state-space-disconnected"}.pdf}
        \end{subfigure}
        \caption{Illustrated is a state space consisting of the five possible states A, B, C, D and E, for which two Markov processes are constructed. For these processes all transitions which have a non-zero probability are depicted with an arrow. It is then clear that the Markov process to the left satisfy ergodicity whilst the one to the right does not.}
        \label{fig:stateSpaceIllustration}
\end{figure}

Detailed balance on the other hand, is the requirement that the net flow of probability between any two states is exactly zero, i.e.\
\begin{equation}
	\label{eq:detailedBalance}
	P(x) \, P(x|x') = P(x') \, P(x'|x)
\end{equation}
where $ P(x) $ is the probability of the system being in state $ x $. Imposing such a condition on the transition probabilities it can be shown \cite{NewmanBarkema} that the Markov process must approach a simple equilibrium for which the stationary distribution is $ \pi (x) $. Hence dynamics such a limit cycles are forbidden by this condition.

\subsection{Metropolis-Hastings algorithm} \label{section:MEA}

The Metropolis-Hastings algorithm is a Markov chain Monte Carlo method for obtaining a sequence of random samples from a probability distribution for which direct sampling would be difficult. Briefly speaking, this algorithm is able to draw samples from any distribution $ P(x) $ given that it is possible to compute the value of a function $ f(x) $ which is proportional to the probability density function $ \rho(x) $ of the distribution $ P(x) $. The Metropolis-Hastings algorithm suggests constructing transition probabilities $ P(x|x') $ in order to design a Markov process for which the stationary distribution $ \pi(x) $ is chosen to be $ P(x) $.

The starting point to derive the Metropolis-Hastings algorithm is to separate the transitional probabilities into two parts; the proposal $ W(x|x') $ and acceptance-rejection $ A(x|x') $. Here $ W(x|x') $ is the conditional probability distribution of proposing a state $ x' $ given a state $ x $ and similarly $ A(x|x') $ is the conditional probability distribution of accepting the proposed state $ x' $ given $ x $. Expressing the transitional probability as a product of these two parts, i.e.\ $ P(x|x') = W(x|x') \, A(x|x') $, the criteria of detailed balance (\ref{eq:detailedBalance}) is re-expressed as
\begin{equation}
	\frac{A(x|x')}{A(x'|x)} = \frac{P(x)}{P(x')} \frac{W(x'|x)}{W(x|x')} \,.
\end{equation}
In order to fulfill the condition above, it is common to use the Metropolis choice for the acceptance,
\begin{equation}
	\label{eq:acceptanceRatio}
	A(x|x')
	= \text{min}\left( 1, \, \frac{P(x)}{P(x')} \frac{W(x'|x)}{W(x|x')} \right)
	= \text{min}\left( 1, \, \frac{f(x)}{f(x')} \frac{W(x'|x)}{W(x|x')} \right) \,,
\end{equation}
where the proportionality between the density of $ P $ and $ f $ has been used in order to reach the last equality. The new state $ x' $ is then accepted according to $ A(x|x') $. In practice this is achieved by sampling a uniform random number $ a \in [0, 1] $ and accepting the proposed transition if $ A(x|x') > a $, otherwise the transition is rejected. In case of the proposed state $ x' $ being rejected, the current state $ x $ is to be thought of as having been sampled yet again.

In order for the Markov process to cover as much of state space as possible, it is important to construct the proposal distributions in such a way that the acceptance ratios become as large as possible. If this is not the case the process will spend an unnecessary amount of time being rejected leaving the current state. This is how importance sampling manifest itself in the case of the Metropolis-Hastings algorithm.

