% !TEX root = ../thesis.tex

\todo{Here we shall summarize what this chapter is about}

\section{General idea}

\todo{"The diagrammatic Monte Carlo (DMC) method [1] is a
technique that allows one to simulate quantities specified
in terms of convergent diagrammatic sums, i.e., sums of
integrals with integrands represented by a diagrammatic
structure"}

\todo{In thermal equilibrium}

Diagrammatic Monte Carlo (from here on abbreviated DMC) is a numerical method developed by Prokof'ev et al. \cite{MishchenkoA.2000DqMC} in order to calculate quantities $ Q(\{ y \}) $, given in terms of a series of integrals with an ever increasing number of integration variables
\begin{equation}
	\label{eq:integralSeries}
	Q(\{ y \})
	= \sum_{n=0}^\infty \sum_{\xi_n} \int \diff x_1 \dots \diff x_n \, D_n(\xi_n, \, \{y\}, \, x_1, \, \dots , \, x_n) \,.
\end{equation}
Here $ \{y\} $ is a set of external variables and $ \xi_n $ indexes the different terms of order $ n $ which are given by the function $ D_n $. Terms corresponding to $ n = 0 $ are understood as being known functions of the external variables. In case of a discrete internal variable $ x_i $, the corresponding integral is exchanged in favor of a sum.

The method is based on the Metropolis-Hastings algorithm which samples terms of the integral series in the $ (\xi_n, \, \{y\}, \, x_1, \, \dots , \, x_n) $ parameter space. That is, a random walk is preformed between the different integrands in the integral series, as well as between the possible values of the integration variables. In this random walk it is also permissible to include one or more of the external variables. Since the terms at $ n = 0 $ are known functions it is then possible to calculate the value of $ Q $ by keeping track of the frequency by which these terms are sampled, as well as the length of the sequence of sampled terms.

To clarify any ambiguities, the DMC method will next be demonstrated by a few simple examples.

\subsection{Example 1}

In this example the task is to compute $ 1 + C $, where for convenience it is assumed that $ C > 1 $ is a constant. The integral series (\ref{eq:integralSeries}) will then consist out of two constant zeroth order terms only, making the parameter space discrete with the two possibilities $ \xi_0 = 0 $ and $ \xi_0 = 1 $ corresponding to the terms $ 1 $ and $ C $ respectively. Hence this is probably the simplest possible implementation of DMC and will make for a good first encounter.

\todo{The function $ D_n $ here play the role of $ f $ in the previous section about the MH algorithm.}

To follow the recipe of the Metropolis-Hastings algorithm, the function $ f $ is defined as being nothing but $ D_0(\xi_0) $ from (\ref{eq:integralSeries}). By this definition $ f $ becomes proportional to the probability density function 

\begin{equation}
	\rho(x) = \frac{f(x)}{\sum_y f(y)} = \frac{f(x)}{1 + C}
	\; ; \quad
	x \in \{1\,, C \} \,,
\end{equation}
from whose probability distribution function $ P $ the sequence of $ \xi_0 $'s will be drawn. Further more there can be at most four types of transitions between the two states in parameter space. By introducing the corresponding transition probabilities: $ P(1|C) $, $ P(C|1) $, $ P(1|1) $ and $ P(C|C) $, the Markov process \question{(is this the correct word?)} to be simulated may then be illustrated as in figure (\ref{fig:example1}) below.

\begin{figure}[H]
	\centering
 	\includegraphics[width=0.9\textwidth, ]{{"Images/Examples/First example"}.pdf}
	\caption{\todo{Caption this plz!}}
	\label{fig:example1}
\end{figure}

To simplify matters, the proposal distributions $ W(1|C) $, $ W(1|1) $, $ W(C|1) $ and $ W(C|C) $ are all chosen to have the same probability of $ 1/2 $. Then, according to (\ref{eq:acceptanceRatio}), the acceptance-rejection ratios will be given by $ A(1|1) = A(1|C) = A(C|C) = 1 $ and $ A(C|1) = 1/C $. By keeping track of how many times $ \xi_0 = 0 $ appears in the generated sequence, lets say $ N_0 $ times, as well as the the total length $ N $ of the sequence, it is possible to calculate $ 1 + C $. This since
\begin{equation}
	\label{eq:example1Prop}
	N_0 \propto \rho(1) \propto 1
	\; , \quad
	N - N_0 \propto \rho(C) \propto C
	\quad \Rightarrow \quad
	\frac{N_0}{N - N_0} = \frac{1}{C}
\end{equation}
so that
\begin{equation}
	\label{eq:example1Answ}
	1 + C = 1 + \frac{N - N_0}{N_0} \,.
\end{equation}

\todo{Include an implementation written in python?}

\subsection{Example 2}

In this second example the task is to compute the sum $ 1 + \int_a^b x \diff x $.

\todo{the only unknown here is the value of the integral. The $ 1 $ is solely used for normalization purposes.}

Instead of having of having two zeroth order terms as in the first example, there is now a zeroth and first order term. This implies that the parameter space is no longer completely discrete with merely two possible states. Similarly to the first example, the zeroth order term is still represented in parameter space by the state $ \xi_0 = 0 $. On the other hand, the first order term corresponds to the infinite number of states $ (\xi_1 = 0, \, x \in [a, \, b]) $. This notation of the states in parameter space is a little cumbersome, however, by assuming $ b > a > 1 $ it is possible to create a one-to-one mapping which maps $ \xi_0 = 0 $ and $ (\xi_1 = 0, \, x \in [a, \, b]) $ onto $ x = 1 $ and $ x \in [a, \, b] $ respectively. Using this notation, a function $ f $ is defined by
\begin{equation}
	f(x) =
	\begin{dcases}
		D_0(\xi_0 = 0) = 1 \; , \quad &x = 1 \\
		D_1(\xi_1 = 0, x) = x \; , \quad &x \in [a, \, b] \,,
   	\end{dcases}
\end{equation}
and thus becomes proportional to the probability density
\begin{equation}
	\rho(x)
	= \frac{f(x)}{\sum_y \rho(y)}
	= \frac{f(x)}{1 + \int_a^b x \diff x}
	\; ; \quad
	x \in \{1\} \cup [a, \, b] \,.
\end{equation}

In order to cover the whole parameter space, it is more than sufficient to consider four types of transitions having the transition probabilities $ P(1|1) $, $ P(1|x) $, $ P(x|1) $ and $ P(x|x') $. Here it is understood that $ x, x' \in [a, \, b] $ and thus corresponds to a state of the first order term. This Markov process might be illustrated as figure \ref{fig:example2} below.

\begin{figure}[H]
	\centering
 	\includegraphics[width=\textwidth, ]{{"Images/Examples/Second example"}.pdf}
	\caption{\todo{Caption this plz!}}
	\label{fig:example2}
\end{figure}

In order to construct proposal distributions to or from the first order term, it is convenient to introduce the collection of states referred to as $ \smallint $, in which all states $ x \in [a, \, b] $. Using this notation, the proposal distributions are chosen to be
\begin{equation}
	\begin{split}
		W(1|1) &= \tfrac{1}{2} \\
		W(x|1) &= W(\smallint | 1) = \tfrac{1}{2}
	\end{split}
	\quad \quad
	\begin{split}
		W(1|x) &= W(1 | \smallint) \, U_{a,b}(x) = \tfrac{1}{2} \tfrac{1}{b-a} \\
		W(x|x') &= W(\smallint | \smallint) \,U_{a,b}(x') = \tfrac{1}{2} \tfrac{1}{b-a} \,.
	\end{split}
\end{equation}
The quantities $ W(1|1) $, $ W(1|\smallint) $, $ W(\smallint | 1) $ and $ W(\smallint | \smallint) $ are simply the probability of proposing a state corresponding to a certain term in the integral series and have been set equally probable. The quantity $ U_{a,b}(x) = [b - a]^{-1} $ is the uniform probability distribution on the interval $ [a, \, b] $ from which $ x $ is sampled. Then, from the proposal distributions follow the acceptance rations
\begin{equation}
	\begin{split}
		A(1|1) &= 1 \\
		A(x|1) &= \text{min} \Big( 1, \,  [b - a]^{-1} \, x^{-1} \Big) \\
	\end{split}
	\quad \quad
	\begin{split}
		A(1|x) &= \text{min} \Big( 1, \,  [b - a] \, x \Big) \\
		A(x|x') &= \text{min} \Big( 1, \, x^{-1} \, x' \Big) \,.
	\end{split}
\end{equation}

By keeping track of the $ N_0 $ number of times $ x = 1 $ appears in the sequence of states and also the length $ N $ of the sequence, it follows from (\ref{eq:example1Prop}) and (\ref{eq:example1Answ}) that
\begin{equation}
	1 + \int_a^b x \diff x = 1 + \frac{N - N_0}{N_0} \,.
\end{equation}

\subsection{Example 3}

In this third and final example, the task is to compute something which is more similar to the actual problem. Hence, the sum to compute is of the form,
\begin{equation}
	1 + \int_{a}^{b} \diff x \, e^{-x} + \int_{a'}^{b'} \diff y \int_{a''}^{b''} \diff z \, e^{-y -z} \,,
\end{equation}
and consists of a zeroth, first and second order term. By assuming that $ b > a > 1 $, a similar one-to-one mapping of the states in parameter space as used in the previous example may also be used here. Again the zeroth and first order terms are chosen to be represented by $ x = 1 $ and $ x \in [a, \, b] $ respectively, whilst the second order term is to be represented by $ x = (y, z) \in [a', \, b'] \times [a'', \, b''] $. In terms of this parameter $ x $, the function $ f $ is defined as
\begin{equation}
	f(x) =
	\begin{dcases}
		D_0(\xi_0 = 0) = 1 \; , \quad &x = 1 \\
		D_1(\xi_1 = 0, x) = e^{-x} \; , \quad &x \in [a, \, b] \\
		D_2(\xi_2 = 0, x) = e^{-y - z} \; , \quad &x \in [a', \, b'] \times [a'', \, b''] \,.
   	\end{dcases}
\end{equation}
By normalization a probability density function $ \rho $ is obtained whose probability distribution $ P $ and seven types of transitions form a Markov process illustrated in figure \ref{fig:example3}.

\begin{figure}[H]
	\centering
 	\includegraphics[width=0.8\textwidth, ]{{"Images/Examples/Third example"}.pdf}
	\caption{\todo{Caption this plz!}}
	\label{fig:example3}
\end{figure}

In order to construct transition probabilities it is convenient to introduce the collection of states $ \smallint $ and $ \smallint \!\! \smallint $. These contain all states in parameter space corresponding the first and second order term respectively. The transition probabilities are then chosen as
\begin{equation}
	\begin{split}
		W(1|x) &= W(1|\smallint) \, U_{a,b}(x) \\
		W(x|1) &= W(\smallint|1) \\
		W(y,z|x) &= W(\smallint \!\! \smallint | \smallint) \, U_{a,b}(x) \\
		W(x|x') &= W(\smallint | \smallint) \,U_{a,b}(x') \,,
	\end{split}
	\quad \quad
	\begin{split}
		W(x|y,z) &= W(\smallint | \smallint \!\! \smallint) \, U_{a',b'}(y) \, U_{a'',b''}(z) \\
		W(y,z|y',z) &= W(\smallint \!\! \smallint | \smallint \!\! \smallint) \, W(\smallint \!\! \smallint | y') \, U_{a',b'}(y') \\
		W(y,z|y,z') &= W(\smallint \!\! \smallint | \smallint \!\! \smallint) \, \, W(\smallint \!\! \smallint | z') \, U_{a'',b''}(z') \\
		\;
	\end{split}
\end{equation}
where
\begin{equation}
	\begin{split}
		W(1|\smallint) &= 1 \\
		W(\smallint | 1) &= W(\smallint | \smallint) = W(\smallint | \smallint \!\! \smallint) = \tfrac{1}{3} \\
		W(\smallint \!\! \smallint | \smallint) &= W(\smallint \!\! \smallint | \smallint \!\! \smallint) = W(\smallint \!\! \smallint | y') = W(\smallint \!\! \smallint | z') = \tfrac{1}{2} \,.
	\end{split}
\end{equation}
The discrete proposal distributions $ W(\smallint \!\! \smallint | y') $ and $ W(\smallint \!\! \smallint | z') $ correspond to choosing to update either the $ y $ or the $ z $ part of the state $ x $. Having all of this information it is then trivial to calculate the acceptance ratios, which become
\begin{equation}
	\begin{split}
		W(1|x) &= \text{min} \Big(1, \, \tfrac{1}{3} [b - a] \, e^{-x} \Big) \\
		W(x|1) &= \text{min} \Big(1, \, 3 \, [b - a]^{-1} \, e^{x} \Big) \\
		W(x|x') &= \text{min} \Big(1, \, e^{x - x'} \Big) \\
		W(x|y,z) &=\text{min} \Big(1, \, \tfrac{2}{3} [b' - a'][b'' - a''][b - a]^{-1} \, e^{x - y - z} \Big) \\
		W(y,z|x) &= \text{min} \Big(1, \, \tfrac{3}{2} [b' - a']^{-1}[b'' - a'']^{-1}[b - a] \, e^{y + z - x} \Big) \\
		W(y,z|y',z) &= \text{min} \Big(1, \, e^{y - y'} \Big) \\
		W(y,z|y,z') &= \text{min} \Big(1, \, e^{z - z'} \Big) \,.
	\end{split}
\end{equation}
By defining $ N_0 $ and $ N $ in accordance to what was done in the previous example, the value of the sum is obtained by
\begin{equation}
	1 + \int_{a}^{b} \diff x \, e^{-x} + \int_{a'}^{b'} \diff y \int_{a''}^{b''} \diff z \, e^{-y -z}
	= 1 + \frac{N - N_0}{N_0} \,.
\end{equation}

\section{Implementation}

The task at hand is now to implement the DMC method in order to calculate the electronic single-particle Green's function $ \Gt(\alpha, \mu, \vec p, \tau) $. The integral series (\ref{eq:integralSeries}) will then be nothing but the diagrammatic series (\ref{eq:GinTermsOfDiagrams}), with the external parameters $ \{ y \} = \{ \alpha, \mu, \vec p, \tau \} $. The integration variables $ x_i $'s must therefore correspond to the internal imaginary-times and momenta, where the internal momenta are chosen to be those of the phonon propagators. By then representing the internal momenta in spherical coordinates $ \vec q = (q \sin \theta \cos \varphi, q \sin \theta \sin \varphi, q \cos \theta) $, the momentum integrals should be replaced according to
\begin{equation}
	\int \frac{\diff^3 q}{(2 \pi)^3}
	\rightarrow
	\int \limits_{q=0}^\infty \int \limits_{\theta=0}^{\pi} \int \limits_{\varphi=0}^{2\pi} \frac{q^2 \sin \theta \diff q \diff \theta \diff \varphi}{(2 \pi)^3} \,.
\end{equation}
The beauty of this is realized when recalling that each phonon brings with it a factor $ V(q)^2 \propto q^{-2} $, whose momentum dependence exactly cancel with that of the integral. For example, the expression corresponding the first order diagram then becomes
\begin{equation}
	-
	\int \limits_{0}^{\tau} \diff \tau_2
	\int \limits_{0}^{\tau_2} \diff \tau_1
	\int \limits_0^\infty \diff q
	\int \limits_0^\pi \diff \theta
	\int \limits_0^{2 \pi} \diff \varphi
	\, \Gt_0(\vec p, \tau_1)
	\Gt_0(\vec p - \vec q, \tau_2 - \tau_1)
	\tilde \Dt_0(\vec q, \tau_2 - \tau_1)
	\Gt_0(\vec p, \tau - \tau_2) \,,
\end{equation}
where $ \tilde \Dt_0(\vec q, \tau) $ is a phonon propagator which has absorbed the factor $ q^2 \sin \theta  \, (2\pi)^{-3} $ originating from the integral, the interaction potential $ V(q)^2 $ along with the factor $ -1 $ from the Feynman rules. Thus
\begin{equation}
	\tilde \Dt_0(\vec q, \tau)
	=
	\frac{2\sqrt 2 \pi \alpha}{(2\pi)^3} \sin \theta \, \exp \{ - \tau\}
\end{equation}
which is a quantity always larger than or equal to zero. The integrand of each and every integral in the integral series will be entirely made up out of $ \Gt_0 $'s and $ \tilde \Dt_0 $'s which implies that every contribution to $ \Gt $ is a positive contribution. This will simplify the DMC implementation since it wont be necessary to calculate what sign each sampled parameter space state comes with.

The external parameters $ \vec p $ and $ \tau $ will be the only ones allowed to change during the Markov process. Including $ \alpha $ and/or $ \mu $ would cause the parameter space to increase and the statistics to be spread out. Thus more computation time would be needed to calculate quantities to the same level of certainty as having $ \alpha $ and $ \mu $ fixed.

The value of the propagator $ \Gt $ will be computed at the discrete set of points $ \vec p_i = \Delta p(0.5 + i) \, \hat{ \vec e}_z $ and $ \tau_j = \Delta \tau (0.5 + j) $ where $ i = 0, \, 1, \, 2, \, \dots, \, N - 1  $, $ j = 0, \, 1, \, 2, \, \dots, \, M - 1 $ and the resolution is chosen in terms of $ \Delta p $ and $ \Delta \tau $. To calculate $ \Gt(\vec p_i, \tau_j) = \Gt_{i, j} $, both a bin $ N_0 $ and a two dimensional histogram $ N $ are used, even though $ \vec p $ and $ \tau $ will be continuous variables. Thus the bin $ N_{i,j} $ of the histogram will be covering the range $ p \in [p_i - \Delta p/2, \, p_i + \Delta p/2] $ and $ \tau \in [\tau_j - \Delta \tau/2, \, \tau_j + \Delta \tau/2] $ of the external parameter values. The value of every bin in the histogram along with $ N_0 $ are initially put to zero. Then, each time a parameter space state is sampled, it will be checked wether or not this state belongs to the zeroth order term $ \Gt_0(\vec p, \tau) $. If this is the case, the value of $ N_0 $ is increased by 1, if not, the bin in the histogram according to the external parameters is increased by 1. By doing this, the quantities $ N_0 $ and $ N_{i,j} $ can be shown to be proportional to
\begin{equation}
	\label{eq:int2sum1}
	\begin{split}
		N_0
		&\propto
		\int \limits_{0}^{N\Delta p} \! \! \diff p \int \limits_{0}^{M\Delta p} \! \! \diff \tau \, \Gt_0(\vec p, \tau) \\
		&=
		\Delta p \, \Delta \tau \sum_{k,l} \Gt_0(\vec p_k, \tau_l) + \mathcal{O} \left( [\Delta p]^3 + [\Delta \tau]^3 \right)
	\end{split}
\end{equation}
and
\begin{equation}
	\label{eq:int2sum2}
	\begin{split}
		N_{i,j}
		&\propto
		\int \limits_{p_{i - 0.5}}^{p_{i + 0.5}} \! \! \! \diff p \int \limits_{\tau_{j - 0.5}}^{\tau_{j + 0.5}} \! \! \! \diff \tau \left[ \Gt(\vec p, \tau) - \Gt_0(\vec p, \tau) \right] \\
		&=
		\Delta p \, \Delta \tau \left[ \Gt(\vec p_i, \tau_j) - \Gt_0(\vec p_i, \tau_j) \right] + \mathcal{O} \left( [\Delta p]^3 + [\Delta \tau]^3 \right)
	\end{split}
\end{equation}
respectively. Omitting the errors due to discretization, the interacting electronic propagator is then found to be
\begin{equation}
	\label{eq:GtofTandP}
	\Gt(\vec p_i, \tau_j)
	=
	\Gt_0(\vec p_i, \tau_j) + N_{i, j} \frac{\sum_{k, l} \Gt_0(\vec p_k, \tau_l)}{N_0} \,.
\end{equation}
On the other hand, if the external momentum where to be held fixed at $ \vec p_0 $, the value of $ \Gt $ at the set of imaginary-times $ \{ \tau_j \} $ would similarly become
\begin{equation}
	\label{eq:GtofT}
	\Gt(\vec p_0, \tau_j) = \Gt_0(\vec p_0, \tau_j) + N_j \frac{\sum_l \Gt_0(\vec p_0, \tau_l)}{N_0} \,.
\end{equation}
Here the histogram $ N $ has only one dimension corresponding to the different $ \tau_j $.


\begin{itemize}
	\item \todo{introduce $ \tau_\text{max} $ and $ p_\text{max} $.}

	\item \todo{Quickly mention the code implementation. momenta belongs to lines, time to nodes. Nodes instead of vertices in order to keep things general (when sampling $ \Sigma* $)}
\end{itemize}

\section{Bare scheme update procedures for $ \Gt$}
\label{eq:secSampleGBare}

What remains to be discussed is how the sampling of states in parameter space occurs. As the name Diagrammatic Monte Carlo suggest, the diagrammatic representation of the integral series will be used. That is, the functions $ D_n $ in the integral series (\ref{eq:integralSeries}) is to be though of as a Feynman diagram (without the integrals). The random walk, which is used to simulate the Markov process, will thus be in terms of such diagrams. It is then important that each and every such diagram must be possible to reach in order to cover all of parameter space and thus maintaining ergodicity. To make sure that this actually is the case, a set of update procedures \cite{MishchenkoA.2000DqMC} have been constructed.


\subsection*{Change of diagram length in time, type 1}

\begin{figure}[H]
	\begin{fmffile}{FMFFILEPropagatorChangeOfDiagramLengthType1}
		\begin{empheq}[box={\FDbox[0pt][0pt]}]{equation*}
			\begin{tikzpicture}[baseline={([yshift=-.5ex]current bounding box.center)}]
				\node {
					\FDframe[1][0][5][5]{
						\begin{fmfgraph*}(40, 7)
					\fmfstraight
					\fmftop{t1,t2,t3,t4,t5,t6}
					\fmfbottom{b1,b2,b3,b4,b5,b6}
					\fmf{dots}{b1,b2}
					\fmf{fermion}{b2,b4}
					\fmf{fermion}{b4,b6}
					\fmf{dashes}{b2,t2}
					\fmf{dashes}{b4,t4}
					\fmfdot{b2,b4}
					\fmfv{label=$ \tau_{2n - 1} $, label.angle=-90}{b2}
					\fmfv{label=$ \tau_{2n} $, label.angle=-90}{b4}
        					\fmfv{label=$ \textcolor{highlight}{\tau} $, label.angle=0}{b6}
						\end{fmfgraph*}%
					}%
				};
			\end{tikzpicture}
			\rightarrow
			\begin{tikzpicture}[baseline={([yshift=-.5ex]current bounding box.center)}]
				\node {
					\FDframe[1][0][5][5]{
						\begin{fmfgraph*}(40, 7)
					\fmfstraight
					\fmftop{t1,t2,t3,t4,t5,t6}
					\fmfbottom{b1,b2,b3,b4,b5,b6}
					\fmf{dots}{b1,b2}
					\fmf{fermion}{b2,b4}
					\fmf{fermion}{b4,b6}
					\fmf{dashes}{b2,t2}
					\fmf{dashes}{b4,t4}
					\fmfdot{b2,b4}
					\fmfv{label=$ \tau_{2n - 1} $, label.angle=-90}{b2}
					\fmfv{label=$ \tau_{2n} $, label.angle=-90}{b4}
        					\fmfv{label=$ \textcolor{highlight}{\tau'} $, label.angle=0}{b6}
						\end{fmfgraph*}%
					}%
				};%
    			\end{tikzpicture}
		\end{empheq}
	\end{fmffile}%
	\caption{The only affected parameter is the highlighted imaginary-time of the end point node.}
	\label{fig:NORMALcodl1}
\end{figure}
This update procedure merely changes the external imaginary-time parameter $ \tau $, which is nothing but the diagram length in time. In the first update type this is achieved by altering the time of the end point node in the diagram, i.e. $ \tau \rightarrow \tau' $, as illustrated in figure \ref{fig:NORMALcodl1}. The only affected quantity of such an update will be the value of the very last $ \Gt_0 $ in the diagram so that
\begin{equation}
	\frac{D_n(\tau')}{D_n(\tau)}
	= \frac{\Gt_0(\vec p, \tau' - \tau_{2n})}{\Gt_0(\vec p, \tau - \tau_{2n})} 
	= \frac{\exp \left\{ -\left(\frac{p^2}{2} - \mu \right) \tau' \right\}}{\exp \left\{ -\left(\frac{p^2}{2} - \mu \right) \tau \right\}}
\end{equation}

Now consider an exponential distribution on the interval $ [\tau_{2n}, \, \tau_\text{max}] $ with rate parameter $ \lambda = p^2/2 - \mu $ of which the density is
\begin{equation}
	\rho(\tau) = \frac{\lambda \, e^{-\lambda (\tau - \tau_{2n})}}{1 - e^{- \lambda (\tau_\text{max} - \tau_{2n})}} \,.
\end{equation}
By sampling $ \tau' $ from such a distribution, the ratio $ W(\tau' | \tau)/W(\tau | \tau') $ will be the inverse of $ D_n'/D_n $. Hence the acceptance ratio $ A(\tau | \tau') $ of this update procedure becomes 1, and any proposed $ \tau' $ is always be accepted.

\subsection*{Change of diagram length in time, type 2}

\begin{itemize}
	\item \todo{Mention something about the probability of choosing a node on random will cancel is chosen uniformly. Tell the reader that this is also the case for all other updates procedures as long as nothing else is said.}
\end{itemize}

\begin{figure}[H]
	\begin{fmffile}{FMFFILEPropagatorChangeOfDiagramLengthType2}
		\begin{empheq}[box={\FDbox[0pt][0pt]}]{equation*}
			\begin{tikzpicture}[baseline={([yshift=-.5ex]current bounding box.center)}]
				\node {
					\FDframe[1][0][5][6]{
						\begin{fmfgraph*}(50, 7)
					\fmfstraight
					\fmftop{t1,t2,t3,t4,t5,t6,t7,t8,t9}
					\fmfbottom{b1,b2,b3,b4,b5,b6,b7,b8,b9}
					\fmf{dots}{b1,b2}
					\fmf{fermion}{b2,b4}
					\fmf{fermion}{b4,b6}
					\fmf{dots}{b6,b7}
					\fmf{fermion}{b7,b9}
					\fmf{dashes}{b2,t2}
					\fmf{dashes}{b4,t4}
					\fmf{dashes}{b6,t6}
					\fmf{dashes}{b7,t7}
					\fmfdot{b2,b4,b6,b7}
					\fmfv{label=$ \tau_{k -1} $, label.angle=-90}{b2}
					\fmfv{label=$ \textcolor{highlight}{ \tau_{k} } $, label.angle=-90}{b4}
					\fmfv{label=$ \textcolor{highlight}{ \tau_{k + 1} \;\;\; } $, label.angle=-90}{b6}
					\fmfv{label=$ \;\;\;\;\; \textcolor{highlight}{ \tau_{2n} } $, label.angle=-90}{b7}
        					\fmfv{label=$ \textcolor{highlight}{\tau} $, label.angle=0}{b9}
						\end{fmfgraph*}%
					}%
				};
			\end{tikzpicture}
			\rightarrow
			\begin{tikzpicture}[baseline={([yshift=-.5ex]current bounding box.center)}]
				\node {
					\FDframe[1][0][5][6]{
						\begin{fmfgraph*}(50, 7)
					\fmfstraight
					\fmftop{t1,t2,t3,t4,t5,t6,t7,t8,t9}
					\fmfbottom{b1,b2,b3,b4,b5,b6,b7,b8,b9}
					\fmf{dots}{b1,b2}
					\fmf{fermion}{b2,b4}
					\fmf{fermion}{b4,b6}
					\fmf{dots}{b6,b7}
					\fmf{fermion}{b7,b9}
					\fmf{dashes}{b2,t2}
					\fmf{dashes}{b4,t4}
					\fmf{dashes}{b6,t6}
					\fmf{dashes}{b7,t7}
					\fmfdot{b2,b4,b6,b7}
					\fmfv{label=$ \tau_{k -1} $, label.angle=-90}{b2}
					\fmfv{label=$ \textcolor{highlight}{ \tau_{k}' } $, label.angle=-90}{b4}
					\fmfv{label=$ \textcolor{highlight}{ \tau_{k + 1}' \;\;\; } $, label.angle=-90}{b6}
					\fmfv{label=$ \;\;\;\;\; \textcolor{highlight}{ \tau_{2n}' } $, label.angle=-90}{b7}
        					\fmfv{label=$ \textcolor{highlight}{\tau'} $, label.angle=0}{b9}
						\end{fmfgraph*}%
					}%
				};%
    			\end{tikzpicture}
		\end{empheq}
	\end{fmffile}%
	\caption{The highlighted $ \tau $'s are the parameters affected by this update.}
	\label{fig:NORMALcodl2}
\end{figure}

This update procedure also changes the external imaginary-time parameter, although it does so in a slightly different by letting any $ \Gt_0 $ in the diagram be lengthen or shortened in time, not just the last one. This is achieved by randomly picking any but the leading node in the diagram to assign a new imaginary-time $ \tau_k' $ from the interval $ [\tau_{k-1}, \, \tau_\text{max} - (\tau - \tau_k)] $. In order to only modify the length of the electronic propagator just in front of the chosen node, every node proceeding this node must clearly have the difference $ \tau_k' - \tau_k $  added to its time. This is illustrated in figure \ref{fig:NORMALcodl2}.

This update does not merely affect the one $ \Gt_0 $, but phonon propagators with start and end points on different sides of the chosen node would also have their length modified by the difference $ \tau_k' - \tau_k $. If there are $ m $ such phonons, the quota of the diagram values become
\begin{equation}
	\begin{split}
		\frac{D_n(\tau')}{D_n(\tau)}
		&= \frac{
			\Gt_0(\vec p, \tau_k - \tau_{k-1}) \prod \limits_{i=0}^{m-1} \tilde \Dt_0(\vec q_i, \Delta \tau_i)
		}{
			\Gt_0(\vec p, \tau_k' - \tau_{k-1}) \prod \limits_{j=0}^{m-1} \tilde \Dt_0(\vec q_j, \Delta \tau_j + [\tau_k' - \tau_k])
		} \\[6pt]
		&= \frac{\exp \left\{ -\left(\frac{p^2}{2} - \mu + m \right) \tau_k' \right\}}{\exp \left\{ -\left(\frac{p^2}{2} - \mu + m \right) \tau_k \right\}} \,,
	\end{split}
\end{equation}
where $ \Delta \tau_i $ is the length in time of the $ i $th phonon propagator. By sampling the $ \tau_k' $ from an exponential distribution with rate parameter $ \lambda = p^2/2 - \mu + m $, the acceptance ration for this update procedure also becomes unity.

This second version of the change of diagram length update procedure is more complex than the first one, and may therefore be chosen less often. In a worst case scenario the complexity scales as $ \mathcal{O} (2n) $, due to figuring out the number of phonons $ m $ just discussed. Only one of the procedures changing the length of the diagram would be sufficient, but having an over complete set of update procedures is necessarily not something negative and could potentially enhance the statistics.

\subsection*{Change of external momentum}

\begin{figure}[H]
	\begin{fmffile}{FMFFILEPropagatorChangeOfExternalMomentum}
		\begin{empheq}[box={\FDbox[0pt][0pt]}]{equation*}
			\begin{tikzpicture}[baseline={([yshift=-.5ex]current bounding box.center)}]
				\node {
					\FDframe[1][0][1][0]{
						\begin{fmfgraph*}(50, 7)
					\fmfstraight
					\fmftop{t1,t2,t3,t4,t5,t6,t7,t8,t9,t10}
					\fmfbottom{b1,b2,b3,b4,b5,b6,b7,b8,b9,b10}
					\fmf{fermion, label=$ \textcolor{highlight}{\vec p_0} $, label.side=left}{b1,b3}
					\fmf{fermion, label=$ \textcolor{highlight}{\vec p_1} $, label.side=left}{b3,b5}
					\fmf{dots}{b5,b6}
					\fmf{fermion, label=$ \textcolor{highlight}{\vec p_{2n - 1}} $, label.side=left}{b6,b8}
					\fmf{fermion, label=$ \textcolor{highlight}{\vec p_{2n}} $, label.side=left}{b8,b10}
					\fmf{dashes}{b3,t3}
					\fmf{dashes}{b5,t5}
					\fmf{dashes}{b6,t6}
					\fmf{dashes}{b8,t8}
					\fmfdot{b3,b5,b6,b8}
						\end{fmfgraph*}%
					}%
				};
			\end{tikzpicture}
			\rightarrow
			\begin{tikzpicture}[baseline={([yshift=-.5ex]current bounding box.center)}]
				\node {
					\FDframe[1][0][1][0]{
						\begin{fmfgraph*}(50, 7)
					\fmfstraight
					\fmftop{t1,t2,t3,t4,t5,t6,t7,t8,t9,t10}
					\fmfbottom{b1,b2,b3,b4,b5,b6,b7,b8,b9,b10}
					\fmf{fermion, label=$ \textcolor{highlight}{\vec p'_0} $, label.side=left}{b1,b3}
					\fmf{fermion, label=$ \textcolor{highlight}{\vec p'_1} $, label.side=left}{b3,b5}
					\fmf{dots}{b5,b6}
					\fmf{fermion, label=$ \textcolor{highlight}{\vec p'_{2n - 1}} $, label.side=left}{b6,b8}
					\fmf{fermion, label=$ \textcolor{highlight}{\vec p'_{2n}} $, label.side=left}{b8,b10}
					\fmf{dashes}{b3,t3}
					\fmf{dashes}{b5,t5}
					\fmf{dashes}{b6,t6}
					\fmf{dashes}{b8,t8}
					\fmfdot{b3,b5,b6,b8}
						\end{fmfgraph*}%
					}%
				};%
    			\end{tikzpicture}
		\end{empheq}
	\end{fmffile}%
	\caption{This update procedure changes the momentum of every $ \Gt_0 $ in the diagram by the external momentum difference $ \vec p' - \vec p $. Surely it must be the case that $ \vec p_0  = \vec p_{2n} = \vec p $ and the same is of course true in primed case as well.}
	\label{fig:NORMALcoem}
\end{figure}

Since there is no preferred direction of the Hamiltonian (\ref{eq:finalHamiltonian}), the Green's function $ \Gt $ becomes dependent merely upon the magnitude of the external momentum $ \vec p $. \todo{(this is supposed to have been discussed at an earlier point!)} This update procedure is thus constructed to keep the direction constant while changing only the magnitude $ p \rightarrow p' $. In order to satisfy momentum conservation at each vertex, the $ \Gt_0 $'s are chosen to absorb the external momentum difference $ \vec p' - \vec p $ leaving the value of the $ \tilde \Dt_0 $'s the same. This is illustrated in figure \ref{fig:NORMALcoem}. The ratio of the diagram value after to before such an update then becomes
\begin{equation}
	\label{eq:externalMomentumUpdateRatio}
	\begin{split}
		\frac{D_n(\vec p')}{D_n'(\vec p)}
		&= \frac{
			\prod \limits_{i=0}^{2n} \Gt_0(\vec p'_i, \tau_{i + 1} - \tau_i)
		}{
			\prod \limits_{j=0}^{2n} \Gt_0(\vec p_j, \tau_{j + 1} - \tau_j)
		} \\
		&= \exp \left\{ - \frac{1}{2} \sum \limits_{i=0}^{2n} \left( \left[ \vec p_i + (\vec p' - \vec p) \right]^2  - p_i^2 \right) (\tau_{i + 1} - \tau_i) \right\} \\
		&= \exp \left\{ - \frac{\tau}{2} \left( [p' - p]^2 + 2 \langle \vec p \rangle_{0, 2n} \cdot [\vec p' - \vec p] \right) \right\}
	\end{split}
\end{equation}
where the mean electronic momentum is defined as
\begin{equation}
	\langle \vec p \rangle_{k,l} \equiv \sum \limits_{i = k}^{l} \frac{\tau_{i + 1} - \tau_i}{\tau} \, \vec p_i \,.
\end{equation}

\begin{itemize}
\item
\todo{Introduce $ p_\text{min} $ earlier in the thesis}
\end{itemize}

By sampling $ p' \in [p_\text{min}, \, p_\text{max}] $ using a truncated half-normal distribution whose corresponding normal distribution would have the standard deviation $ \sigma = 1/\sqrt \tau $, the fraction of the proposal distributions take the value
\begin{equation}
	\frac{W(\vec p' | \vec p)}{W(\vec p | \vec p')} = \exp \left\{ - \frac{\tau}{2} (p^2 - p'^2) \right\}
\end{equation}
so that the acceptance ratio is found to be
\begin{equation}
	\begin{split}
		A(p|p')
		&= \text{min} \Big( 1, \, \exp \big\{ - (\vec p' - \vec p) \cdot (\langle \vec p \rangle_{0,2n} - \vec p) \, \tau \big\} \Big) \\
		&= \text{min} \Big( 1, \, \exp \big\{ - (p' - p) \, (\langle p_z \rangle_{0,2n} - p) \, \tau \big\} \Big) \,.
	\end{split}
\end{equation}
In the final equality the vectors has ben represented in a Cartesian coordinate system with the $ z $-axis parallel to the external momentum. On average $ \langle p_z \rangle_{0,2n} $ should not differ to much from $ p $, implying that both the exponential and the acceptance ration should be close to unity most of the time. This of course being the reason why the update procedure is constructed the way it is.

\question{Perhaps $ \langle p_z \rangle_{0,2n} = p $ on average?}

\subsection*{Change of transferred momentum magnitude}

\begin{figure}[H]
	\begin{fmffile}{FMFFILEPropagatorChangeOfTransferredMomentum}
		\begin{empheq}[box={\FDbox[0pt][0pt]}]{equation*}
			\begin{tikzpicture}[baseline={([yshift=-.5ex]current bounding box.center)}]
				\node {
					\FDframe[1][1][1][5]{
						\begin{fmfgraph*}(40, 20)
					\fmfstraight
					\fmftop{t1,t2,t3,t4,t5,t6,t7,t8}
					\fmfbottom{b1,b2,b3,b4,b5,b6,b7,b8}
					\fmf{dots}{b1,b2}
					\fmf{fermion, label=$ \textcolor{highlight}{\vec p_a} $, label.side=left}{b2,b4}
					\fmf{dots}{b4,b5}
					\fmf{fermion, label=$ \textcolor{highlight}{\vec p_b} $, label.side=left}{b5,b7}
					\fmf{dots}{b7,b8}
					\fmf{dashes, tension=1.5}{b4,v1}
					\fmf{phantom}{v1,t4}
					\fmf{dashes, tension=1.5}{b5,v2}
					\fmf{phantom}{v2,t5}
					\fmf{dashes, left, tension=0, label=$ \textcolor{highlight}{\vec q_k} $, label.side=left}{b2,b7}
					\fmfdot{b2,b4,b5,b7}
					\fmfv{label=$ \tau_a $, label.angle=-90}{b2}
					\fmfv{label=$ \tau_{b+1} $, label.angle=-90}{b7}
						\end{fmfgraph*}%
					}%
				};
			\end{tikzpicture}
			\rightarrow
			\begin{tikzpicture}[baseline={([yshift=-.5ex]current bounding box.center)}]
				\node {
					\FDframe[1][1][1][5]{
						\begin{fmfgraph*}(40, 20)
					\fmfstraight
					\fmftop{t1,t2,t3,t4,t5,t6,t7,t8}
					\fmfbottom{b1,b2,b3,b4,b5,b6,b7,b8}
					\fmf{dots}{b1,b2}
					\fmf{fermion, label=$ \textcolor{highlight}{\vec p'_a} $, label.side=left}{b2,b4}
					\fmf{dots}{b4,b5}
					\fmf{fermion, label=$ \textcolor{highlight}{\vec p'_b} $, label.side=left}{b5,b7}
					\fmf{dots}{b7,b8}
					\fmf{dashes, tension=1.5}{b4,v1}
					\fmf{phantom}{v1,t4}
					\fmf{dashes, tension=1.5}{b5,v2}
					\fmf{phantom}{v2,t5}
					\fmf{dashes, left, tension=0, label=$ \textcolor{highlight}{\vec q_k'} $, label.side=left}{b2,b7}
					\fmfdot{b2,b4,b5,b7}
					\fmfv{label=$ \tau_a $, label.angle=-90}{b2}
					\fmfv{label=$ \tau_{b+1} $, label.angle=-90}{b7}
						\end{fmfgraph*}%
					}%
				};%
    			\end{tikzpicture}
		\end{empheq}
	\end{fmffile}%
	\caption{The momentum transferred via an internal phonon propagator is updated. In order obey momentum conservation at every vertex, electronic propagators beneath the phonon arc absorb the momentum difference.}
	\label{fig:NORMALcotm}
\end{figure}

This update procedure is designed to be very similar to that of the external momentum. However, the main difference of course being that the magnitude of momentum transferred via a phonon propagator is updated rather than the external momentum. In order to achieve this, a $ \tilde \Dt_0 $ is randomly picked and has a new momentum magnitude assigned to it $ q_k \rightarrow q'_k $ while keeping the direction fixed. In order to conserve momentum at the two vertices connected to the phonon propagator, the $ \Gt_0 $'s located beneath the phonon arc should absorb the momentum difference $ \vec q_k - \vec q'_k $. This is illustrated in figure \ref{fig:NORMALcotm}. Since the $ \tilde \Dt(\vec q, \tau) $'s does not depend on the magnitude $ q = | \vec q | $, the ratio of diagram values become
\begin{equation}
	\begin{split}
		\frac{D_n(\vec q'_k)}{D_n(\vec q_k)}
		&= \frac{
			\prod \limits_{i=a}^{b} \Gt_0(\vec p'_i, \tau_{i + 1} - \tau_i)
		}{
			\prod \limits_{j=a}^{b} \Gt_0(\vec p_j, \tau_{j + 1} - \tau_j)
		} \\
		&= \exp \left\{ - \frac{1}{2} \sum \limits_{i=a}^b \left( \left[ \vec p_i + (\vec q_k - \vec q'_k) \right]^2  - p_i^2 \right) (\tau_{i + 1} - \tau_i) \right\} \\
		&= \exp \left\{ - \frac{\tau_{b + 1} - \tau_a}{2} \left( [q_k - q'_k]^2 + 2 \langle \vec p \rangle_{a,b} \cdot [\vec q_k - \vec q'_k] \right) \right\} \,,
	\end{split}
\end{equation}
which indeed is similar to (\ref{eq:externalMomentumUpdateRatio}). Following in the footsteps of the previous update procedure, $ q'_k \in [0, \infty[ $ is sampled from a half-normal distribution whose corresponding normal distribution would have the standard deviation $ \sigma = 1/\sqrt{\tau_{b+1} - \tau_a} $. The acceptance ration is then found to be,
\begin{equation}
	A(\vec q_k | \vec q'_k)
	=
	\text{min} \Big( 1, \, \exp \big\{ - (\vec q_k - \vec q'_k) \cdot (\langle \vec p \rangle_{a,b} + \vec q_k) \, [\tau_{b+1} - \tau_a] \big\} \Big) \,.
\end{equation}
It is reasonable to assume that on average, $ \langle \vec p \rangle_{a,b} + \vec q_k $ does not differ too much from the external momentum $ \vec p $. Hence this update procedure should have an acceptance ration close to unity at low external momenta whilst performing worse at higher external momenta.

\subsection*{Change of transferred momentum direction}

This update procedure changes the direction $ (\theta_k, \, \varphi_k) \rightarrow (\theta'_k, \, \varphi'_k) $ of the momentum transferred via a phonon propagator. As in the previous update procedure, the electronic propagators below the phonon arc absorb the momentum difference $ \vec q_k - \vec q'_k $ which is illustrated in figure \ref{fig:NORMALcotm}. This time, since $ \tilde \Dt \propto \sin \theta $ the ratio of the diagram values becomes slightly different
\begin{equation}
	\begin{split}
		\frac{D_n(\vec q'_k)}{D_n(\vec q_k)}
		&= \frac{\sin \theta'_k}{\sin \theta_k}
		\frac{
			\prod \limits_{i=a}^{b} \Gt_0(\vec p'_i, \tau_{i + 1} - \tau_i)
		}{
			\prod \limits_{j=a}^{b} \Gt_0(\vec p_j, \tau_{j + 1} - \tau_j)
		} \\
		&= \frac{\sin \theta'_k}{\sin \theta_k}
		\exp \left\{ - \frac{\tau_{b + 1} - \tau_a}{2} \left( [\vec q_k - \vec q'_k]^2 + 2 \langle \vec p \rangle_{a,b} \cdot [\vec q_k - \vec q'_k] \right) \right\} \,.
	\end{split}
\end{equation}
By sampling the azimuthal angle uniformly on the interval $ \varphi'_k \in [0, \, 2\pi ] $, and the polar angle $ \theta'_k \in [0, \, \pi] $ from a probability distribution whose density $ \rho(\theta'_k) = \tfrac{1}{2} \sin \theta'_k $, one obtains the acceptance ratio
\begin{equation}
	A(\vec q_k | \vec q'_k)
	= \min{1, \, \exp \left\{ - \frac{\tau_{b + 1} - \tau_a}{2} \left( [\vec q_k - \vec q'_k]^2 + 2 \langle \vec p \rangle_{a,b} \cdot [\vec q_k - \vec q'_k] \right) \right\} } \,.
\end{equation}


\subsection*{Vertex shift in time}

\begin{figure}[H]
	\begin{fmffile}{FMFFILEPropagatorVertexShiftInTime}
		\begin{empheq}[box={\FDbox[0pt][0pt]}]{equation*}
			\begin{tikzpicture}[baseline={([yshift=-.5ex]current bounding box.center)}]
				\node {
					\FDframe[1][0][1][6]{
						\begin{fmfgraph*}(40, 7)
					\fmfstraight
					\fmftop{t1,t2,t3,t4,t5,t6,t7}
					\fmfbottom{b1,b2,b3,b4,b5,b6,b7}
					\fmf{dots}{b1,b2}
					\fmf{fermion}{b2,b4}
					\fmf{fermion}{b4,b6}
					\fmf{dots}{b6,b7}
					\fmf{dashes}{b2,t2}
					\fmf{dashes}{b4,t4}
					\fmf{dashes}{b6,t6}
					\fmfdot{b2,b4,b6}
					\fmfv{label=$ \tau_{k -1} $, label.angle=-90}{b2}
					\fmfv{label=$ \textcolor{highlight}{ \tau_{k} } $, label.angle=-90}{b4}
					\fmfv{label=$ \tau_{k + 1} $, label.angle=-90}{b6}
						\end{fmfgraph*}%
					}%
				};
			\end{tikzpicture}
			\rightarrow
			\begin{tikzpicture}[baseline={([yshift=-.5ex]current bounding box.center)}]
				\node {
					\FDframe[1][0][1][6]{
						\begin{fmfgraph*}(40, 7)
					\fmfstraight
					\fmftop{t1,t2,t3,t4,t5,t6,t7}
					\fmfbottom{b1,b2,b3,b4,b5,b6,b7}
					\fmf{dots}{b1,b2}
					\fmf{fermion}{b2,b4}
					\fmf{fermion}{b4,b6}
					\fmf{dots}{b6,b7}
					\fmf{dashes}{b2,t2}
					\fmf{dashes}{b4,t4}
					\fmf{dashes}{b6,t6}
					\fmfdot{b2,b4,b6}
					\fmfv{label=$ \tau_{k -1} $, label.angle=-90}{b2}
					\fmfv{label=$ \textcolor{highlight}{ \tau_{k}' } $, label.angle=-90}{b4}
					\fmfv{label=$ \tau_{k + 1} $, label.angle=-90}{b6}
						\end{fmfgraph*}%
					}%
				};%
    			\end{tikzpicture}
		\end{empheq}
	\end{fmffile}%
	\caption{The imaginary-time of internal node $ k $ is updated.}
	\label{fig:NORMALvsit}
\end{figure}

This update procedure changes the imaginary-time $ \tau_k \rightarrow \tau'_k $ of a randomly chosen internal node whilst keeping the chronological ordering, i.e $ \tau_{k-1} < \tau'_k < \tau_{k+1} $. The procedure is illustrated in figure \ref{fig:NORMALvsit}, and as can be seen, it does only affect the three propagators connected to the node so that
\begin{equation}
	\begin{split}
		\frac{D_n(\tau'_k)}{D_n(\tau_k)}
		&= \frac{
			\Gt_0(\vec p_{k-1}, \tau'_k - \tau_{k_1}) \, \Gt_0(\vec p_k, \tau_{k+1} - \tau'_k) \, \tilde \Dt_0(\vec q_k, \pm (\tau_l - \tau'_k))
		}{
			\Gt_0(\vec p_{k-1}, \tau'_k - \tau_{k_1}) \, \Gt_0(\vec p_k, \tau_{k+1} - \tau_k) \, \tilde \Dt_0(\vec q_k, \pm (\tau_l - \tau_k))
		} \\
		&= \exp \left\{  - \left[ \frac{p_{k-1}^2}{2} - \frac{p_k^2}{2}  \mp 1 \right] (\tau' - \tau) \right\} \,.
	\end{split}
\end{equation}
Here the upper sign is used if $ \tau_l > \tau_k $, meaning that the phonon propagator is leaving to node $ l $ from node $ k $. If instead $ \tau_l < \tau_k $, the lower sign should be used and the situation becomes the opposite. By sampling $ \tau'_k $ from the interval $ [\tau_{k-1}, \, \tau_{k+1}] $ using an exponential distribution with rate parameter $ \lambda = p_{k-1}^2/2 - p_k^2/2  \mp 1 $, the acceptance ration becomes unity.

\subsection*{Change of diagram structure}

\begin{figure}[H]
	\begin{fmffile}{FMFFILEPropagatorChangeOfDiagramStructure}
		\begin{empheq}[box={\FDbox[0pt][0pt]}]{equation*}
			\begin{tikzpicture}[baseline={([yshift=-.5ex]current bounding box.center)}]
				\node {
					\FDframe[1][1][1][5]{
						\begin{fmfgraph*}(40, 15)
					\fmfstraight
					\fmftop{t1,t2,t3,t4,t5}
					\fmfbottom{b1,b2,b3,b4,b5}
					\fmf{dots}{b1,b2}
					\fmf{fermion, label=$ \textcolor{highlight}{\vec p_k} $, label.side=left}{b2,b4}
					\fmf{dots}{b4,b5}
					\fmf{dashes, foreground=(0,,0,,1)}{b2,t2}
					\fmf{dashes, foreground=(1,,0,,0)}{b4,t4}
					\fmfdot{b2,b4}
        					\marrow{a}{left}{lft}{$ c_1 q_1 $}{b2,t2}
        					\marrow{b}{right}{rt}{$ c_2 q_2 $}{b4,t4}
					\fmfv{label=$ \tau_k $, label.angle=-90}{b2}
					\fmfv{label=$ \tau_{k+1} $, label.angle=-90}{b4}
						\end{fmfgraph*}%
					}%
				};
			\end{tikzpicture}
			\rightarrow
			\begin{tikzpicture}[baseline={([yshift=-.5ex]current bounding box.center)}]
				\node {
					\FDframe[1][1][1][5]{
						\begin{fmfgraph*}(40, 15)
					\fmfstraight
					\fmftop{t1,t2,t3,t4,t5}
					\fmfbottom{b1,b2,b3,b4,b5}
					\fmf{dots}{b1,b2}
					\fmf{fermion, label=$ \textcolor{highlight}{\vec p_k'} $, label.side=left}{b2,b4}
					\fmf{dots}{b4,b5}
					\fmf{dashes, foreground=(1,,0,,0), left=0.4}{b2,t4}
					\fmf{dashes, foreground=(0,,0,,1), right=0.4}{b4,t2}
					\fmfdot{b2,b4}
        					\Marrow{a}{left}{lft}{$ c_2 q_2 $}{b2,t3}{12}
        					\Marrow{b}{right}{rt}{$ c_1 q_1 $}{b4,t3}{12}
					\fmfv{label=$ \tau_k $, label.angle=-90}{b2}
					\fmfv{label=$ \tau_{k+1} $, label.angle=-90}{b4}
						\end{fmfgraph*}%
					}%
				};%
    			\end{tikzpicture}
		\end{empheq}
	\end{fmffile}%
	\caption{The diagram structure is modified by interchanging the phonon propagators connected to two neighboring nodes. \todo{Bold face: $ \vec q_1 $ and $ \vec q_2 $}}
	\label{fig:NORMALcods}
\end{figure}


This update procedure, as illustrated in figure \ref{fig:NORMALcods}, interchange the two phonon propagators connected to a pair of randomly selected neighboring nodes. In order to conserve momentum, the $ \Gt_0 $ connected to both of the selected nodes must absorb the difference $ \vec p'_k - \vec p_k = c_1 \vec q_1 - c_2 \vec q_2 $. Here the $ c_i $ tells whether the propagator is propagating towards any of the two nodes ($ c_i = -1 $) or if it is propagating away from any of the two nodes ($ c_i = 1 $). The ratio of the diagram value prior to and after the update then becomes
\begin{equation}
	\begin{split}
		\frac{D_n(\xi'_n)}{D_n(\xi_n)}
		&= \frac{
			\Dt_0 (\vec q_1, c_1[\tau_i - \tau_{k+1}]) \, \Dt_0 (\vec q_2, c_2[\tau_j - \tau_k]) \, \Gt_0 (\vec p'_k, \tau_{k+1} - \tau_k)
		}{
			\Dt_0 (\vec q_1, c_1[\tau_i - \tau_k]) \, \Dt_0 (\vec q_2, c_2[\tau_j - \tau_{k+1}]) \, \Gt_0 (\vec p_k, \tau_{k+1} - \tau_k)
		} \\[4pt]
		&= \exp \left\{ -\left[ \frac{(\vec p_k + c_1 \vec q_1 - c_2 \vec q_2)^2}{2} - \frac{p_k^2}{2} - c_1 + c_2 \right] (\tau_{k+1} - \tau_k) \right\} \,.
	\end{split}
\end{equation}
Other than the pair of nodes to be picked, there are no parameters to be sampled in order to change the diagram structure in this way. Thus $ W(\xi_n|\xi'_n) = W(\xi'_n|\xi_n) $ and the update procedure should be accepted according to
\begin{equation}
	A(\xi_n|\xi'_n) = \min{1, \, \frac{D_n(\xi'_n)}{D_n(\xi_n)}} \,.
\end{equation}


\subsection*{Change of digram order}

\begin{figure}[H]
	\begin{fmffile}{FMFFILEPropagatorChangeOfDiagramOrder}
		\begin{empheq}[box={\FDbox[0pt][0pt]}]{equation*}
			\begin{tikzpicture}[baseline={([yshift=-.5ex]current bounding box.center)}]
				\node {
					\FDframe[1][4][1][5]{
						\begin{fmfgraph*}(40, 15)
					\fmfstraight
					\fmftop{t1,t2,t3,t4,t5,t6,t7,t8}
					\fmfbottom{b1,b2,b3,b4,b5,b6,b7,b8}
					\fmf{dots}{b1,b2}
					\fmf{fermion, label=$ \vec p_i $, label.side=left}{b2,b4}
					\fmf{dots}{b4,b5}
					\fmf{fermion, label=$ \vec p_j $, label.side=left}{b5,b7}
					\fmf{dots}{b7,b8}
					\fmf{dashes}{b2,v1}
					\fmf{phantom}{v1,t2}
					\fmf{dashes}{b4,v2}
					\fmf{phantom}{v2,t4}
					\fmf{dashes}{b5,v3}
					\fmf{phantom}{v3,t5}
					\fmf{dashes}{b7,v4}
					\fmf{phantom}{v4,t7}
					\fmfdot{b2,b4,b5,b7}
						\end{fmfgraph*}%
					}%
				};
			\end{tikzpicture}
			\leftrightarrow
			\begin{tikzpicture}[baseline={([yshift=-.5ex]current bounding box.center)}]
				\node {
					\FDframe[1][4][1][5]{
						\begin{fmfgraph*}(60, 15)
					\fmfstraight
					\fmftop{t1,t2,t3,t4,t5,t6,t7,t8}
					\fmfbottom{b1,b2,b3,b4,b5,b6,b7,b8}
					\fmf{dots}{b1,b2}
					\fmf{fermion, label=$ \vec p_i $, label.side=left}{b2,b3}
					\fmf{fermion, label=$ \textcolor{highlight}{\vec p_i'} $, label.side=left}{b3,b4}
					\fmf{dots}{b4,b5}
					\fmf{fermion, label=$ \textcolor{highlight}{\vec p_j'} $, label.side=left}{b5,b6}
					\fmf{fermion, label=$ \vec p_j $, label.side=left}{b6,b7}
					\fmf{dots}{b7,b8}
					\fmf{dashes}{b2,v1}
					\fmf{phantom}{v1,t2}
					\fmf{dashes}{b4,v2}
					\fmf{phantom}{v2,t4}
					\fmf{dashes}{b5,v3}
					\fmf{phantom}{v3,t5}
					\fmf{dashes}{b7,v4}
					\fmf{phantom}{v4,t7}
					\fmf{dashes, left, foreground=(1,,0,,0), label=$ \textcolor{highlight}{\vec q_k} $}{b3,b6}
					\fmfdot{b2,b3,b4,b5,b6,b7}
					\fmfv{foreground=(1,,0,,0), label=$ \textcolor{highlight}{\tau_l} $, label.a=-90}{b3}
					\fmfv{foreground=(1,,0,,0), label=$ \textcolor{highlight}{\tau_m} $, label.a=-90}{b6}
						\end{fmfgraph*}%
					}%
				};%
    			\end{tikzpicture}
		\end{empheq}
	\end{fmffile}%
	\caption{An illustration of the change of diagram order procedure.}
	\label{fig:NORMALcodo}
\end{figure}

This final update procedure which is illustrated in figure \ref{fig:NORMALcodo}, is the only one which changes the order of the diagram at hand. To increase the diagram order, an electronic propagator $ \Gt_{0, i} $ is selected on random and then split at a time $ \tau_l $, which is sampled uniformly on the interval $ [\tau_i, \, \tau_{i+1}] $. After this, another imaginary time $ \tau_m $ is sampled on the interval $ \tau_m \in[\tau_l, \tau] $ using an exponential distribution with a rate parameter $ \lambda = 1 $. The $ \Gt_{0,j} $ which happen to occupy the imaginary-time $ \tau_m $ is split in twice at that point as well. For each of the two times $ \tau_l $ and $ \tau_m $, a node is inserted so that the loose ends of the $ \Gt_0 $'s have something to connect to. The two newly introduced nodes are then further connected to a new phonon propagator $ \tilde \Dt_0 $, for which the momentum $ \vec q_k $ is sampled according to the \textit{change of transferred momentum} procedures introduced earlier. In order to obey momentum conservation at each node, the $ \Gt_0 $'s under the newly added phonon arc have their momentum subtracted by $ \vec q_k $. In this way, the probability distribution of increasing the diagram order becomes
\begin{equation}
	\label{eq:transitionUp}
	\begin{split}
		W(n|n+1)
		&=
		P_\text{R}(n) \;
		\frac{1}{2n + 1} \frac{1}{\tau_{i+1}  - \tau_i} \;
		\frac{e^{- (\tau_m - \tau_l)}}{1 - e^{- (\tau - \tau_l)}} \;
		\frac{\sin \theta_k}{2} \frac{1}{2 \pi} \\[4pt]
		& \times \sqrt{\frac{2 (\tau_m - \tau_l)}{\pi}} \exp \left\{- \frac{q_k^2}{2} (\tau_m - \tau_l) \right\} \,.
	\end{split}
\end{equation}
Here $ P_\text{R}(n) $ is the probability of choosing to raise the diagram order once having selected the \textit{change of diagram order} procedure. Of course the corresponding probability of choosing to lower the diagram order is then nothing but $ 1 - P_\text{R}(n) $. Further more, the ratio of the diagram value prior to and after the update is realized to be
\begin{equation}
	\begin{split}
		\frac{D_{n+1}}{D_n}
		&= \tilde \Dt_0(\vec q_k, \tau_m - \tau_l) \,
		\frac{
			\prod \limits_{i=l}^{m-1} \Gt_0(\vec p_i - \vec q_k, \tau_{i + 1} - \tau_i)
		}{
			\prod \limits_{i=l}^{m-1} \Gt_0(\vec p_i, \tau_{i + 1} - \tau_i)
		} \\
		&= \frac{2 \sqrt 2 \pi \alpha}{(2\pi)^3} \, \sin \theta_k \, \exp \left\{ - \left[ \frac{q_k^2}{2} + 1 - \langle \vec p \rangle_{l,m-1} \cdot \vec q_k \right] (\tau_m - \tau_l) \right\} \,.
	\end{split}
\end{equation}

The procedure of lowering the diagram order is much more simplistic; it is only necessary to randomly pick a $ \tilde \Dt $ which is to be removed. Hence $ W(n+1|n) = (1 - P_\text{R}(n+1)) \, [n+1]^{-1} $, and by introducing the quantity
\begin{equation}
	\label{eq:changeOrderR}
	\begin{split}
		R(n|n+1)
		&= \frac{D_{n+1}}{D_n} \frac{W(n+1|n)}{W(n|n+1)} \\[4pt]
		&=
		\frac{1 - P_\text{R}(n+1)}{P_\text{R}(n)}
		\frac{\alpha}{\sqrt \pi}
		\frac{2n + 1}{n+1}
		\frac{\tau_{i+1} - \tau_i}{\sqrt{\tau_m - \tau_l}} \\
		&\times \left[ 1 - e^{-(\tau - \tau_l)} \right]
		\exp \big\{ [\langle \vec p \rangle_{l,m-1} \cdot \vec q_k] (\tau_m - \tau_l) \big\} \,
	\end{split}
\end{equation}
the acceptance ratios may be expressed as
\begin{equation}
	\label{eq:acceptanceRatioChangeOrder}
	A(n|n+1) = \min{1, \, R(n|n+1)}
	\; , \quad
	A(n+1|n) = \min{1, \, 1/R(n|n+1)} \,.
\end{equation}
By requiring that
\begin{equation}
	\frac{1 - P_\text{R}(n+1)}{P_\text{R}(n)} = \frac{\sqrt \pi}{2 \alpha}
	\quad \Rightarrow \quad
	P_\text{R}(n) = P_\text{R} = \left[ 1 + \frac{\sqrt \pi}{2 \alpha}\right]^{-1}
\end{equation}
these acceptance ratios become independent of the coupling constant $ \alpha $ and less dependent of the diagram order $ n $

Clearly it should not be possible to lower the diagram order any further than $ n=0 $. Also, one could think of implementing a maximum order $ n_\text{max} $ for which the diagram order 
should not be able to rise above. To achieve this, it is extremely important not to set $ P_\text{R} = 1 $ and $ P_\text{R} = 0 $ at $ n=0 $ and $ n=n_\text{max} $ respectively, since this would ruin the detailed balance. Rather one should approach this by simply refusing such an update. For example, if the procedure to increase the diagram order happen to be chosen when $ n = n_\text{max} $, it should be refused and a new update procedure chosen instead.

\begin{itemize}
	\item \todo{Check the acceptance ratio!\textbf{}}
\end{itemize}

\subsection{Results}

\begin{itemize}
\item
\todo{Result should be independent on weight of each update function}
\end{itemize}

Here follow some results obtained when simulating $ \Gt $ using the bare scheme update procedures described above. The external momentum $ \vec p $ has been fixed during these simulations in order to not spread the statistics out over external parameters for which the data is not shown.


\begin{figure}[H]
	\centering
	\begin{subfigure}[b]{\textwidth}
		\includegraphics[width=\textwidth]{{"Images/Plots/Gt/Gt_a1_p0_bare"}.pdf}
	\end{subfigure} \\
	\begin{subfigure}[b]{\textwidth}
		\includegraphics[width=\textwidth]{{"Images/Plots/Gt/Gt_a1_p15_bare"}.pdf}
	\end{subfigure} \\
	\begin{subfigure}[b]{\textwidth}
		\includegraphics[width=\textwidth]{{"Images/Plots/Gt/Gt_a2_p0_bare"}.pdf}
	\end{subfigure}
	\caption{The acquired value of $ \Gt(p = 0, \, \tau) $ after 80 minutes of core time. Here $ \tau_{max} = 40 $ and $ \Delta \tau = 0.02 $ has been used.}
	\label{fig:GOft}
\end{figure}


\begin{table}[H]
	\begin{center}
		\begin{tabular}{r | c | c | c} 
		 	$ \tau $ & $ \Gt(0, 1, -1.1) $ & $ \Gt(1.5, 1, -0.25) $ & $ \Gt(0, 2, -2.2) $ \\ 
		 	\specialrule{.1em}{.05em}{.05em} 
0.01 & 0.9906 & 0.9881 & 0.9797 \\
1.01 & 0.6242 & 0.4938 & 0.3922 \\
2.01 & 0.5225 & 0.3631 & 0.2808 \\
3.01 & 0.4673 & 0.3066 & 0.2314 \\
4.01 & 0.4259 & 0.2745 & 0.1993 \\
5.01 & 0.3907 & 0.2528 & 0.1738 \\
6.01 & 0.359 & 0.2365 & 0.1524 \\
7.01 & 0.3301 & 0.223 & 0.1339 \\
8.01 & 0.3041 & 0.2113 & 0.1176 \\
9.01 & 0.2797 & 0.2003 & 0.1031 \\
10.01 & 0.2573 & 0.1902 & 0.09057 \\
11.01 & 0.2374 & 0.1806 & 0.07967 \\
12.01 & 0.2175 & 0.1715 & 0.07009 \\
13.01 & 0.2003 & 0.1635 & 0.0617 \\
14.01 & 0.1844 & 0.1552 & 0.05428 \\
15.01 & 0.1695 & 0.1476 & 0.04763 \\
16.01 & 0.156 & 0.1409 & 0.04189 \\
17.01 & 0.1436 & 0.1341 & 0.03696 \\
18.01 & 0.1319 & 0.1276 & 0.03243 \\
19.01 & 0.1213 & 0.1216 & 0.02866 \\
20.01 & 0.1116 & 0.1157 & 0.02498 \\
21.01 & 0.1025 & 0.1103 & 0.02211 \\
22.01 & 0.09434 & 0.1051 & 0.01937 \\
23.01 & 0.08689 & 0.09985 & 0.01701 \\
24.01 & 0.07983 & 0.09523 & 0.01492 \\
25.01 & 0.07363 & 0.0909 & 0.01322 \\
26.01 & 0.06764 & 0.08651 & 0.01168 \\
27.01 & 0.06217 & 0.0825 & 0.01027 \\
28.01 & 0.05718 & 0.07844 & 0.009083 \\
29.01 & 0.05272 & 0.07471 & 0.007966 \\
30.01 & 0.04861 & 0.07102 & 0.007016 \\
31.01 & 0.04458 & 0.06742 & 0.006182 \\
32.01 & 0.04098 & 0.06404 & 0.005393 \\
33.01 & 0.03794 & 0.06131 & 0.004762 \\
34.01 & 0.03482 & 0.05836 & 0.00411 \\
35.01 & 0.0319 & 0.05525 & 0.003671 \\
36.01 & 0.02945 & 0.05269 & 0.003204 \\
37.01 & 0.02723 & 0.05022 & 0.002901 \\
38.01 & 0.02509 & 0.04788 & 0.002536 \\
39.01 & 0.02288 & 0.04576 & 0.002207 \\
39.99 & 0.02102 & 0.04357 & 0.001962 \\
		\end{tabular}
	\end{center}
	\caption{Some values of $ \Gt(p, \alpha, \mu) $ from the plots in figure \ref{fig:GOft}.}
	\label{tab:truthTables}   
\end{table}

\section{Bare scheme update procedures for $ \Sigma^* $}

Rather than calculating $ \Gt(\vec p, \tau) $ directly using DMC, it is also possible and even so preferred \question{(motivate this from papers. Cover more diagrams and so on...)} to instead simulate the proper self energy $ \Sigma^*(\vec p, \tau) $, from which the electronic propagator is calculated using the Dyson equation (\ref{eq:dysonEquation}).
In order to do this, the random walk must now cover diagrams without external legs but also be able to reach the bare propagator $ \Gt_0 $ for normalization purposes. This is easily accomplished by a slight modification of some of the update procedures introduced in the previous section, and will be discussed in more detail shortly.

Before that however, it is important to realize that no longer all types of diagrams ($ n > 0 $) should be binned. In order to calculate $ \Sigma^* $ it is critical that the histogram merely have contributions from irreducible diagrams. Then, in similarity to (\ref{eq:GtofTandP}) and (\ref{eq:GtofT}) the value of $ \Sigma^* $ is calculated in terms $ N_0 $ and $ N $ in the following way
\begin{equation}
	\label{eq:properSnormalization}
	\Sigma^* (\vec p_i, \tau_j) = N_{i,j} \frac{\sum_{k,l} \Gt_0 (\vec p_k, \tau_l)}{N_0}
	\; , \quad
	\Sigma^* (\vec p_0, \tau_j) = N_{j} \frac{\sum_{l} \Gt_0 (\vec p_0, \tau_l)}{N_0} \,.
\end{equation}
An easy way to check whether or not a diagram is irreducible, is to store the current momentum of every $ \Gt_0 $ present in the diagram within a hash table. If one or more momenta are found to be equal to that of the external momentum, the diagram must clearly be reducible and should thus not be binned. Since the complexity of a search in a hash table is $ \mathcal{O}(1) $, this implementation should not limit the performance of the algorithm. To recapitulate, all self energy diagrams (together with the bare propagator for normalization purposes) should be sampled, but only proper ones are allowed to increment the bins values $ N_{i,j} $ of the histogram.

Now, returning to the update procedures, there are only two which need to be modified. The others stay the same but might have some trivial change of notation for quantities, such as $ \langle \vec p \rangle_{0,2n} \rightarrow \langle \vec p \rangle_{0, 2n-1} $ in the case of the \textit{change of external momentum} procedure.

\subsection*{Change of diagram length in time, type 1}

\begin{figure}[H]
	\begin{fmffile}{FMFFILESelfEnergyDiagramLengthChaneTyp1}
		\begin{empheq}[box={\FDbox[0pt][0pt]}]{equation*}
			\begin{tikzpicture}[baseline={([yshift=-.5ex]current bounding box.center)}]
				\node {
					\FDframe[1][0][4][5]{
						\begin{fmfgraph*}(40, 14)
							\fmfstraight
							\fmftop{t1,t2,t3,t4,t5,t6}
							\fmfbottom{b1,b2,b3,b4,b5,b6}
							\fmf{dots}{b1,b2}
							\fmf{fermion}{b2,b4}
							\fmf{fermion}{b4,b6}
							\fmf{dashes}{b2,v1}
							\fmf{phantom}{v1,t2}
							\fmf{dashes}{b4,v2}
							\fmf{phantom}{v2,t4}
							\fmf{dashes, right=0.4}{b6,t4}
							\fmfdot{b2,b4,b6}
							\fmfv{label=$ \tau_{2n - 3} $, label.angle=-90}{b2}
							\fmfv{label=$ \tau_{2n - 2} $, label.angle=-90}{b4}
        							\fmfv{label=$ \textcolor{highlight}{\tau} $, label.angle=0}{b6}
						\end{fmfgraph*}%
					}%
				};
			\end{tikzpicture}
			\rightarrow
			\begin{tikzpicture}[baseline={([yshift=-.5ex]current bounding box.center)}]
				\node {
					\FDframe[1][0][5][5]{
						\begin{fmfgraph*}(40, 14)
							\fmfstraight
							\fmftop{t1,t2,t3,t4,t5,t6}
							\fmfbottom{b1,b2,b3,b4,b5,b6}
							\fmf{dots}{b1,b2}
							\fmf{fermion}{b2,b4}
							\fmf{fermion}{b4,b6}
							\fmf{dashes}{b2,v1}
							\fmf{phantom}{v1,t2}
							\fmf{dashes}{b4,v2}
							\fmf{phantom}{v2,t4}
							\fmf{dashes, right=0.4}{b6,t4}
							\fmfdot{b2,b4,b6}
							\fmfv{label=$ \tau_{2n - 3} $, label.angle=-90}{b2}
							\fmfv{label=$ \tau_{2n - 2} $, label.angle=-90}{b4}
       		 					\fmfv{label=$ \textcolor{highlight}{\tau'} $, label.angle=0}{b6}
						\end{fmfgraph*}%
					}%
				};%
    			\end{tikzpicture}
		\end{empheq}
	\end{fmffile}%
	\caption{An illustration of the first kind of update procedure for changing the length of a diagram without external legs.}
	\label{fig:Scodl1}
\end{figure}

At $ n > 0 $, there is now a phonon propagator connected to the end point node of the diagram as depicted in figure \ref{fig:Scodl1}. Thus, in accordance with the \textit{change of diagram length in time, type 2} update procedure,
\begin{equation}
	\frac{D_n(\tau')}{D_n(\tau)}
	= \exp \left\{ -\left[\frac{p^2}{2} - \mu + 1 \right] (\tau' - \tau) \right\} \,.
\end{equation}
Hence, to maintain the acceptance ratio at unity, the only modification needed is to change the rate parameter of the distribution from which $ \tau' $ is sampled, i.e. $ \lambda \rightarrow \lambda' = \lambda + 1 $.

\subsection*{Change of diagram order}

\begin{figure}[H]
	\begin{fmffile}{FMFFILESelfEnergyOrderChange}
		\begin{empheq}[box={\FDbox[0pt][0pt]}]{equation*}
			\begin{tikzpicture}[baseline={([yshift=-.5ex]current bounding box.center)}]
				\node {
					\FDframe[4][5][4][2]{
						\begin{fmfgraph*}(40, 20)
							\fmfstraight
							\fmfbottom{b1,b2}
							\fmf{fermion, label=$ \textcolor{highlight}{\vec p} $, label.side=left}{b1,b2}
							\fmfv{label=$ 0 $, label.angle=-180}{b1}
							\fmfv{label=$ \tau $, label.angle=0}{b2}
						\end{fmfgraph*}%
					}%
				};
			\end{tikzpicture}
			\leftrightarrow
			\begin{tikzpicture}[baseline={([yshift=-.5ex]current bounding box.center)}]
				\node {
					\FDframe[4][5][4][2]{
						\begin{fmfgraph*}(40, 20)
							\fmfstraight
							\fmfbottom{b1,b2}
							\fmf{fermion, label=$ \textcolor{highlight}{\vec p'} $, label.side=left}{b1,b2}
							\fmf{dashes, left, foreground=(1,,0,,0), label=$ \textcolor{highlight}{\vec q} $}{b1,b2}
							\fmfdot{b1,b2}
							\fmfv{foreground=(1,,0,,0), label=$ 0 $, label.a=180}{b1}
							\fmfv{foreground=(1,,0,,0), label=$ \tau $, label.a=0}{b2}
						\end{fmfgraph*}%
					}%
				};%
    			\end{tikzpicture}
		\end{empheq}
	\end{fmffile}%
	\caption{An illustration of the change of diagram order procedure between zeroth and first order diagrams.}
	\label{fig:Scodo}
\end{figure}




In order to prevent generating diagrams with external legs, it is necessary only to modify the transition between a zeroth and a first order diagram. Instead of sampling two times where new nodes then will be inserted for the phonon to connect to, the already existing start and end point node of diagram will be used. This is illustrated in figure \ref{fig:Scodo}. Other than that this transition is no different from the ordinary \textit{change of diagram order} update procedure so that
\begin{equation}
	W(n = 0 | n = 1)
	=
	P_\text{R} \;
	\frac{\sin \theta_k}{2} \frac{1}{2 \pi} \\[4pt]
	\sqrt{\frac{2 \tau}{\pi}} \exp \left\{- \frac{q_k^2}{2} \tau \, \right\} \,.
\end{equation}
The acceptance ratio may thus be expressed as previously (\ref{eq:acceptanceRatioChangeOrder}) with
\begin{equation}
	\begin{split}
		R(n=0|n=1)
		&= \frac{D_{n=1}}{D_{n=0}} \frac{W(n=1|n=0)}{W(n=0|n=1)} \\[4pt]
		&=
		\frac{1 - P_\text{R}}{P_\text{R}}
		\frac{\alpha}{\sqrt \pi}
		\frac{1}{\sqrt{\tau}}
		\exp \big\{ [\langle \vec p \rangle_{l,m-1} \cdot \vec q_k - 1] \tau \big\} \,.
	\end{split}
\end{equation}

The transitions procedure between diagrams of order $ n > 0 $, as introduce in section \ref{eq:secSampleGBare}, can not add any external legs since both the start and end point node of the diagram will be connected to phonons. However, there are now $ 2n -1 $ rather than $ 2n + 1 $ number of $ \Gt_0 $'s to chose from when sampling the starting point time of the phonon propagator.
Hence the "$ 2n + 1 $" in equation (\ref{eq:transitionUp}) and (\ref{eq:changeOrderR}) should be replaced by "$ 2n - 1 $" to incorporate this.


\subsection{Divergent diagram}


It can be shown that the first order self energy diagram $ \Sigma^{*(1)}(\vec p, |tau) $ is proportional to $ 1 / \sqrt \tau $ and thus diverges when $ \tau \rightarrow 0 $. It is not possible to capture such a behavior using a histogram since the function to be approximated has a too large second derivative in the vicinity of the singularity. To show this, consider the mean value of a function $ f(x) $ on the interval $ x_i - \Delta x/2 < x < x_i + \Delta x/2 $ with $ f(x_i) $ expanded in terms of the small parameter $ \Delta x $, i.e.
\begin{equation}
	\begin{split}
		&\frac{1}{\Delta x} \bigintsss_{x_i - \Delta x/2}^{x_i + \Delta x/2} \mkern-36mu f(t) \diff t \\
		&\qquad= \frac{1}{\Delta x} \bigintsss_{x_i - \Delta x/2}^{x_i + \Delta x/2} \mkern-36mu f(x_i + [t - x_i]) \diff t \\
		&\qquad= \frac{1}{\Delta x} \bigintsss_{x_i - \Delta x/2}^{x_i + \Delta x/2} \mkern-36mu \left[ f(x_i) + f'(x_i) \, [t - x_i] + \tfrac{1}{2} f''(x_i) \, [t - x_i]^2 + \cdots \right] \diff t \\
		&\qquad= f(x_i) + \tfrac{1}{24} f''(x_i) \, [\Delta x]^2 + \mathcal{O}([\Delta x]^4) \,.
	\end{split}
\end{equation}
In order for this mean value to be well approximated by $ f(x_i) $, it is required that $ f''(x_i) \, [\Delta x]^2 \ll f(x_i) $. However, in the case of $ f(x) = 1/\sqrt x $ and $ x_i = \Delta x/2 $ this is not fulfilled, no matter the size of $ \Delta x $, since $ f''(x_i) \, [\Delta x]^2 = 3 \sqrt 2 / \sqrt{ \Delta x} $ whilst $ f(x_i) = 2 / \sqrt{\Delta x} $. The ability of a histogram to approximate the function $ 1/ \sqrt x $ in the vicinity of $ x = 0 $ is illustrated in figure \ref{fig:HistogramApproximationOfDivergentDistribution}.
\begin{figure}[H]
	\centering
 	\includegraphics[width=\textwidth, ]{{"Images/Histogram illustration/Divergent distribution"}.pdf}
	\caption{The function $ 1/ \sqrt x $ approximated by a histogram with bin size $ \Delta x  = 0.02 $ in the vicinity of $ x = 0 $. As can be seen, the approximative value at $ x_0 = 0.01 $ is quite far off from the true one.}
	\label{fig:HistogramApproximationOfDivergentDistribution}
\end{figure}

\image{Remove vertical lines for the legend to be true}

The true value of the first order self energy diagram at zero external momentum is
\begin{equation}
	\label{eq:prop1OSelfEnergy}
	\Sigma^{* (1)} (\vec p = \vec 0, \tau) = \frac{\alpha}{\sqrt \pi} \frac{e^{-(1 - \mu)\tau}}{\sqrt \tau}
	\quad \tau \geq 0\,.
\end{equation}
When approximating this function with a histogram of bin size $ \Delta \tau $, the value of the bin corresponding to $ \tau_i $ becomes
\begin{equation}
	\begin{split}
		&\langle \Sigma^{* (1)} (\vec p = \vec 0) \rangle_j \\
		&\qquad=
		\frac{1}{\Delta \tau} \bigintsss_{\tau_j - \Delta \tau/2}^{\tau_j + \Delta \tau/2} \mkern-36mu \Sigma^{* (1)} (\vec p = \vec 0, t) \diff t \\
		&\qquad= \frac{1}{\Delta \tau} \frac{\alpha}{\sqrt{1 - \mu}}
		\left[
			\text{erf} \left\{ \sqrt{(1 - \mu) \left( \tau_j + \tfrac{\Delta \tau}{2} \right) } \right\}
			- \text{erf} \left\{ \sqrt{(1 - \mu) \left( \tau_j - \tfrac{\Delta \tau}{2} \right) } \right\}
		\right]
	\end{split}
\end{equation}
However, for external momentum $ \vec p \neq \vec 0 $ it seems next to impossible to find an analytical expression of $ \Sigma^{* (1)} (\vec p, \tau) $ due to cumbersome integrals. Nevertheless, by the usage of Monte Carlo integration these integrals may be calculated to an extremely good precision in a matter of seconds.

In order to find out whether a value of $ \Sigma^{*(1)} (\vec p_i, \tau_j) $ should be calculated using DMC or Monte Carlo integration, it is reasonable to look at the difference $ \Delta \Sigma^{*(1)}_j = \langle \Sigma^{* (1)} (\vec p = \vec 0) \rangle_j  - \Sigma^{* (1)} (\vec p = \vec 0, \tau_j)$. For times $ \tau_j  < \tau_\text{threshold} $ where this difference is larger than a threshold value $ \varepsilon $, Monte Carlo integration should be used, otherwise DMC will be sufficient. The DMC code written during this master project has the threshold set to $ \varepsilon = 0.001 $. In table \ref{tab:SigmaDiffs} the value of $ \Delta \Sigma^{*(1)}_j $ is given for the first six $ j $'s. 
\begin{table}[H]
	\begin{center}
		\begin{tabular}{r !{\vrule width .1em} c | c | c | c | c | c | c} 
		 	$ j $ & 0 & 1 & 2 & 3 & 4 & 5 & 6 \\[2pt]
			\hline
			\rule{0pt}{3ex} $ \Delta \Sigma^{*(1)}_j $ & 2.34 & 0.0486 & 0.0133 & 0.0058 & 0.00314 & 0.00193 & 0.00129
		\end{tabular}
	\end{center}
	\caption{Here $ \Delta \Sigma^{*(1)}_j $ is calculated for different values of $ j $. The parameters used are $ \alpha = 1 $, $ \mu = -1.1 $ and $ \Delta \tau = 0.02 $.}
	\label{tab:SigmaDiffs}   
\end{table}

It is crucial that there will be no contribution from $ \Sigma^{*(1)} $ to the histogram $ N $ for times where it is calculated using Monte Carlo integration. However, to avoid such a double contribution it is as simple as to not bin a first order self energy diagram if the length $ \tau $ of which belongs to a bin $ N_{i,j} $ of time $ \tau_j < \tau_\text{threshold} $.

\subsection{Results}

Here follow some results obtained when simulating $ \Sigma^* $ using the bare scheme update procedures described above. For the same reasons as given before the external momentum $ \vec p $ has again been kept fixed during these simulations .


\begin{figure}[H]
	\centering
	\begin{subfigure}[b]{\textwidth}
		\includegraphics[width=\textwidth]{{"Images/Plots/St/St_a1_p0"}.pdf}
	\end{subfigure} \\
	\begin{subfigure}[b]{\textwidth}
		\includegraphics[width=\textwidth]{{"Images/Plots/St/St_a1_p15"}.pdf}
	\end{subfigure} \\
	\begin{subfigure}[b]{\textwidth}
		\includegraphics[width=\textwidth]{{"Images/Plots/St/St_a2_p0"}.pdf}
	\end{subfigure}
	\caption{The acquired value of $ \Sigma^*(p = 0, \, 0 \leq \tau \leq 5 ) $ after 80 minutes of core time. Here $ \tau_{max} = 40 $ and $ \Delta \tau = 0.02 $ has been used.}
	\label{fig:SOft}
\end{figure}


\begin{table}[H]
	\begin{center}
		\begin{tabular}{r | c | c | c} 
		 	$ \tau $ & $ \Sigma^*(0, 1, -1.1) $ & $ \Sigma^*(1.5, 1, -0.25) $ & $ \Sigma^*(0, 2, -2.2) $ \\ 
		 	\specialrule{.1em}{.05em}{.05em} 
0.01 & 5.531 & 5.537 & 10.96 \\
0.21 & 0.892 & 0.9145 & 1.591 \\
0.41 & 0.5063 & 0.5362 & 0.8721 \\
0.61 & 0.3417 & 0.3757 & 0.5845 \\
0.81 & 0.2484 & 0.2877 & 0.4318 \\
1.01 & 0.1889 & 0.2312 & 0.3366 \\
1.21 & 0.1481 & 0.1924 & 0.2724 \\
1.41 & 0.1184 & 0.1638 & 0.2249 \\
1.61 & 0.09575 & 0.1419 & 0.1887 \\
1.81 & 0.07845 & 0.1248 & 0.1613 \\
2.01 & 0.0643 & 0.1114 & 0.1377 \\
2.21 & 0.05323 & 0.0994 & 0.1191 \\
2.41 & 0.04421 & 0.08949 & 0.103 \\
2.61 & 0.03667 & 0.08083 & 0.08986 \\
2.81 & 0.03072 & 0.07354 & 0.07825 \\
3.01 & 0.02576 & 0.06704 & 0.06804 \\
3.21 & 0.02159 & 0.06117 & 0.05961 \\
3.41 & 0.01814 & 0.05634 & 0.05227 \\
3.61 & 0.01523 & 0.05141 & 0.046 \\
3.81 & 0.01287 & 0.04739 & 0.04028 \\
4.01 & 0.0109 & 0.04374 & 0.03547 \\
4.21 & 0.009089 & 0.04027 & 0.03091 \\
4.41 & 0.007704 & 0.03723 & 0.02729 \\
4.61 & 0.006375 & 0.03454 & 0.02392 \\
4.81 & 0.00551 & 0.03193 & 0.02108 \\
4.99 & 0.004662 & 0.02981 & 0.01871 \\
		\end{tabular}
	\end{center}
	\caption{Some values of $ \Sigma^*(p, \alpha, \mu) $ from the plots in figure \ref{fig:SOft}.}
	\label{tab:truthTables}   
\end{table}

\subsection{Implementing Dyson equation numerically}

It is not entirely trivial how to implement Dyson equation when having to use a discrete Fourier transform. First of all, the proper self energy must be transformed into frequency space, but due to the singularity at $ \tau = 0 $ it is not preferable to transform this quantity directly. However, knowing the analytical expression of this singular contribution, it can then be subtracted from the self energy so that the discrete Fourier transform may be applied to the resulting regular expression. The singular part is then Fourier transformed analytically and once in $ \omega $-space it is added to the transformed regular expression. That is,
\begin{equation}
	\Sigma^{*}(\vec p_i, \omega_j)
	= \mathcal{F}_\text{DFT} \left\{ \Sigma^{*}(\vec p_i, \tau_j) - \Sigma^{*}_\text{singular}(\vec p_i, \tau_j) \right\}
	+ \Sigma^{*}_\text{singular}(\vec p_i, \omega_j) \,,
\end{equation}
which is possible due to the linearity of the Fourier transform. A possible choice of the singular part is $ \Sigma^{*}_\text{singular}(\vec p_i, \tau_j) = \Sigma^{*(1)}(\vec p = \vec 0, \tau_j) $ for which the expression is (\ref{eq:prop1OSelfEnergy}) and thus
\begin{equation}
	\Sigma^{*}_\text{singular}(\vec p_i, \omega_j) = \frac{\alpha}{\sqrt{1 - \mu + i\omega_j}} \,.
\end{equation}

Having the proper self energy in momentum and frequency space, Dyson equation is given by (\ref{eq:dysonEquation}). However, it is not possible to directly transform back to $ \Gt(\vec p_i, \tau_j) $ using the inverse discrete Fourier transform. This has to do with the fact that $ \Gt(\vec p, \omega) $ falls of as $ 1/\omega $ when $ \omega \rightarrow \infty $, which it too slow. Instead one may transform the difference
\begin{equation}
	\Delta \Gt(\vec p, \omega)
	= \Gt(\vec p, \omega) - \Gt_0(\vec p, \omega)
	= \frac{\Sigma^*(\vec p, \omega)}{\left( i \omega + \xi(\vec p) - \Sigma^*(\vec p, \omega) \right) \left( i \omega + \xi(\vec p) \right)}
\end{equation}
which has the proportionality $ \Delta \Gt(\vec p, \omega \rightarrow \infty) \propto \omega^{-5/2} $ because $ \Sigma^*(\vec p, \omega \rightarrow \infty) \propto \omega^{-1/2} $. Since also the inverse Fourier transform is linear, it follows that
\begin{equation}
	\mathcal{F}^{-1}_{DFT} \left\{ \Delta \Gt(\vec p_i, \omega_j) \right\} = \Delta \Gt(\vec p_i, \tau_j) = \Gt(\vec p_i, \tau_j) - \Gt_0(\vec p_i, \tau_j) \,.
\end{equation}
The interacting electronic propagator in $ \tau $-space is finally obtained by
\begin{equation}
	\Gt(\vec p_i, \tau_j) = \Gt_0(\vec p_i, \tau_j) + \Delta \Gt(\vec p_i, \tau_j) \,.
\end{equation}

In figure \ref{fig:dysonDifference} the relative difference between the $ \Gt_{\Sigma^*} $ obtained using Dyson equation and the directly simulated $ \Gt $ is plotted against $ \tau $ for both $ \Delta \tau = 0.02 $ and $ \Delta \tau = 0.01 $. As can be seen the difference is smaller than the size of $ \Delta \tau $ in both cases. The agreement also seems to improve somewhat linearly with smaller $ \Delta \tau $, the drawback is however more noise since there is less statistics contributing to each bin $ N_j $.
\begin{figure}[H]
	\centering
	\begin{subfigure}[b]{\textwidth}
		\includegraphics[width=\textwidth]{{"Images/Plots/GfromSminusG/dt=0.02"}.pdf}
	\end{subfigure} \\
	\begin{subfigure}[b]{\textwidth}
		\includegraphics[width=\textwidth]{{"Images/Plots/GfromSminusG/dt=0.01"}.pdf}
	\end{subfigure}
	\caption{The relative difference between $ \Gt_{\Sigma^*} $ obtained using Dyson equation and the directly simulated $ \Gt $. For each of these simulations a core time of 24 hours has been used.}
	\label{fig:dysonDifference}
\end{figure}

\section{Bold-line scheme \question{?}}

The bold-line scheme \cite{PhysRevLett.99.250201} is a self consistent scheme making use of bold-line tricks iteratively in order to partially of fully sum up a diagram series. Dyson equation is one such bold-line trick and is the only one to be investigated in this thesis.

Here the propagator  $ \Gt_{k + 1} = \Gt^{(0)} + \Delta \Gt_{k + 1} $  is obtained when employing Dyson equation to the self energy $ S_{k+1} $, made up of self energy diagrams subjected to certain constraints in order to prevent double counting. However, rather than using the bare propagator when calculating $ S_{k+1} $, the $ \Gt_k $ computed in the previous iteration of the scheme is instead used. During the first iteration, when no propagator previously have been calculated, the bare one is used, i.e. $ \Gt_0 = \Gt^{(0)} $. This scheme will converge given an appropriate choice of parameters so that $ S_{m+1} \simeq S_{m} $ for some $ m $. In practice, as will be shown, this convergence will happen after 4 or so iterations.

\subsection{Skeleton diagrams}

In order for certain diagrams to not contribute more than once to the $ \Gt_k $, it is necessary to narrow down the class of allowed diagrams to a subclass of the proper self energy diagrams, referred to as skeleton diagrams \cite{mattuck2012guide}. This class of diagrams is characterized by the lack of insertions, i.e. diagram parts which act like self energies to some of the constituents of the diagram. It is easily realized, that the skeleton diagrams in the series of $ \Gt $ are particularly easy to identify. That is, if the phonon propagators of a self energy diagram are entirely interconnected, the diagram is a skeleton one. Here interconnected phonon propagator is referred to those who intersect with at least another one when they are all drawn on one side of the straight line of electronic propagators, as done throughout this paper. This is illustrated in figure \ref{fig:sampleSkeletonDiagrams}.
\begin{figure}[H]
	\centering
	\begin{subfigure}[b]{0.499\textwidth}%
		\begin{center}
			\begin{fmffile}{FMFFILEsampleSkeletonDiagramA}%
				\FDframe{%
					\begin{fmfgraph*}(50, 20)
						\fmfstraight
						\fmfbottom{i,o}
						\fmf{fermion}{i,v1}
						\fmf{fermion, foreground=(1,,0,,1)}{v1,v2}
						\fmf{fermion}{v2,v3}
						\fmf{fermion}{v3,v4}
						\fmf{fermion}{v4,o}
						\fmf{dashes, left, tension=0}{i,v4}
						\fmf{dashes, left, tension=0, foreground=(1,,0,,1)}{v1,v2}
						\fmf{dashes, left, tension=0}{v3,o}
						\fmfdot{i,o,v1,v2,v3,v4}
						\fmfv{foreground=(1,,0,,1)}{v1}
						\fmfv{foreground=(1,,0,,1)}{v2}
					\end{fmfgraph*}%
				}
			\end{fmffile}%
		\end{center}
	\end{subfigure}\hfill
	\begin{subfigure}[b]{0.499\textwidth}
		\begin{center}
			\begin{fmffile}{FMFFILEsampleSkeletonDiagramB}
				\FDframe{
					\begin{fmfgraph*}(50, 20)
						\fmfstraight
						\fmfbottom{i,o}
						\fmf{fermion}{i,v1}
						\fmf{fermion}{v1,v2}
						\fmf{fermion}{v2,v3}
						\fmf{fermion}{v3,v4}
						\fmf{fermion}{v4,o}
						\fmf{dashes, left, tension=0}{i,v4}
						\fmf{dashes, left, tension=0}{v1,v3}
						\fmf{dashes, left, tension=0}{v2,o}
						\fmfdot{i,o,v1,v2,v3,v4}
					\end{fmfgraph*}%
				}
			\end{fmffile}%
		\end{center}
	\end{subfigure} \\[2em]
	\begin{subfigure}[b]{0.499\textwidth}
		\begin{center}
			\begin{fmffile}{FMFFILEsampleSkeletonDiagramC}
				\FDframe{
					\begin{fmfgraph*}(50, 25)
						\fmfstraight
						\fmfbottom{i,o}
						\fmf{fermion}{i,v1}
						\fmf{fermion, foreground=(1,,0,,1)}{v1,v2}
						\fmf{fermion, foreground=(1,,0,,1)}{v2,v3}
						\fmf{fermion, foreground=(1,,0,,1)}{v3,v4}
						\fmf{fermion}{v4,o}
						\fmf{dashes, left, tension=0}{i,o}
						\fmf{dashes, left, tension=0, foreground=(1,,0,,1)}{v1,v3}
						\fmf{dashes, left, tension=0, foreground=(1,,0,,1)}{v2,v4}
						\fmfdot{i,o,v1,v2,v3,v4}
						\fmfv{foreground=(1,,0,,1)}{v1}
						\fmfv{foreground=(1,,0,,1)}{v2}
						\fmfv{foreground=(1,,0,,1)}{v3}
						\fmfv{foreground=(1,,0,,1)}{v4}
					\end{fmfgraph*}%
				}
			\end{fmffile}%
		\end{center}
	\end{subfigure}\hfill
	\begin{subfigure}[b]{0.499\textwidth}
		\begin{center}
			\begin{fmffile}{FMFFILEsampleSkeletonDiagramD}
				\FDframe{
					\begin{fmfgraph*}(50, 25)
						\fmfstraight
						\fmfbottom{i,o}
						\fmf{fermion}{i,v1}
						\fmf{fermion}{v1,v2}
						\fmf{fermion}{v2,v3}
						\fmf{fermion}{v3,v4}
						\fmf{fermion}{v4,o}
						\fmf{dashes, left, tension=0}{i,v2}
						\fmf{dashes, left, tension=0}{v1,v4}
						\fmf{dashes, left, tension=0}{v3,o}
						\fmfdot{i,o,v1,v2,v3,v4}
					\end{fmfgraph*}%
				}
			\end{fmffile}%
		\end{center}
	\end{subfigure}
	\caption{The diagrams to the left belong to the class of skeleton diagrams whilst the ones to the right merely belong to the class of proper self energy diagrams. The insertions of the proper self energy diagrams are here highlighted.}
	\label{fig:sampleSkeletonDiagrams}
\end{figure}

Even by restricting to merely a subset of skeleton diagrams, bounded by the diagram order $ n \leq n_\text{max} $, the range of diagrams contributing to $ \Gt_k $ will grow extremely fast with the bold-line iteration $ k $. This will now be demonstrated in the case of $ n_\text{max} = 1 $.

\noindent \textbf{First iteration}
\begin{fmffile}{FMFFILEfirstIterationGandS}
	\begin{empheq}[box={\FDbox[0pt][0pt]}]{equation}
		\label{eq:BoldG1}
		\begin{split}
			S_1
			&=
			\begin{tikzpicture}[baseline={([yshift=-.5ex]current bounding box.center)}]
				\node {
					\FDframe{
						\begin{fmfgraph*}(11, 6)
							\fmfbottom{b1,b2}
							\fmf{fermion}{b1,b2}
							\fmf{dashes, left}{b1,b2}
							\fmfdot{b1,b2}
						\end{fmfgraph*}%
					}
				};%
			\end{tikzpicture} \\
			\Gt_1
			&=
			\begin{tikzpicture}[baseline={([yshift=1pt]current bounding box.south)}]
				\node {
					\FDframe{
						\begin{fmfgraph*}(11, 1)
							\fmfstraight
							\fmfbottom{i,o}
							\fmf{heavy, foreground=(1,,0,,0)}{i,o}
						\end{fmfgraph*}%
					}%
				};
			\end{tikzpicture} \\
			&=
			\begin{tikzpicture}[baseline={([yshift=1pt]current bounding box.south)}]
				\node {
					\FDframe{
						\begin{fmfgraph*}(11, 1)
							\fmfstraight
							\fmfbottom{i,o}
							\fmf{fermion}{i,o}
						\end{fmfgraph*}%
					}%
				};%
    			\end{tikzpicture}
			+
		    	\begin{tikzpicture}[baseline={([yshift=1pt]current bounding box.south)}]
				\node {
					\FDframe{
						\begin{fmfgraph*}(33, 5.5)
							\fmfstraight
							\fmfbottom{i,o}
							\fmf{fermion}{i,v1}
							\fmf{fermion}{v1,v2}
							\fmf{fermion}{v2,o}
							\fmf{dashes, left, tension=0}{v1,v2}
							\fmfdot{v1,v2}
						\end{fmfgraph*}%
					}%
				};%
			\end{tikzpicture}
			+
			\begin{tikzpicture}[baseline={([yshift=1pt]current bounding box.south)}]
				\node {
					\FDframe{
						\begin{fmfgraph*}(55, 5.5)
							\fmfstraight
							\fmfbottom{i,o}
							\fmf{fermion}{i,v1}
							\fmf{fermion}{v1,v2}
 							\fmf{fermion}{v2,v3}
							\fmf{fermion}{v3,v4}
							\fmf{fermion}{v4,o}
							\fmf{dashes, left, tension=0}{v1,v2}
							\fmf{dashes, left, tension=0}{v3,v4}
							\fmfdot{v1,v2,v3,v4}
						\end{fmfgraph*}%
					}%
				};%
			\end{tikzpicture} \\
			&+ \cdots
		\end{split}
	\end{empheq}
\end{fmffile}

\noindent \textbf{Second iteration}
\begin{fmffile}{FMFFILEsecondIterationGandS}
	\begin{empheq}[box={\FDbox[0pt][0pt]}]{equation*}
		\begin{split}
			S_2 &=
			\begin{tikzpicture}[baseline={([yshift=-.5ex]current bounding box.center)}]
				\node {
					\FDframe{
						\begin{fmfgraph*}(11, 6)
							\fmfbottom{b1,b2}
							\fmf{heavy, foreground=(1,,0,,0)}{b1,b2}
							\fmf{dashes, left}{b1,b2}
							\fmfdot{b1,b2}
						\end{fmfgraph*}%
					}
				};%
			\end{tikzpicture} \\
			\Gt_2
			&=
			\begin{tikzpicture}[baseline={([yshift=1pt]current bounding box.south)}]
				\node {
					\FDframe{
						\begin{fmfgraph*}(11, 1)					
							\fmfstraight
							\fmfbottom{i,o}
							\fmf{heavy, foreground=(0,,0,,1)}{i,o}
						\end{fmfgraph*}%
					}%
				};
			\end{tikzpicture} \\
			&=
			\begin{tikzpicture}[baseline={([yshift=1pt]current bounding box.south)}]
				\node {
					\FDframe{
						\begin{fmfgraph*}(11, 1)					
							\fmfstraight
							\fmfbottom{i,o}
							\fmf{fermion}{i,o}
						\end{fmfgraph*}%
					}%
				};%
    			\end{tikzpicture}
			+
		    	\begin{tikzpicture}[baseline={([yshift=1pt]current bounding box.south)}]
				\node {
					\FDframe{
						\begin{fmfgraph*}(33, 5.5)					
							\fmfstraight
							\fmfbottom{i,o}
							\fmf{fermion}{i,v1}
							\fmf{heavy, foreground=(1,,0,,0)}{v1,v2}
							\fmf{fermion}{v2,o}
							\fmf{dashes, left, tension=0}{v1,v2}
							\fmfdot{v1,v2}
						\end{fmfgraph*}%
					}%
				};%
			\end{tikzpicture}
			+
			\begin{tikzpicture}[baseline={([yshift=1pt]current bounding box.south)}]
				\node {
					\FDframe{
						\begin{fmfgraph*}(55, 5.5)
							\fmfstraight
							\fmfbottom{i,o}
							\fmf{fermion}{i,v1}
							\fmf{heavy, foreground=(1,,0,,0)}{v1,v2}
 							\fmf{fermion}{v2,v3}
							\fmf{heavy, foreground=(1,,0,,0)}{v3,v4}
							\fmf{fermion}{v4,o}
							\fmf{dashes, left, tension=0}{v1,v2}
							\fmf{dashes, left, tension=0}{v3,v4}
							\fmfdot{v1,v2,v3,v4}
						\end{fmfgraph*}%
					}%
				};%
			\end{tikzpicture} \\
			&+ \cdots \,.
		\end{split}
	\end{empheq}
\end{fmffile}%
By substituting with $ \Gt_1 $ in terms of the diagram series (\ref{eq:BoldG1}) into the diagram series of $ \Gt_2 $, this series, expressed in terms of the bare constituents, becomes
\begin{fmffile}{FMFFILEsecondIterationG}
	\begin{empheq}[box={\FDbox[0pt][0pt]}]{equation*}
		\begin{split}
			\Gt_2
			&=
			\Gt_1 \\
			&+
			\begin{tikzpicture}[baseline={([yshift=1pt]current bounding box.south)}]
				\node {
					\FDframe{
						\begin{fmfgraph*}(55, 16.5)
							\fmfstraight
							\fmfbottom{i,o}
							\fmf{fermion}{i,v1}
							\fmf{fermion}{v1,v2}
 							\fmf{fermion}{v2,v3}
							\fmf{fermion}{v3,v4}
							\fmf{fermion}{v4,o}
							\fmf{dashes, left, tension=0}{v1,v4}
							\fmf{dashes, left, tension=0}{v2,v3}
							\fmfdot{v1,v2,v3,v4}
						\end{fmfgraph*}%
					}%
				};%
			\end{tikzpicture} \\
			&+
			\begin{tikzpicture}[baseline={([yshift=1pt]current bounding box.south)}]
				\node {
					\FDframe{
						\begin{fmfgraph*}(77, 27.5)
							\fmfstraight
							\fmfbottom{i,o}
							\fmf{fermion}{i,v1}
							\fmf{fermion}{v1,v2}
 							\fmf{fermion}{v2,v3}
							\fmf{fermion}{v3,v4}
							\fmf{fermion}{v4,v5}
							\fmf{fermion}{v5,v6}
							\fmf{fermion}{v6,o}
							\fmf{dashes, left, tension=0}{v1,v6}
							\fmf{dashes, left, tension=0}{v2,v3}
							\fmf{dashes, left, tension=0}{v4,v5}
							\fmfdot{v1,v2,v3,v4,v5,v6}
						\end{fmfgraph*}%
					}%
				};%
			\end{tikzpicture}
			+ \cdots \\
			&+
			\begin{tikzpicture}[baseline={([yshift=1pt]current bounding box.south)}]
				\node {
					\FDframe{
						\begin{fmfgraph*}(77, 16.5)
							\fmfstraight
							\fmfbottom{i,o}
							\fmf{fermion}{i,v1}
							\fmf{fermion}{v1,v2}
 							\fmf{fermion}{v2,v3}
							\fmf{fermion}{v3,v4}
							\fmf{fermion}{v4,v5}
							\fmf{fermion}{v5,v6}
							\fmf{fermion}{v6,o}
							\fmf{dashes, left, tension=0}{v1,v4}
							\fmf{dashes, left, tension=0}{v2,v3}
							\fmf{dashes, left, tension=0}{v5,v6}
							\fmfdot{v1,v2,v3,v4,v5,v6}
						\end{fmfgraph*}%
					}%
				};%
			\end{tikzpicture}
			+ \cdots \,.
		\end{split}
	\end{empheq}
\end{fmffile}%

\noindent \textbf{Third iteration}
\begin{fmffile}{FMFFILEthirdIterationGandS}
	\begin{empheq}[box={\FDbox[0pt][0pt]}]{equation*}
		\begin{split}
			S_3 &=
			\begin{tikzpicture}[baseline={([yshift=-.5ex]current bounding box.center)}]
				\node {
					\FDframe{
						\begin{fmfgraph*}(11, 6)
							\fmfbottom{b1,b2}
							\fmf{heavy, foreground=(0.8,,0.2,,1)}{b1,b2}
							\fmf{dashes, left}{b1,b2}
							\fmfdot{b1,b2}
						\end{fmfgraph*}%
					}
				};%
			\end{tikzpicture} \\
			\Gt_3
			&=
			\begin{tikzpicture}[baseline={([yshift=1pt]current bounding box.south)}]
				\node {
					\FDframe{
						\begin{fmfgraph*}(11, 1)					
							\fmfstraight
							\fmfbottom{i,o}
							\fmf{heavy, foreground=(0,,0,,1)}{i,o}
						\end{fmfgraph*}%
					}%
				};
			\end{tikzpicture} \\
			&=
			\begin{tikzpicture}[baseline={([yshift=1pt]current bounding box.south)}]
				\node {
					\FDframe{
						\begin{fmfgraph*}(11, 1)					
							\fmfstraight
							\fmfbottom{i,o}
							\fmf{fermion}{i,o}
						\end{fmfgraph*}%
					}%
				};%
    			\end{tikzpicture}
			+
		    	\begin{tikzpicture}[baseline={([yshift=1pt]current bounding box.south)}]
				\node {
					\FDframe{
						\begin{fmfgraph*}(33, 5.5)					
							\fmfstraight
							\fmfbottom{i,o}
							\fmf{fermion}{i,v1}
							\fmf{heavy, foreground=(0,,0,,1)}{v1,v2}
							\fmf{fermion}{v2,o}
							\fmf{dashes, left, tension=0}{v1,v2}
							\fmfdot{v1,v2}
						\end{fmfgraph*}%
					}%
				};%
			\end{tikzpicture}
			+
			\begin{tikzpicture}[baseline={([yshift=1pt]current bounding box.south)}]
				\node {
					\FDframe{
						\begin{fmfgraph*}(55, 5.5)
							\fmfstraight
							\fmfbottom{i,o}
							\fmf{fermion}{i,v1}
							\fmf{heavy, foreground=(0,,0,,1)}{v1,v2}
 							\fmf{fermion}{v2,v3}
							\fmf{heavy, foreground=(0,,0,,1)}{v3,v4}
							\fmf{fermion}{v4,o}
							\fmf{dashes, left, tension=0}{v1,v2}
							\fmf{dashes, left, tension=0}{v3,v4}
							\fmfdot{v1,v2,v3,v4}
						\end{fmfgraph*}%
					}%
				};%
			\end{tikzpicture} \\
			&+ \cdots \,.
		\end{split}
	\end{empheq}
\end{fmffile}%
Similarly to before, by substituting with $ \Gt_2 $ into $ \Gt_3 $, one obtains 
\begin{fmffile}{FMFFILEthirdIterationG}
	\begin{empheq}[box={\FDbox[0pt][0pt]}]{equation*}
		\begin{split}
			\Gt_3
			&=
			\Gt_2 \\
			&+
			\begin{tikzpicture}[baseline={([yshift=1pt]current bounding box.south)}]
				\node {
					\FDframe{
						\begin{fmfgraph*}(77, 27.5)
							\fmfstraight
							\fmfbottom{i,o}
							\fmf{fermion}{i,v1}
							\fmf{fermion}{v1,v2}
 							\fmf{fermion}{v2,v3}
							\fmf{fermion}{v3,v4}
							\fmf{fermion}{v4,v5}
							\fmf{fermion}{v5,v6}
							\fmf{fermion}{v6,o}
							\fmf{dashes, left, tension=0}{v1,v6}
							\fmf{dashes, left, tension=0}{v2,v5}
							\fmf{dashes, left, tension=0}{v3,v4}
							\fmfdot{v1,v2,v3,v4,v5,v6}
						\end{fmfgraph*}%
					}%
				};%
			\end{tikzpicture} \\
			&+
			\begin{tikzpicture}[baseline={([yshift=1pt]current bounding box.south)}]
				\node {
					\FDframe{
						\begin{fmfgraph*}(99, 38.5)
							\fmfstraight
							\fmfbottom{i,o}
							\fmf{fermion}{i,v1}
							\fmf{fermion}{v1,v2}
 							\fmf{fermion}{v2,v3}
							\fmf{fermion}{v3,v4}
							\fmf{fermion}{v4,v5}
							\fmf{fermion}{v5,v6}
							\fmf{fermion}{v6,v7}
							\fmf{fermion}{v7,v8}
							\fmf{fermion}{v8,o}
							\fmf{dashes, left, tension=0}{v1,v8}
							\fmf{dashes, left, tension=0}{v2,v5}
							\fmf{dashes, left, tension=0}{v3,v4}
							\fmf{dashes, left, tension=0}{v6,v7}
							\fmfdot{v1,v2,v3,v4,v5,v6,v7,v8}
						\end{fmfgraph*}%
					}%
				};%
			\end{tikzpicture}
			+ \cdots \,.
		\end{split}
	\end{empheq}
\end{fmffile}%
Already at this point, a wide range of diagrams contribute to $ \Gt_3 $. However, even if one continues this iterative process, a skeleton diagram of order $ n > 1 $ in which phonon propagators intersect wont be encountered in the series.

\subsection{Implementation}

The diagram update procedures, for bold-line iterations $ k > 1 $, need to be altered in order to account for the replacement of the bare propagators within the diagram in favor of $ \Gt_i $. However, rather than expressing $ \Gt_i $ in terms of the difference $ \Delta \Gt_k $ to the bare propagator, it is more convenient to work with an additional imaginary phase $ \varphi_k (\vec p, \tau) $, so that
\begin{equation}
	\Gt_k(\vec p, \tau) = e^{\varphi_k (\vec p, \tau)} \Gt^{(0)}(\vec p, \tau) \,.
\end{equation}
This phase is defined through
\begin{equation}
	\label{eq:imaginaryPhase}
	\varphi(\vec p, \tau) = - \tau \, \Delta \xi_k( p_l, \tau_m)
\end{equation}
where $ \Delta \xi_k $ is an additional energy
\begin{equation}
	\Delta \xi_k(\vec p_i, \tau_j) = \frac{1}{\tau_j} \log \frac{\Gt^{(0)}(\vec p_i, \tau_j)}{\Gt_k(\vec p_i, \tau_j)} \,.
\end{equation}
In equation (\ref{eq:imaginaryPhase}), $ p_l $ and $ \tau_m $ are chosen to obey $ p_l - \tfrac{1}{2} \Delta p \leq p \leq p_l + \tfrac{1}{2} \Delta p $ and $ \tau_m - \tfrac{1}{2} \Delta \tau \leq \tau \leq \tau_m + \tfrac{1}{2} \Delta $ respectively. However, in the case of momentum magnitudes $ p > p_{N-1} + \tfrac{1}{2} \Delta p $, it is natural to use $ p_{N-1} $. During the discretization it is then important to chose a large enough cutoff momentum $ p_\text{max} $ in order for the true $ G_k(\vec p, \tau) $ to be reasonably approximated by $ e^{\varphi_k (\vec p, \tau)} \Gt^{(0)}(\vec p, \tau) $ at momentum magnitudes $ p > p_{N-1} + \tfrac{1}{2} \Delta p $. Thus, if the $ p_\text{max} $ is chosen to small, the $ \Gt_k $ wont converge to the true interacting propagator $ \Gt $.

Now, with $ \Gt_k (\vec p, \tau) $ defined in this way, the only modification needed in order for the update procedures to reflect the change $ \Gt^{(0)} \rightarrow \Gt_k $, is to multiply the quota of the diagram values $ D'/ D $ with the factor
\begin{equation}
	\exp \left\{ \sum_{a \in A} \varphi(\vec p_a, \tau_a) - \sum_{b \in B} \varphi(\vec p_b, \tau_b) \right\} \,.
\end{equation}
Here $ B $ and $ A $ is the set of affected electronic propagators before and after the update procedure respectively.

But wait, there is more. Update procedures involving the sampling of imaginary-times from an exponential distribution with momentum dependent rate parameter must further be slightly modified in order to improve the otherwise disastrous statistics. This since the quota $ W(\tau'_l | \tau_l) / W(\tau_l | \tau'_l) = \exp \{ -\lambda (\tau_l - \tau'_l) \}$, for certain differences $ \tau_l - \tau'_l $, poorly mimics the ratio $ D(\tau'_l) / D(\tau_l) $ due to the choice of rate parameter $ \lambda(\vec p) $. This is easily realized by comparing the $ \Gt(\vec p, \tau) $'s in figure \ref{fig:GOft} to their corresponding bare propagators $ \Gt^{(0)}(\vec p, \tau) $. In order to resolve this issue, one adds to the the original rate parameter the contribution $ \Delta \lambda_k(\vec p_l) $, which is obtained by fitting an exponentially decaying function $ C_k(\vec p_l)  \exp \{ - \Delta \lambda_k(\vec p_l) \, \tau \} $ to $ \Gt_k(\vec p_l, \tau_j) / \Gt^{(0)} (\vec p_l, \tau_j) $ for each $ \vec p_l $. Again $ p_l - \tfrac{1}{2} \Delta p \leq p \leq p_l + \tfrac{1}{2} \Delta p $ and $ p_{N-1} $ is used for $ p > p_{N-1} + \tfrac{1}{2} \Delta p $.

After each bold-line iteration, when calculating the value of $ S_{k+1}(\vec p_i, \tau_j) $ from $ N_{i,j} $, it is important to normalize using $ \Gt_k $ rather than the bare propagator $ \Gt^{(0)} $. Hence, in similarity with (\ref{eq:properSnormalization}),
\begin{equation}
	S_{k+1} (\vec p_i, \tau_j) = N_{i,j} \frac{\sum_{l,m} \Gt_k (\vec p_l, \tau_m)}{N_0} \,.
\end{equation}
Equally important for this to be true, is to make sure that only skeleton diagrams contribute to incrementing the bins $ N_{i,j} $ of the histogram.


\subsection{Results}

Nine different simulations for an increasing value of the maximum diagram order $ n_\text{max} $ has been carried out using the discretization $ \Delta \tau = 0.02 $, $ \Delta p = 0.02 $, $ p_\text{max} = 10 $ and $ \tau_\text{max} = 60 $. With larger $ n_\text{max} $, the statistics became significantly more contaminated by noise. Thus, in order to try and suppress this noise, the computation for each iteration in the bold-line scheme needed to be increased. The number of core hours needed quickly outgrew what was possible to calculate using a single core in a foreseeable future, hence the code was parallelized using the \textit{Message Passing Interface} (MPI).

Depicted in figures \ref{fig:boldNmax1} to \ref{fig:boldNmax9} are the obtained values of $ S_k $'s, as well as the corresponding $ \Gt_k $'s, for an increasing value of $ n_\text{max} $. The proper self energy $ \Sigma^* $ and the interacting Greens function, acquired using Dyson equation, $ \Gt $ are also outlined.

\begin{figure}[H]
	\centering
	\begin{subfigure}[b]{\textwidth}
		\includegraphics[width=\textwidth]{{"Images/Plots/bold/boldplot_a_nmax=1_p=0.01"}.pdf}
	\end{subfigure}
	\caption{A total core time of 13 days was used for each of the four iterations in the bold-line scheme.}
	\label{fig:boldNmax1}
\end{figure}

\begin{figure}[H]
	\centering
	\begin{subfigure}[b]{\textwidth}
		\includegraphics[width=\textwidth]{{"Images/Plots/bold/boldplot_a_nmax=2_p=0.01"}.pdf}
	\end{subfigure}
	\caption{A total core time of 13 days was used for each of the four iterations in the bold-line scheme.}
	\label{fig:boldNmax2}
\end{figure}

\begin{figure}[H]
	\centering
	\begin{subfigure}[b]{\textwidth}
		\includegraphics[width=\textwidth]{{"Images/Plots/bold/boldplot_a_nmax=3_p=0.01"}.pdf}
	\end{subfigure}
	\caption{A total core time of 15 days was used for each of the four iterations in the bold-line scheme.}
	\label{fig:boldNmax3}
\end{figure}

\begin{figure}[H]
	\centering
	\begin{subfigure}[b]{\textwidth}
		\includegraphics[width=\textwidth]{{"Images/Plots/bold/boldplot_a_nmax=4_p=0.01"}.pdf}
	\end{subfigure}
	\caption{A total core time of 15 days was used for each of the four iterations in the bold-line scheme.}
	\label{fig:boldNmax4}
\end{figure}

\begin{figure}[H]
	\centering
	\begin{subfigure}[b]{\textwidth}
		\includegraphics[width=\textwidth]{{"Images/Plots/bold/boldplot_a_nmax=5_p=0.01"}.pdf}
	\end{subfigure}
	\caption{A total core time of 15 days was used for each of the four iterations in the bold-line scheme.}
	\label{fig:boldNmax5}
\end{figure}

\begin{figure}[H]
	\centering
	\begin{subfigure}[b]{\textwidth}
		\includegraphics[width=\textwidth]{{"Images/Plots/bold/boldplot_a_nmax=6_p=0.01"}.pdf}
	\end{subfigure}
	\caption{A total core time of 28 days was used for each of the four iterations in the bold-line scheme.}
	\label{fig:boldNmax6}
\end{figure}

\begin{figure}[H]
	\centering
	\begin{subfigure}[b]{\textwidth}
		\includegraphics[width=\textwidth]{{"Images/Plots/bold/boldplot_a_nmax=7_p=0.01"}.pdf}
	\end{subfigure}
	\caption{A total core time of 44 days was used for each of the four iterations in the bold-line scheme.}
	\label{fig:boldNmax7}
\end{figure}

\begin{figure}[H]
	\centering
	\begin{subfigure}[b]{\textwidth}
		\includegraphics[width=\textwidth]{{"Images/Plots/bold/boldplot_a_nmax=8_p=0.01"}.pdf}
	\end{subfigure}
	\caption{A total core time of 65 days was used for each of the four iterations in the bold-line scheme.}
	\label{fig:boldNmax8}
\end{figure}

\begin{figure}[H]
	\centering
	\begin{subfigure}[b]{\textwidth}
		\includegraphics[width=\textwidth]{{"Images/Plots/bold/boldplot_a_nmax=9_p=0.01"}.pdf}
	\end{subfigure}
	\caption{A total core time of 203 days was used for each of the four iterations in the bold-line scheme.}
	\label{fig:boldNmax9}
\end{figure}

Evident from these figures, is that $ S_k $ approaches $ \Sigma^* $ as both the bold-line iteration $ k $ and the maximum diagram order $ n_\text{max} $ become larger, just as expected. However, even though an awful amount of computation time was used to calculate the $ S_k $'s for $ n_\text{max} = 8, \, 9 $, it seems that it was not enough since there is still much noise present.

By fitting the logarithm of these $ \Gt_k $'s to a straight line $ y = k \tau + m $ at large imaginary-times, one can extract the corresponding $ E_0(n_\text{max}, k) $ and $ Z_0(n_\text{max}, k) $ using (\ref{eq:longTimeLimit}). This has been done an the result is presented in figures \ref{fig:EandZvsN} and \ref{fig:EandZvsK}.

\begin{figure}[H]
	\centering
	\begin{subfigure}[b]{\textwidth}
		\includegraphics[width=\textwidth]{{"Images/Plots/Quantities/BoldE0andZ0vsN"}.pdf}
	\end{subfigure}
	\caption{Here $ E_0(n_\text{max}, k) $ and $ Z_0(n_\text{max}, k) $ obtained from the bold-line simulations are shown next to the true values $ E_0 $ and $ Z_0 $.}
	\label{fig:EandZvsN}
\end{figure}

\begin{figure}[H]
	\centering
	\begin{subfigure}[b]{\textwidth}
		\includegraphics[width=\textwidth]{{"Images/Plots/Quantities/BoldE0andZ0vsK"}.pdf}
	\end{subfigure}
	\caption{Here $ E_0(n_\text{max}, k) $ and $ Z_0(n_\text{max}, k) $  obtained from the bold-line simulations are shown next to the true values $ E_0 $ and $ Z_0 $.}
	\label{fig:EandZvsK}
\end{figure}

Unfortunately there was only four iterations used in the bold-line scheme, which according to figure \ref{fig:EandZvsK} was not enough to reach a steady state value for $ E_0 $ and $ Z_0 $. This steady state could nevertheless not have been very far away, by the looks of it a fifth or perhaps a sixth iteration would probably have been sufficient for the trends in that figure to level out. Additionally, it would presumably also have been necessary to use a larger $ n_\text{max} $ in order to overlap with the curves of the true $ E_0 $ and $ Z_0 $. Such a computation would however require an immense amount of computation time in order for the error bars to be of satisfactory size which was also the reason for it not being carried out. The quantities obtained after the fourth iteration with $ n_\text{max} = 8, 9 $ already have a bit too much uncertainty in them due to the noisy statistics.

Even with these shortcomings, it is from the presented result apparent that $ E_0(n_\text{max}, k) $ and $ Z_0(n_\text{max}, k) $ approach the true values $ E_0 $ and $ Z_0 $ respectively as $ n_\text{max} $ and $ k $ increase.

\section{Numerical \question{and analytical (!?)} Results}

This thesis would not be complete without presenting some general quantities of interest to do with the polaron. Here numerous simulations of $ \Gt $ has been carried out using the bare scheme for $ \Sigma^* $ with different values of the interaction parameter $ \alpha $ and the external momentum $ \vec p $ from which $ E_0 $ and $ Z_0 $ then have been extracted. The result is presented in figures \ref{fig:EandZvsP} and \ref{fig:EandZvsA} but also in table \ref{tab:EandZvsPandA}. The computation time for each data point range from two to twelve core hours, providing a standard deviation smaller than $ 5 \cdot 10^{-4} $. For comparison these numerically computed quantities are presented next to corresponding ones obtained using traditional analytical perturbative methods.

\todo{Present the analytical perturbative quantities here instead of doing it in the caption of the figures.}

\begin{figure}[H]
	\centering
	\begin{subfigure}[b]{\textwidth}
		\includegraphics[width=\textwidth]{{"Images/Plots/Quantities/EandZvsP"}.pdf}
	\end{subfigure}
	\caption{Here the numerically obtained $ E_0^\text{DMC} $ and $ Z_0^\text{DMC} $ are plotted against the external momentum magnitude $ p $ at $ \alpha = 1 $. The perturbative analytical result of $ E_0 $ up to first \cite{electronsInLatticeFields}\cite{RichardFeynman} and second \cite{Haga} order are also outlined and happen to agree quite well for $ p < 1 $. The error bars are here omitted since they would not have been visible due to the low uncertainty.}
	\label{fig:EandZvsP}
\end{figure}

\begin{figure}[H]
	\centering
	\begin{subfigure}[b]{\textwidth}
		\includegraphics[width=\textwidth]{{"Images/Plots/Quantities/EandZvsA"}.pdf}
	\end{subfigure}
	\caption{Here the numerically obtained $ E_0^\text{DMC} $ and $ Z_0^\text{DMC} $ are plotted against the interaction parameter $ \alpha $ at $ p = 0 $. Again analytical perturbative results up to the first and second order are outlined. Since $ \Gt^{(1)}(\vec p = \vec 0, \tau) = [1 - \alpha/2] \, \Gt^{(0)} (\vec p = \vec 0, \tau)$ it is apparent that $ Z_0^{(0)} = 1 - \alpha/2 $ by comparing agains \ref{eq:longTimeLimit}. The error bars are here omitted since they would not have been visible due to the low uncertainty.}
	\label{fig:EandZvsA}
\end{figure}

\begin{table}[H]
	\begin{minipage}{.5\linewidth}
		\centering
		\caption*{$ \alpha = 1 $}
		\begin{tabular}{r | c | c} 
			$ p $ & $ E_0^\text{DMC} $ & $ Z_0^\text{DMC} $ \\ 
		 	\specialrule{.1em}{.05em}{.05em} 
0 & -1.0168 & 0.5918 \\
0.11 & -1.0117 & 0.5909 \\
0.21 & -0.9984 & 0.5886 \\
0.33 & -0.9714 & 0.5839 \\
0.45 & -0.9326 & 0.5769 \\
0.55 & -0.8915 & 0.5691 \\
0.67 & -0.8320 & 0.5569 \\
0.79 & -0.7619 & 0.5411 \\
0.89 & -0.6959 & 0.5248 \\
1 & -0.6158 & 0.5022 \\
1.26 & -0.4044 & 0.4251 \\
1.41 & -0.2760 & 0.3585 \\
1.55 & -0.1618 & 0.2763 \\
1.615 & -0.1141 & 0.2303 \\
1.675 & -0.0753 & 0.1825 \\
1.73 & -0.0458 & 0.1328 \\
		\end{tabular}
	\end{minipage}%
	\begin{minipage}{.5\linewidth}
		\centering
		\caption*{$ p = 0 $}
		\begin{tabular}{r | c | c} 
			$ \alpha $ & $ E_0^\text{DMC} $ & $ Z_0^\text{DMC} $ \\ 
			\specialrule{.1em}{.05em}{.05em} 
0.01 & -0.0100 & 0.9950 \\
0.1 & -0.1002 & 0.9511 \\
0.3 & -0.3015 & 0.8590 \\
0.5 & -0.5041 & 0.7743 \\
0.8 & -0.8107 & 0.6600 \\
1 & -1.0168 & 0.5918 \\
1.5 & -1.5389 & 0.4458 \\
2 & -2.0711 & 0.3303 \\
2.5 & -2.6147 & 0.2401 \\
3 & -3.1705 & 0.1708 \\
3.5 & -3.7403 & 0.1184 \\
4 & -4.3256 & 0.0797 \\
4.5 & -4.9284 & 0.0516 \\
5 & -5.5514 & 0.0320 \\
5.5 & -6.1976 & 0.0188 \\
6 & -6.8709 & 0.0104 \\
		\end{tabular}
	\end{minipage} 
	\caption{Some of the data from figures \ref{fig:EandZvsP} and \ref{fig:EandZvsA}.}
	\label{tab:EandZvsPandA}   
\end{table}

